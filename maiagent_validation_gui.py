#!/usr/bin/env python3
"""
MaiAgent Django è‡ªå‹•åŒ–é©—è­‰å·¥å…· - GUI ç‰ˆæœ¬

å…·æœ‰åœ–å½¢åŒ–ä½¿ç”¨è€…ç•Œé¢çš„ AI åŠ©ç†å›è¦†å“è³ªé©—è­‰å·¥å…·
æ”¯æ´ RAG å¢å¼·çµ±è¨ˆåˆ†æåŠŸèƒ½
"""

# ç‰ˆæœ¬ä¿¡æ¯
__version__ = "4.2.6"
__app_name__ = "MaiAgent ç®¡ç†å·¥å…·é›†"
__build_date__ = "2025-01-27"
__author__ = "MaiAgent Team"
__description__ = "AI åŠ©ç†å›è¦†å“è³ªé©—è­‰èˆ‡çµ„ç¹”ç®¡ç†å·¥å…· - RAG å¢å¼·ç‰ˆ"

import asyncio
import csv
import configparser
import json
import logging
import mimetypes
import os
import platform
import re
import subprocess
import sys
import threading
# éš±è— macOS Tk å»¢æ£„è­¦å‘Š
os.environ['TK_SILENCE_DEPRECATION'] = '1'
import tkinter as tk
from tkinter import ttk, filedialog, messagebox, scrolledtext
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import webbrowser
import time

import aiohttp
import pandas as pd
from difflib import SequenceMatcher


# è¨­å®šæ—¥èªŒ
def setup_logging():
    """è¨­å®šå¢å¼·ç‰ˆæ—¥èªŒç³»çµ±"""
    # å‰µå»ºæ—¥èªŒç›®éŒ„
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    
    # è¨­å®šæ—¥èªŒæ ¼å¼
    log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    date_format = '%Y-%m-%d %H:%M:%S'
    
    # æ¸…é™¤ç¾æœ‰çš„è™•ç†å™¨
    root_logger = logging.getLogger()
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)
    
    # è¨­å®šæ ¹æ—¥èªŒ
    logging.basicConfig(
        level=logging.DEBUG,
        format=log_format,
        datefmt=date_format,
        handlers=[
            # ä¸»æ—¥èªŒæ–‡ä»¶ - è¨˜éŒ„æ‰€æœ‰ç´šåˆ¥
            logging.FileHandler(
                log_dir / f'validation_main_{pd.Timestamp.now().strftime("%Y%m%d")}.log', 
                encoding='utf-8'
            ),
            # éŒ¯èª¤æ—¥èªŒæ–‡ä»¶ - åªè¨˜éŒ„éŒ¯èª¤
            logging.FileHandler(
                log_dir / f'validation_error_{pd.Timestamp.now().strftime("%Y%m%d")}.log', 
                encoding='utf-8'
            ),
            # æ§åˆ¶å°è¼¸å‡º
            logging.StreamHandler()
        ]
    )
    
    # è¨­å®šéŒ¯èª¤è™•ç†å™¨åªè¨˜éŒ„ERRORåŠä»¥ä¸Šç´šåˆ¥
    error_handler = logging.getLogger().handlers[1]
    error_handler.setLevel(logging.ERROR)
    
    return logging.getLogger(__name__)

logger = setup_logging()


@dataclass
class ValidationRow:
    """é©—è­‰è¡Œæ•¸æ“šçµæ§‹"""
    ç·¨è™Ÿ: str
    æå•è€…: str
    å•é¡Œæè¿°: str
    å»ºè­°_or_æ­£ç¢ºç­”æ¡ˆ: str
    æ‡‰åƒè€ƒçš„æ–‡ä»¶: str
    æ‡‰åƒè€ƒçš„æ–‡ä»¶æ®µè½: str
    æ‡‰åƒè€ƒæ–‡ä»¶UUID: str = ""  # æ–°å¢æ¬„ä½ï¼Œç”¨æ–¼UUIDåŒ¹é…
    æ˜¯å¦æª¢ç´¢KMæ¨è–¦: str = ""  # æ–°å¢æ¬„ä½ï¼Œæ§åˆ¶æ˜¯å¦é€²è¡Œé©—è­‰
    
    # API å›è¦†çµæœï¼ˆè‡ªå‹•å¡«å…¥ï¼‰
    AIåŠ©ç†å›è¦†: str = ""
    # å‹•æ…‹å¼•ç”¨ç¯€é»æ¬„ä½ï¼ˆå°‡åœ¨è™•ç†æ™‚å‹•æ…‹æ·»åŠ ï¼‰
    # å‹•æ…‹åƒè€ƒæ–‡ä»¶æ¬„ä½ï¼ˆå°‡åœ¨è™•ç†æ™‚å‹•æ…‹æ·»åŠ ï¼‰
    
    # é©—è­‰çµæœï¼ˆè‡ªå‹•å¡«å…¥ï¼‰
    å¼•ç”¨ç¯€é»æ˜¯å¦å‘½ä¸­: str = ""
    åƒè€ƒæ–‡ä»¶æ˜¯å¦æ­£ç¢º: str = ""
    å›è¦†æ˜¯å¦æ»¿æ„: str = ""
    
    # RAG å¢å¼·æŒ‡æ¨™ï¼ˆè‡ªå‹•å¡«å…¥ï¼‰
    precision: float = 0.0
    recall: float = 0.0
    f1_score: float = 0.0
    hit_rate: float = 0.0
    
    # åƒè€ƒæ–‡ä»¶å‘½ä¸­çµ±è¨ˆï¼ˆæ–°å¢ï¼‰
    åƒè€ƒæ–‡ä»¶å‘½ä¸­ç‡: float = 0.0
    æœŸæœ›æ–‡ä»¶ç¸½æ•¸: int = 0
    å‘½ä¸­æ–‡ä»¶æ•¸: int = 0
    å‘½ä¸­æ–‡ä»¶: str = ""  # æ–°å¢ï¼šæ ¼å¼åŒ–çš„å‘½ä¸­æ–‡ä»¶åˆ—è¡¨
    æœªå‘½ä¸­æ–‡ä»¶: str = ""
    
    # ç”¨æ–¼å„²å­˜åŸå§‹ API å›å‚³æ•¸æ“š
    _raw_citation_nodes: List[Dict] = None
    _raw_citations: List[Dict] = None
    
    def __post_init__(self):
        if self._raw_citation_nodes is None:
            self._raw_citation_nodes = []
        if self._raw_citations is None:
            self._raw_citations = []


@dataclass
class OrganizationMember:
    """çµ„ç¹”æˆå“¡è³‡æ–™çµæ§‹"""
    id: str
    name: str
    email: str
    is_owner: bool
    created_at: str
    groups: List[str]
    group_permissions: Dict[str, List[str]]


@dataclass
class DeploymentTask:
    """éƒ¨ç½²ä»»å‹™è³‡æ–™çµæ§‹"""
    task_id: str
    csv_file: str
    api_key: str
    base_url: str
    organization_name: str
    create_users: bool
    referral_code: str
    status: str = "pending"
    progress: int = 0
    log_messages: List[str] = None
    
    def __post_init__(self):
        if self.log_messages is None:
            self.log_messages = []


@dataclass
class ApiResponse:
    """API å›è¦†æ•¸æ“šçµæ§‹"""
    conversation_id: Optional[str]
    content: str
    citations: List[Dict]
    citation_nodes: List[Dict]


class MaiAgentApiClient:
    """MaiAgent API å®¢æˆ¶ç«¯"""
    
    def __init__(self, base_url: str, api_key: str, logger_callback=None):
        self.base_url = base_url.rstrip('/')
        self.api_key = api_key
        self.session = None
        self.logger_callback = logger_callback
    
    def _build_api_url(self, endpoint: str) -> str:
        """æ™ºèƒ½æ§‹å»ºAPI URLï¼Œé¿å…é‡è¤‡çš„/apiè·¯å¾‘"""
        base_url = self.base_url.rstrip('/')
        endpoint = endpoint.lstrip('/')
        
        # å¦‚æœbase_urlå·²ç¶“åŒ…å«/apiï¼Œç›´æ¥ä½¿ç”¨
        if base_url.endswith('/api'):
            return f"{base_url}/{endpoint}"
        # å¦‚æœbase_urlæ˜¯ä¸»åŸŸåï¼Œè‡ªå‹•æ·»åŠ /api
        elif base_url.endswith('.ai') or base_url.endswith('.com') or '/api' not in base_url:
            return f"{base_url}/api/{endpoint}"
        # å…¶ä»–æƒ…æ³ç›´æ¥æ‹¼æ¥
        else:
            return f"{base_url}/{endpoint}"
        
    def _log_api_request(self, url, method, payload=None, headers=None):
        """è¨˜éŒ„APIè«‹æ±‚ - å¢å¼·ç‰ˆæœ¬"""
        if self.logger_callback:
            # è¨˜éŒ„åŸºæœ¬è«‹æ±‚ä¿¡æ¯
            self.logger_callback('log_api_request', url, method, payload)
            
            # è¨˜éŒ„è©³ç´°çš„è«‹æ±‚ä¿¡æ¯
            details = [
                f"ğŸš€ APIè«‹æ±‚è©³æƒ…:",
                f"   æ–¹æ³•: {method}",
                f"   URL: {url}",
            ]
            
            if headers:
                details.append(f"   è«‹æ±‚Headers:")
                for key, value in headers.items():
                    # éš±è—æ•æ„Ÿä¿¡æ¯
                    if 'authorization' in key.lower() or 'api-key' in key.lower():
                        details.append(f"     {key}: {value[:20]}..." if len(str(value)) > 20 else f"     {key}: {value}")
                    else:
                        details.append(f"     {key}: {value}")
            
            if payload:
                details.append(f"   è«‹æ±‚è¼‰è·:")
                if isinstance(payload, dict):
                    import json
                    try:
                        payload_str = json.dumps(payload, indent=2, ensure_ascii=False)
                        # é™åˆ¶è¼‰è·é•·åº¦ä»¥é¿å…æ—¥èªŒéé•· - å¢åŠ åˆ°2000å­—å…ƒ
                        if len(payload_str) > 2000:
                            payload_str = payload_str[:2000] + "...(å…§å®¹å·²æˆªæ–·)"
                        details.append(f"     {payload_str}")
                    except:
                        details.append(f"     {str(payload)[:2000]}...")
                else:
                    details.append(f"     {str(payload)[:2000]}...")
            
            # ç™¼é€è©³ç´°æ—¥èªŒ
            for detail in details:
                if self.logger_callback:
                    self.logger_callback('log_info', detail, 'API')
    
    def _log_api_response(self, url, status_code, response_size=0, duration=None, response_data=None, response_headers=None):
        """è¨˜éŒ„APIå›æ‡‰ - å¢å¼·ç‰ˆæœ¬"""
        if self.logger_callback:
            # è¨˜éŒ„åŸºæœ¬å›æ‡‰ä¿¡æ¯
            self.logger_callback('log_api_response', url, status_code, response_size, duration)
            
            # è¨˜éŒ„è©³ç´°çš„å›æ‡‰ä¿¡æ¯
            details = [
                f"ğŸ“¥ APIå›æ‡‰è©³æƒ…:",
                f"   URL: {url}",
                f"   ç‹€æ…‹ç¢¼: {status_code}",
                f"   å›æ‡‰å¤§å°: {response_size} å­—å…ƒ",
            ]
            
            if duration:
                details.append(f"   è€—æ™‚: {duration:.2f}ç§’")
            
            if response_headers:
                details.append(f"   å›æ‡‰Headers:")
                for key, value in response_headers.items():
                    details.append(f"     {key}: {value}")
            
            if response_data:
                details.append(f"   å›æ‡‰å…§å®¹:")
                if isinstance(response_data, dict):
                    import json
                    try:
                        response_str = json.dumps(response_data, indent=2, ensure_ascii=False)
                        # é™åˆ¶å›æ‡‰é•·åº¦ä»¥é¿å…æ—¥èªŒéé•· - å¢åŠ åˆ°5000å­—å…ƒ
                        if len(response_str) > 5000:
                            response_str = response_str[:5000] + "...(å…§å®¹å·²æˆªæ–·)"
                        details.append(f"     {response_str}")
                    except:
                        details.append(f"     {str(response_data)[:1000]}...")
                elif isinstance(response_data, str):
                    if len(response_data) > 5000:
                        details.append(f"     {response_data[:5000]}...(å…§å®¹å·²æˆªæ–·)")
                    else:
                        details.append(f"     {response_data}")
                else:
                    details.append(f"     {str(response_data)[:5000]}...")
            
            # ç™¼é€è©³ç´°æ—¥èªŒ
            log_level = 'log_info' if 200 <= status_code < 300 else 'log_error'
            for detail in details:
                if self.logger_callback:
                    self.logger_callback(log_level, detail, 'API')
        
    async def __aenter__(self):
        headers = {
            'Authorization': f'Api-Key {self.api_key}',
            'Content-Type': 'application/json'
        }
        # æ·»åŠ è¶…æ™‚è¨­å®šå’Œé€£æ¥æ± é…ç½®
        timeout = aiohttp.ClientTimeout(total=90, connect=10, sock_read=60)
        connector = aiohttp.TCPConnector(
            limit=100,  # ç¸½é€£æ¥æ± å¤§å°
            limit_per_host=20,  # æ¯å€‹ä¸»æ©Ÿçš„é€£æ¥æ•¸
            enable_cleanup_closed=True,  # å•Ÿç”¨æ¸…ç†é—œé–‰çš„é€£æ¥
            force_close=False,  # å…è¨±é€£æ¥é‡ç”¨ä»¥æé«˜æ€§èƒ½
            keepalive_timeout=30  # ä¿æŒé€£æ¥çš„è¶…æ™‚æ™‚é–“
        )
        self.session = aiohttp.ClientSession(
            headers=headers, 
            timeout=timeout,
            connector=connector
        )
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def get_chatbots(self) -> List[Dict]:
        """ç²å–å¯ç”¨çš„èŠå¤©æ©Ÿå™¨äººåˆ—è¡¨ï¼ˆæ”¯æ´åˆ†é ï¼‰"""
        if not self.session:
            raise Exception("API Client session not initialized")
            
        all_chatbots = []
        url = self._build_api_url("chatbots/")
        page_number = 1
        
        while url:
            start_time = pd.Timestamp.now()
            
            self._log_api_request(url, 'GET')
            
            async with self.session.get(url) as response:
                duration = (pd.Timestamp.now() - start_time).total_seconds()
                response_text = await response.text()
                
                self._log_api_response(url, response.status, len(response_text), duration)
                
                if response.status == 200:
                    data = await response.json()
                    
                    if isinstance(data, list):
                        # ç›´æ¥è¿”å›åˆ—è¡¨ï¼ˆéåˆ†é æ ¼å¼ï¼‰
                        return data
                    elif isinstance(data, dict):
                        # åˆ†é æ ¼å¼
                        current_results = data.get('results', [])
                        all_chatbots.extend(current_results)
                        
                        # æª¢æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é 
                        next_url = data.get('next')
                        if next_url:
                            url = next_url
                            page_number += 1
                            # è¨˜éŒ„åˆ†é é€²åº¦
                            total_count = data.get('count', 0)
                            current_count = len(all_chatbots)
                            if self.logger_callback:
                                self.logger_callback('log_info', f"ğŸ“„ å·²è¼‰å…¥ç¬¬ {page_number-1} é ï¼Œå…± {current_count}/{total_count} å€‹èŠå¤©æ©Ÿå™¨äºº")
                        else:
                            # æ²’æœ‰ä¸‹ä¸€é ï¼ŒçµæŸå¾ªç’°
                            url = None
                    else:
                        return []
                else:
                    raise Exception(f"ç²å–èŠå¤©æ©Ÿå™¨äººåˆ—è¡¨å¤±æ•—: {response.status} - {response_text}")
        
        return all_chatbots
    
    async def send_message(self, chatbot_id: str, message: str, conversation_id: Optional[str] = None, max_retries: int = 3, query_metadata: Optional[Dict] = None) -> ApiResponse:
        """ç™¼é€è¨Šæ¯åˆ°æŒ‡å®šçš„èŠå¤©æ©Ÿå™¨äººï¼ˆå…·å‚™é‡è©¦æ©Ÿåˆ¶ï¼‰"""
        if not self.session:
            raise Exception("API Client session not initialized")
            
        url = self._build_api_url(f"chatbots/{chatbot_id}/completions/")
        
        # æ§‹å»ºåŸºæœ¬è¼‰è·
        message_data = {
            "content": message,
            "attachments": []
        }
        
        # å¦‚æœæä¾›äº† query_metadataï¼Œæ·»åŠ åˆ° message ä¸­
        if query_metadata:
            message_data["query_metadata"] = query_metadata
        
        payload = {
            "conversation": conversation_id,
            "message": message_data,
            "isStreaming": False
        }
        
        last_exception = None
        
        for attempt in range(max_retries):
            try:
                start_time = pd.Timestamp.now()
                self._log_api_request(url, 'POST', payload)
                
                async with self.session.post(url, json=payload) as response:
                    duration = (pd.Timestamp.now() - start_time).total_seconds()
                    response_text = await response.text()
                    
                    # è¨˜éŒ„åŸå§‹å›æ‡‰æ–‡æœ¬
                    self._log_api_response(url, response.status, len(response_text), duration, response_data=response_text)
                    
                    if response.status == 200:
                        data = await response.json()
                        
                        # é¡å¤–è¨˜éŒ„è§£æå¾Œçš„JSONçµæ§‹ä»¥ä¾¿æ–¼é™¤éŒ¯
                        if self.logger_callback:
                            self.logger_callback('log_info', f"ğŸ” è§£æå¾Œçš„APIå›æ‡‰çµæ§‹:", 'API')
                            self.logger_callback('log_info', f"   - conversationId: {data.get('conversationId', 'N/A')}", 'API')
                            self.logger_callback('log_info', f"   - content length: {len(data.get('content', ''))}", 'API')
                            self.logger_callback('log_info', f"   - citations count: {len(data.get('citations', []))}", 'API')
                            self.logger_callback('log_info', f"   - citationNodes count: {len(data.get('citationNodes', []))}", 'API')
                            
                            # è¨˜éŒ„citationsçµæ§‹
                            citations = data.get('citations', [])
                            if citations:
                                self.logger_callback('log_info', f"   ğŸ“„ Citations è©³æƒ…:", 'API')
                                for i, citation in enumerate(citations[:3], 1):  # åªé¡¯ç¤ºå‰3å€‹
                                    self.logger_callback('log_info', f"     {i}. filename: {citation.get('filename', 'N/A')}", 'API')
                                    self.logger_callback('log_info', f"        labels: {citation.get('labels', [])}", 'API')
                            
                            # è¨˜éŒ„citationNodesçµæ§‹
                            citation_nodes = data.get('citationNodes', [])
                            if citation_nodes:
                                self.logger_callback('log_info', f"   ğŸ“ CitationNodes è©³æƒ…:", 'API')
                                for i, node in enumerate(citation_nodes[:3], 1):  # åªé¡¯ç¤ºå‰3å€‹
                                    if 'chatbotTextNode' in node:
                                        if 'text' in node['chatbotTextNode']:
                                            content_preview = node['chatbotTextNode'].get('text', '')[:100]
                                            self.logger_callback('log_info', f"     {i}. chatbotTextNode.text: {content_preview}...", 'API')
                                        elif 'content' in node['chatbotTextNode']:
                                            content_preview = node['chatbotTextNode'].get('content', '')[:100]
                                            self.logger_callback('log_info', f"     {i}. chatbotTextNode.content: {content_preview}...", 'API')
                                        else:
                                            self.logger_callback('log_info', f"     {i}. chatbotTextNodeçµæ§‹: {list(node['chatbotTextNode'].keys())}", 'API')
                                    elif 'text' in node:
                                        content_preview = node.get('text', '')[:100]
                                        self.logger_callback('log_info', f"     {i}. text: {content_preview}...", 'API')
                                    else:
                                        self.logger_callback('log_info', f"     {i}. çµæ§‹: {list(node.keys())}", 'API')
                        
                        return ApiResponse(
                            conversation_id=data.get('conversationId'),
                            content=data.get('content', ''),
                            citations=data.get('citations', []),
                            citation_nodes=data.get('citationNodes', [])
                        )
                    else:
                        raise Exception(f"ç™¼é€è¨Šæ¯å¤±æ•—: {response.status} - {response_text}")
                        
            except (aiohttp.ClientError, aiohttp.ServerTimeoutError, asyncio.TimeoutError, 
                    ConnectionError, OSError) as e:
                last_exception = e
                error_str = str(e).lower()
                
                # ç‰¹æ®Šè™•ç†é€£æ¥é‡ç½®éŒ¯èª¤ï¼ˆWinError 10054ï¼‰
                is_connection_reset = any(keyword in error_str for keyword in [
                    'winerror 10054', 'connection was forcibly closed', 
                    'connection reset', 'connection aborted'
                ])
                
                if self.logger_callback:
                    if is_connection_reset:
                        self.logger_callback('log_warning', f"ğŸ”Œ é€£æ¥è¢«é ç«¯ä¸»æ©Ÿé‡ç½® (å˜—è©¦ {attempt + 1}/{max_retries}): {str(e)}", 'API')
                        self.logger_callback('log_info', f"   ğŸ’¡ å»ºè­°ï¼šé™ä½ä½µç™¼æ•¸é‡æˆ–å¢åŠ å»¶é²æ™‚é–“", 'API')
                    else:
                        self.logger_callback('log_warning', f"âš ï¸ API è«‹æ±‚å¤±æ•— (å˜—è©¦ {attempt + 1}/{max_retries}): {str(e)}", 'API')
                
                if attempt < max_retries - 1:
                    # å°æ–¼é€£æ¥é‡ç½®éŒ¯èª¤ï¼Œä½¿ç”¨æ›´é•·çš„ç­‰å¾…æ™‚é–“
                    if is_connection_reset:
                        wait_time = (2 ** attempt) * 2  # é€£æ¥é‡ç½®æ™‚ç­‰å¾…æ™‚é–“ç¿»å€
                    else:
                        wait_time = 2 ** attempt  # æŒ‡æ•¸é€€é¿ç­–ç•¥ï¼šæ¯æ¬¡é‡è©¦ç­‰å¾…æ™‚é–“åŠ å€
                    
                    if self.logger_callback:
                        # ä½¿ç”¨å®‰å…¨çš„æ—¥èªŒè¨˜éŒ„æ–¹å¼ï¼Œé¿å… GUI ç·šç¨‹å•é¡Œ
                        try:
                            if is_connection_reset:
                                self.logger_callback('log_info', f"   â° é€£æ¥é‡ç½®éŒ¯èª¤ï¼Œç­‰å¾… {wait_time} ç§’å¾Œé‡è©¦...", 'API')
                            else:
                                self.logger_callback('log_info', f"   â° {wait_time} ç§’å¾Œé‡è©¦...", 'API')
                        except Exception:
                            print(f"   â° {wait_time} ç§’å¾Œé‡è©¦...")
                    await asyncio.sleep(wait_time)
                    
        # æ‰€æœ‰é‡è©¦éƒ½å¤±æ•—äº†
        if last_exception:
            error_msg = f"API è«‹æ±‚åœ¨ {max_retries} æ¬¡é‡è©¦å¾Œä»ç„¶å¤±æ•—: {str(last_exception)}"
            if self.logger_callback:
                self.logger_callback('log_error', f"âŒ {error_msg}", 'API')
            raise Exception(error_msg)
        else:
            raise Exception("API è«‹æ±‚å¤±æ•—ï¼ŒæœªçŸ¥éŒ¯èª¤")
    
    # === çµ„ç¹”ç®¡ç†åŠŸèƒ½ ===
    
    async def get_organizations(self) -> List[Dict]:
        """ç²å–çµ„ç¹”åˆ—è¡¨"""
        if not self.session:
            raise Exception("API Client session not initialized")
            
        url = self._build_api_url("organizations/")
        start_time = pd.Timestamp.now()
        
        self._log_api_request(url, 'GET')
        
        async with self.session.get(url) as response:
            duration = (pd.Timestamp.now() - start_time).total_seconds()
            response_text = await response.text()
            
            self._log_api_response(url, response.status, len(response_text), duration)
            
            if response.status == 200:
                data = await response.json()
                if isinstance(data, list):
                    return data
                elif isinstance(data, dict):
                    return data.get('results', [])
                else:
                    return []
            else:
                raise Exception(f"ç²å–çµ„ç¹”åˆ—è¡¨å¤±æ•—: {response.status} - {response_text}")
    
    async def get_organization_members(self, org_id: str) -> List[Dict]:
        """ç²å–çµ„ç¹”æˆå“¡"""
        if not self.session:
            raise Exception("API Client session not initialized")

        url = self._build_api_url(f"organizations/{org_id}/members/")
        start_time = pd.Timestamp.now()

        self._log_api_request(url, 'GET')

        async with self.session.get(url) as response:
            duration = (pd.Timestamp.now() - start_time).total_seconds()
            response_text = await response.text()

            self._log_api_response(url, response.status, len(response_text), duration)

            if response.status == 200:
                data = await response.json()
                if isinstance(data, list):
                    return data
                elif isinstance(data, dict):
                    return data.get('results', [])
                else:
                    return []
            else:
                raise Exception(f"ç²å–çµ„ç¹”æˆå“¡å¤±æ•—: {response.status} - {response_text}")
    
    async def get_organization_groups(self, org_id: str) -> List[Dict]:
        """ç²å–çµ„ç¹”ç¾¤çµ„"""
        if not self.session:
            raise Exception("API Client session not initialized")

        url = self._build_api_url(f"organizations/{org_id}/groups/")
        start_time = pd.Timestamp.now()

        self._log_api_request(url, 'GET')

        async with self.session.get(url) as response:
            duration = (pd.Timestamp.now() - start_time).total_seconds()
            response_text = await response.text()

            self._log_api_response(url, response.status, len(response_text), duration)

            if response.status == 200:
                data = await response.json()
                if isinstance(data, list):
                    return data
                elif isinstance(data, dict):
                    return data.get('results', [])
                else:
                    return []
            else:
                raise Exception(f"ç²å–çµ„ç¹”ç¾¤çµ„å¤±æ•—: {response.status} - {response_text}")
    
    async def get_group_members(self, org_id: str, group_id: str) -> List[Dict]:
        """ç²å–ç¾¤çµ„æˆå“¡"""
        if not self.session:
            raise Exception("API Client session not initialized")

        url = self._build_api_url(f"organizations/{org_id}/groups/{group_id}/group-members/")
        start_time = pd.Timestamp.now()

        self._log_api_request(url, 'GET')

        async with self.session.get(url) as response:
            duration = (pd.Timestamp.now() - start_time).total_seconds()
            response_text = await response.text()

            self._log_api_response(url, response.status, len(response_text), duration)

            if response.status == 200:
                data = await response.json()
                if isinstance(data, list):
                    return data
                elif isinstance(data, dict):
                    return data.get('results', [])
                else:
                    return []
            else:
                raise Exception(f"ç²å–ç¾¤çµ„æˆå“¡å¤±æ•—: {response.status} - {response_text}")
    
    async def get_permissions(self) -> List[Dict]:
        """ç²å–æ¬Šé™åˆ—è¡¨"""
        if not self.session:
            raise Exception("API Client session not initialized")

        url = self._build_api_url("permissions/")
        start_time = pd.Timestamp.now()

        self._log_api_request(url, 'GET')

        async with self.session.get(url) as response:
            duration = (pd.Timestamp.now() - start_time).total_seconds()
            response_text = await response.text()

            self._log_api_response(url, response.status, len(response_text), duration)

            if response.status == 200:
                data = await response.json()
                if isinstance(data, list):
                    return data
                elif isinstance(data, dict):
                    return data.get('results', [])
                else:
                    return []
            else:
                raise Exception(f"ç²å–æ¬Šé™åˆ—è¡¨å¤±æ•—: {response.status} - {response_text}")
    
    # === çŸ¥è­˜åº«ç®¡ç†åŠŸèƒ½ ===
    
    async def get_knowledge_bases(self) -> List[Dict]:
        """ç²å–çŸ¥è­˜åº«åˆ—è¡¨ï¼ˆæ”¯æ´åˆ†é ï¼‰"""
        if not self.session:
            raise Exception("API Client session not initialized")

        all_knowledge_bases = []
        url = self._build_api_url("knowledge-bases/")
        page_number = 1
        
        while url:
            start_time = pd.Timestamp.now()

            # è¨˜éŒ„è«‹æ±‚è©³æƒ…ï¼ˆåŒ…å«headersï¼‰
            request_headers = dict(self.session.headers) if hasattr(self.session, 'headers') else {}
            self._log_api_request(url, 'GET', headers=request_headers)

            async with self.session.get(url) as response:
                duration = (pd.Timestamp.now() - start_time).total_seconds()
                response_text = await response.text()
                
                # è¨˜éŒ„å›æ‡‰è©³æƒ…ï¼ˆåŒ…å«headerså’Œå…§å®¹ï¼‰
                response_headers = dict(response.headers)
                try:
                    response_data = await response.json() if response_text else None
                except:
                    response_data = response_text

                self._log_api_response(url, response.status, len(response_text), duration, 
                                     response_data=response_data, response_headers=response_headers)

                if response.status == 200:
                    data = await response.json()
                    
                    if isinstance(data, list):
                        # ç›´æ¥è¿”å›åˆ—è¡¨ï¼ˆéåˆ†é æ ¼å¼ï¼‰
                        return data
                    elif isinstance(data, dict):
                        # åˆ†é æ ¼å¼
                        current_results = data.get('results', [])
                        all_knowledge_bases.extend(current_results)
                        
                        # æª¢æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é 
                        next_url = data.get('next')
                        if next_url:
                            url = next_url
                            page_number += 1
                            # è¨˜éŒ„åˆ†é é€²åº¦
                            total_count = data.get('count', 0)
                            current_count = len(all_knowledge_bases)
                            if self.logger_callback:
                                self.logger_callback('log_info', f"ğŸ“„ å·²è¼‰å…¥ç¬¬ {page_number-1} é ï¼Œå…± {current_count}/{total_count} å€‹çŸ¥è­˜åº«")
                        else:
                            # æ²’æœ‰ä¸‹ä¸€é ï¼ŒçµæŸå¾ªç’°
                            url = None
                    else:
                        return []
                else:
                    raise Exception(f"ç²å–çŸ¥è­˜åº«åˆ—è¡¨å¤±æ•—: {response.status} - {response_text}")
        
        return all_knowledge_bases
    
    async def get_knowledge_base_files(self, kb_id: str, progress_callback=None, load_all_at_once=True) -> List[Dict]:
        """ç²å–çŸ¥è­˜åº«æ–‡ä»¶åˆ—è¡¨ï¼ˆæ”¯æ´ä¸€æ¬¡æ€§è¼‰å…¥æˆ–åˆ†é è¼‰å…¥ï¼‰"""
        if not self.session:
            raise Exception("API Client session not initialized")

        if load_all_at_once:
            # å˜—è©¦ä¸€æ¬¡æ€§è¼‰å…¥æ‰€æœ‰æ–‡ä»¶
            return await self._get_all_files_at_once(kb_id, progress_callback)
        else:
            # ä½¿ç”¨åŸæœ‰åˆ†é æ–¹å¼
            return await self._get_files_paginated(kb_id, progress_callback)
    
    async def _get_all_files_at_once(self, kb_id: str, progress_callback=None) -> List[Dict]:
        """ä¸€æ¬¡æ€§è¼‰å…¥æ‰€æœ‰çŸ¥è­˜åº«æ–‡ä»¶"""
        # å…ˆç²å–ç¬¬ä¸€é ä¾†å¾—åˆ°ç¸½æ•¸
        url = self._build_api_url(f"knowledge-bases/{kb_id}/files/")
        
        start_time = pd.Timestamp.now()
        self._log_api_request(url, 'GET')
        
        async with self.session.get(url) as response:
            duration = (pd.Timestamp.now() - start_time).total_seconds()
            response_text = await response.text()
            self._log_api_response(url, response.status, len(response_text), duration)
            
            if response.status != 200:
                raise Exception(f"ç²å–çŸ¥è­˜åº«æ–‡ä»¶åˆ—è¡¨å¤±æ•—: {response.status} - {response_text}")
            
            data = await response.json()
            
            if isinstance(data, list):
                # ç›´æ¥è¿”å›åˆ—è¡¨ï¼ˆéåˆ†é æ ¼å¼ï¼‰
                if progress_callback:
                    progress_callback(len(data), len(data))
                if self.logger_callback:
                    self.logger_callback('log_info', f"ğŸ“„ ä¸€æ¬¡æ€§è¼‰å…¥å®Œæˆï¼Œå…± {len(data)} å€‹æ–‡ä»¶")
                return data
            elif isinstance(data, dict):
                total_count = data.get('count', 0)
                if total_count == 0:
                    return []
                
                # å˜—è©¦ç”¨å¤§çš„ page_size ä¸€æ¬¡æ€§ç²å–æ‰€æœ‰æ–‡ä»¶
                large_page_size = max(total_count, 10000)  # è‡³å°‘10000ï¼Œç¢ºä¿èƒ½ç²å–æ‰€æœ‰æ–‡ä»¶
                url_with_size = self._build_api_url(f"knowledge-bases/{kb_id}/files/?page_size={large_page_size}")
                
                start_time = pd.Timestamp.now()
                self._log_api_request(url_with_size, 'GET')
                
                async with self.session.get(url_with_size) as large_response:
                    duration = (pd.Timestamp.now() - start_time).total_seconds()
                    large_response_text = await large_response.text()
                    self._log_api_response(url_with_size, large_response.status, len(large_response_text), duration)
                    
                    if large_response.status == 200:
                        large_data = await large_response.json()
                        all_files = large_data.get('results', [])
                        
                        if progress_callback:
                            progress_callback(len(all_files), total_count)
                        
                        if self.logger_callback:
                            self.logger_callback('log_info', f"ğŸ“„ ä¸€æ¬¡æ€§è¼‰å…¥å®Œæˆï¼Œå…± {len(all_files)}/{total_count} å€‹æ–‡ä»¶")
                        
                        return all_files
                    else:
                        # å¦‚æœå¤§é é¢è¼‰å…¥å¤±æ•—ï¼Œå›é€€åˆ°åˆ†é æ¨¡å¼
                        if self.logger_callback:
                            self.logger_callback('log_warning', f"ä¸€æ¬¡æ€§è¼‰å…¥å¤±æ•—ï¼Œå›é€€åˆ°åˆ†é æ¨¡å¼: {large_response.status}")
                        return await self._get_files_paginated(kb_id, progress_callback)
            else:
                return []

    async def _get_files_paginated(self, kb_id: str, progress_callback=None) -> List[Dict]:
        """åŸæœ‰çš„åˆ†é è¼‰å…¥æ–¹å¼ï¼ˆå‚™ç”¨ï¼‰"""
        all_files = []
        url = self._build_api_url(f"knowledge-bases/{kb_id}/files/")
        page_number = 1
        total_count = 0
        
        while url:
            start_time = pd.Timestamp.now()
            self._log_api_request(url, 'GET')

            async with self.session.get(url) as response:
                duration = (pd.Timestamp.now() - start_time).total_seconds()
                response_text = await response.text()
                self._log_api_response(url, response.status, len(response_text), duration)

                if response.status == 200:
                    data = await response.json()
                    
                    if isinstance(data, list):
                        if progress_callback:
                            progress_callback(len(data), len(data))
                        return data
                    elif isinstance(data, dict):
                        current_results = data.get('results', [])
                        all_files.extend(current_results)
                        
                        next_url = data.get('next')
                        total_count = data.get('count', 0)
                        current_count = len(all_files)
                        
                        if progress_callback:
                            progress_callback(current_count, total_count)
                        
                        if next_url:
                            url = next_url
                            page_number += 1
                            if self.logger_callback:
                                self.logger_callback('log_info', f"ğŸ“„ å·²è¼‰å…¥ç¬¬ {page_number-1} é ï¼Œå…± {current_count}/{total_count} å€‹æ–‡ä»¶")
                        else:
                            url = None
                    else:
                        if progress_callback:
                            progress_callback(0, 0)
                        return []
                else:
                    raise Exception(f"ç²å–çŸ¥è­˜åº«æ–‡ä»¶åˆ—è¡¨å¤±æ•—: {response.status} - {response_text}")
        
        return all_files
    
    async def download_knowledge_base_file(self, kb_id: str, file_id: str, max_retries: int = 3) -> bytes:
        """ä¸‹è¼‰çŸ¥è­˜åº«æ–‡ä»¶ï¼ˆæ”¯æ´é‡è©¦æ©Ÿåˆ¶ï¼‰"""
        if not self.session:
            raise Exception("API Client session not initialized")

        last_error = None
        
        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    # ç­‰å¾…ä¸€æ®µæ™‚é–“å†é‡è©¦
                    await asyncio.sleep(2 ** attempt)  # æŒ‡æ•¸é€€é¿ï¼š2, 4, 8 ç§’
                    # ä½¿ç”¨å®‰å…¨çš„æ—¥èªŒè¨˜éŒ„æ–¹å¼ï¼Œé¿å… GUI ç·šç¨‹å•é¡Œ
                    try:
                        self.logger_callback('log_info', f"é‡è©¦ä¸‹è¼‰æ–‡ä»¶ {file_id}ï¼Œç¬¬ {attempt + 1} æ¬¡å˜—è©¦")
                    except Exception:
                        print(f"é‡è©¦ä¸‹è¼‰æ–‡ä»¶ {file_id}ï¼Œç¬¬ {attempt + 1} æ¬¡å˜—è©¦")
                
                # å…ˆç²å–æ–‡ä»¶çš„è©³ç´°ä¿¡æ¯ï¼ŒåŒ…å«æ–‡ä»¶çš„ URL
                file_detail_url = self._build_api_url(f"knowledge-bases/{kb_id}/files/{file_id}/")
                start_time = pd.Timestamp.now()
                
                self._log_api_request(file_detail_url, 'GET')
                
                async with self.session.get(file_detail_url) as response:
                    duration = (pd.Timestamp.now() - start_time).total_seconds()
                    self._log_api_response(file_detail_url, response.status, 0, duration)
                    
                    if response.status == 200:
                        file_data = await response.json()
                        
                        # å¾æ–‡ä»¶è©³ç´°ä¿¡æ¯ä¸­ç²å–æ–‡ä»¶ URL
                        file_url = None
                        if 'file' in file_data and file_data['file']:
                            file_url = file_data['file']
                        
                        if not file_url:
                            raise Exception(f"æ–‡ä»¶ {file_id} æ²’æœ‰å¯ç”¨çš„ä¸‹è¼‰ URL")
                        
                        # æª¢æŸ¥æ–‡ä»¶ç‹€æ…‹
                        file_status = file_data.get('status', '')
                        if file_status in ['deleting', 'failed']:
                            raise Exception(f"æ–‡ä»¶ {file_id} ç‹€æ…‹ç‚º {file_status}ï¼Œç„¡æ³•ä¸‹è¼‰")
                        
                        # ç›´æ¥ä¸‹è¼‰æ–‡ä»¶ URL
                        self._log_api_request(file_url, 'GET')
                        download_start_time = pd.Timestamp.now()
                        
                        async with self.session.get(file_url) as download_response:
                            download_duration = (pd.Timestamp.now() - download_start_time).total_seconds()
                            
                            if download_response.status == 200:
                                file_content = await download_response.read()
                                self._log_api_response(file_url, download_response.status, len(file_content), download_duration)
                                if attempt > 0:
                                    # ä½¿ç”¨å®‰å…¨çš„æ—¥èªŒè¨˜éŒ„æ–¹å¼ï¼Œé¿å… GUI ç·šç¨‹å•é¡Œ
                                    try:
                                        self.logger_callback('log_info', f"æ–‡ä»¶ {file_id} é‡è©¦æˆåŠŸ")
                                    except Exception:
                                        print(f"æ–‡ä»¶ {file_id} é‡è©¦æˆåŠŸ")
                                return file_content
                            else:
                                response_text = await download_response.text()
                                self._log_api_response(file_url, download_response.status, len(response_text), download_duration)
                                
                                # å¦‚æœæ˜¯ 502/503/504 ç­‰æœå‹™å™¨éŒ¯èª¤ï¼Œå¯ä»¥é‡è©¦
                                if download_response.status in [502, 503, 504] and attempt < max_retries - 1:
                                    last_error = Exception(f"ä¸‹è¼‰æ–‡ä»¶å¤±æ•—: HTTP {download_response.status} - {response_text}")
                                    continue
                                else:
                                    raise Exception(f"ä¸‹è¼‰æ–‡ä»¶å¤±æ•—: HTTP {download_response.status} - {response_text}")
                    
                    elif response.status == 404:
                        raise Exception(f"æ–‡ä»¶ {file_id} ä¸å­˜åœ¨")
                    elif response.status in [502, 503, 504] and attempt < max_retries - 1:
                        # æœå‹™å™¨éŒ¯èª¤ï¼Œå¯ä»¥é‡è©¦
                        response_text = await response.text()
                        last_error = Exception(f"ç²å–æ–‡ä»¶ä¿¡æ¯å¤±æ•—: HTTP {response.status} - {response_text}")
                        continue
                    else:
                        response_text = await response.text()
                        raise Exception(f"ç²å–æ–‡ä»¶ä¿¡æ¯å¤±æ•—: HTTP {response.status} - {response_text}")
                        
            except asyncio.TimeoutError:
                last_error = Exception(f"ä¸‹è¼‰æ–‡ä»¶ {file_id} è¶…æ™‚")
                if attempt < max_retries - 1:
                    # ä½¿ç”¨å®‰å…¨çš„æ—¥èªŒè¨˜éŒ„æ–¹å¼ï¼Œé¿å… GUI ç·šç¨‹å•é¡Œ
                    try:
                        self.logger_callback('log_warning', f"æ–‡ä»¶ {file_id} ä¸‹è¼‰è¶…æ™‚ï¼Œå°‡é‡è©¦")
                    except Exception:
                        print(f"æ–‡ä»¶ {file_id} ä¸‹è¼‰è¶…æ™‚ï¼Œå°‡é‡è©¦")
                    continue
                else:
                    break
            except Exception as e:
                last_error = e
                # å°æ–¼æŸäº›éŒ¯èª¤ï¼Œä¸éœ€è¦é‡è©¦
                if "ä¸å­˜åœ¨" in str(e) or "ç„¡æ³•ä¸‹è¼‰" in str(e):
                    break
                elif attempt < max_retries - 1:
                    # ä½¿ç”¨å®‰å…¨çš„æ—¥èªŒè¨˜éŒ„æ–¹å¼ï¼Œé¿å… GUI ç·šç¨‹å•é¡Œ
                    try:
                        self.logger_callback('log_warning', f"ä¸‹è¼‰æ–‡ä»¶ {file_id} å¤±æ•—: {str(e)}")
                    except Exception:
                        print(f"ä¸‹è¼‰æ–‡ä»¶ {file_id} å¤±æ•—: {str(e)}")
                    continue
                else:
                    break
        
        # æ‰€æœ‰é‡è©¦éƒ½å¤±æ•—äº†
        error_msg = str(last_error) if last_error else f"ç„¡æ³•ä¸‹è¼‰æ–‡ä»¶ {file_id}"
        # ä½¿ç”¨å®‰å…¨çš„æ—¥èªŒè¨˜éŒ„æ–¹å¼ï¼Œé¿å… GUI ç·šç¨‹å•é¡Œ
        try:
            self.logger_callback('log_error', f"ä¸‹è¼‰æ–‡ä»¶ {file_id} æœ€çµ‚å¤±æ•—: {error_msg}")
        except Exception:
            print(f"ä¸‹è¼‰æ–‡ä»¶ {file_id} æœ€çµ‚å¤±æ•—: {error_msg}")
        raise Exception(f"ç„¡æ³•ä¸‹è¼‰æ–‡ä»¶ {file_id}: {error_msg}")
    
    async def get_knowledge_base_file_content(self, kb_id: str, file_id: str) -> Dict:
        """å–å¾—çŸ¥è­˜åº«æª”æ¡ˆå…§å®¹"""
        url = self._build_api_url(f"knowledge-bases/{kb_id}/files/{file_id}/")
        
        headers = {"Authorization": f"Api-Key {self.api_key}"}
        self._log_api_request(url, "GET")
        
        start_time = time.time()
        
        async with self.session.get(url, headers=headers) as response:
            if response.status == 200:
                result = await response.json()
                self._log_api_response(url, response.status, len(str(result)), time.time() - start_time)
                return result
            else:
                self._log_api_response(url, response.status, 0, time.time() - start_time)
                response.raise_for_status()

    async def get_upload_presigned_url(self, model_name: str, field_name: str, filename: str, file_size: int) -> Dict:
        """å–å¾—æª”æ¡ˆä¸Šå‚³çš„é ç°½åURL"""
        url = self._build_api_url("upload-presigned-url/")
        
        print(f"ğŸ” èª¿è©¦ä¿¡æ¯ - åŸå§‹base_url: {self.base_url}")
        print(f"ğŸ” èª¿è©¦ä¿¡æ¯ - é ç°½åURL: {url}")
        
        headers = {
            "Authorization": f"Api-Key {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model_name": model_name,
            "field_name": field_name,
            "filename": filename,
            "file_size": file_size
        }
        
        # è¨˜éŒ„è©³ç´°è«‹æ±‚ä¿¡æ¯ï¼ˆåŒ…å«headersï¼‰
        self._log_api_request(url, "POST", payload=payload, headers=headers)
        
        start_time = time.time()
        
        async with self.session.post(url, headers=headers, json=payload) as response:
            response_text = await response.text()
            response_headers = dict(response.headers)
            
            try:
                response_data = await response.json() if response_text else None
            except:
                response_data = response_text
            
            # è¨˜éŒ„è©³ç´°å›æ‡‰ä¿¡æ¯
            self._log_api_response(url, response.status, len(response_text), time.time() - start_time,
                                 response_data=response_data, response_headers=response_headers)
            
            if response.status == 200:
                result = await response.json()
                return result
            else:
                print(f"âŒ é ç°½åURLè«‹æ±‚å¤±æ•—: {response.status}")
                print(f"âŒ éŸ¿æ‡‰å…§å®¹: {response_text}")
                response.raise_for_status()

    async def upload_file_to_s3(self, presigned_data: Dict, file_path: str) -> bool:
        """ä½¿ç”¨é ç°½åURLä¸Šå‚³æª”æ¡ˆåˆ°S3 - ä¿®æ­£æ–‡ä»¶è™•ç†æ–¹å¼"""
        url = presigned_data["url"]
        fields = presigned_data["fields"]
        
        print(f"ğŸ” S3ä¸Šå‚³èª¿è©¦ - URL: {url}")
        print(f"ğŸ” S3ä¸Šå‚³èª¿è©¦ - å­—æ®µæ•¸é‡: {len(fields)}")
        print(f"ğŸ” S3ä¸Šå‚³èª¿è©¦ - æ–‡ä»¶è·¯å¾‘: {file_path}")
        print(f"ğŸ” S3ä¸Šå‚³èª¿è©¦ - æ–‡ä»¶å¤§å°: {os.path.getsize(file_path)} bytes")
        
        # ç²å–æ–‡ä»¶ç›¸é—œä¿¡æ¯
        filename = os.path.basename(file_path)
        content_type = mimetypes.guess_type(file_path)[0] or 'application/octet-stream'
        
        print(f"ğŸ” æ–‡ä»¶ä¿¡æ¯: filename={filename}, content_type={content_type}")
        
        # å…ˆè®€å–æ–‡ä»¶å…§å®¹åˆ°å…§å­˜ï¼Œé¿å…æ–‡ä»¶æè¿°ç¬¦å•é¡Œ
        with open(file_path, 'rb') as f:
            file_content = f.read()
        
        print(f"ğŸ” æ–‡ä»¶å…§å®¹è®€å–å®Œæˆ: {len(file_content)} bytes")
        
        # ä½¿ç”¨aiohttp.FormData - é—œéµï¼šä¸åœ¨withèªå¥ä¸­è™•ç†è«‹æ±‚
        data = aiohttp.FormData()
        
        # æ·»åŠ æ‰€æœ‰é ç°½åå­—æ®µ
        for key, value in fields.items():
            data.add_field(key, str(value))
            print(f"ğŸ” æ·»åŠ å­—æ®µ: {key} = {value}")
        
        # æ·»åŠ æ–‡ä»¶å…§å®¹ï¼ˆä¸æ˜¯æ–‡ä»¶å°è±¡ï¼‰
        data.add_field('file', file_content, 
                      filename=filename, 
                      content_type=content_type)
        
        print(f"ğŸ” æ·»åŠ æ–‡ä»¶å…§å®¹: filename={filename}, content_type={content_type}, size={len(file_content)}")
        
        start_time = time.time()
        # è¨˜éŒ„S3ä¸Šå‚³è«‹æ±‚è©³æƒ…
        s3_request_payload = {"fields": fields, "file": filename, "size": len(file_content)}
        self._log_api_request(url, "POST", payload=s3_request_payload, headers={"Content-Type": "multipart/form-data"})
        
        # ç‚ºS3ä¸Šå‚³å‰µå»ºç¨ç«‹çš„sessionï¼Œé¿å…é»˜èªheadersæ±¡æŸ“
        try:
            # å‰µå»ºè‡¨æ™‚sessionï¼Œä¸åŒ…å«ä»»ä½•é»˜èªheaders
            timeout = aiohttp.ClientTimeout(total=60)  # 60ç§’è¶…æ™‚
            async with aiohttp.ClientSession(timeout=timeout) as s3_session:
                # æ˜ç¢ºä¸è¨­ç½®ä»»ä½•headersï¼Œè®“aiohttpè‡ªå‹•è™•ç†multipart/form-data
                print(f"ğŸ” ä½¿ç”¨ç¨ç«‹S3 sessioné€²è¡Œä¸Šå‚³")
                async with s3_session.post(url, data=data) as response:
                    response_text = await response.text()
                    response_headers = dict(response.headers)
                    request_headers = dict(response.request_info.headers) if hasattr(response, 'request_info') else {}
                    success = response.status in [200, 201, 204]
                    
                    # è¨˜éŒ„è©³ç´°S3ä¸Šå‚³å›æ‡‰
                    self._log_api_response(url, response.status, len(response_text), time.time() - start_time,
                                         response_data=response_text, response_headers=response_headers)
                    
                    if not success:
                        print(f"âŒ S3ä¸Šå‚³å¤±æ•—: ç‹€æ…‹ç¢¼ {response.status}")
                        print(f"âŒ S3éŸ¿æ‡‰: {response_text}")
                        print(f"ğŸ” è«‹æ±‚headers: {request_headers}")
                    else:
                        print(f"âœ… S3ä¸Šå‚³æˆåŠŸ: ç‹€æ…‹ç¢¼ {response.status}")
                    
                    return success
                 
        except Exception as e:
            print(f"âŒ S3ä¸Šå‚³ç•°å¸¸: {e}")
            self._log_api_response(url, 0, 0, time.time() - start_time)
            return False

    async def create_knowledge_base_file(self, kb_id: str, filename: str, file_path_in_storage: str, parser_id: str = None) -> Dict:
        """åœ¨çŸ¥è­˜åº«ä¸­å‰µå»ºæª”æ¡ˆè¨˜éŒ„"""
        url = self._build_api_url(f"knowledge-bases/{kb_id}/files/")
        
        headers = {
            "Authorization": f"Api-Key {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "files": [
                {
                    "filename": filename,
                    "file": file_path_in_storage,
                    "parser": parser_id
                }
            ]
        }
        
        # è¨˜éŒ„è©³ç´°è«‹æ±‚ä¿¡æ¯
        self._log_api_request(url, "POST", payload=payload, headers=headers)
        
        start_time = time.time()
        
        async with self.session.post(url, headers=headers, json=payload) as response:
            response_text = await response.text()
            response_headers = dict(response.headers)
            
            try:
                response_data = await response.json() if response_text else None
            except:
                response_data = response_text
            
            # è¨˜éŒ„è©³ç´°å›æ‡‰ä¿¡æ¯
            self._log_api_response(url, response.status, len(response_text), time.time() - start_time,
                                 response_data=response_data, response_headers=response_headers)
            
            if response.status == 201:
                result = await response.json()
                return result
            else:
                response.raise_for_status()

    async def upload_file_to_knowledge_base(self, kb_id: str, file_path: str, parser_id: str = None) -> Dict:
        """å®Œæ•´çš„æª”æ¡ˆä¸Šå‚³åˆ°çŸ¥è­˜åº«æµç¨‹"""
        filename = os.path.basename(file_path)
        file_size = os.path.getsize(file_path)
        
        # 1. å–å¾—é ç°½åURL
        presigned_data = await self.get_upload_presigned_url(
            model_name="chatbot-file",
            field_name="file",
            filename=filename,
            file_size=file_size
        )
        
        # 2. ä¸Šå‚³æª”æ¡ˆåˆ°S3
        upload_success = await self.upload_file_to_s3(presigned_data, file_path)
        
        if not upload_success:
            raise Exception("æª”æ¡ˆä¸Šå‚³åˆ°S3å¤±æ•—")
        
        # 3. å¾é ç°½åURLçš„fieldsä¸­å–å¾—æª”æ¡ˆè·¯å¾‘
        file_key = presigned_data["fields"]["key"]
        # å°‡å®Œæ•´è·¯å¾‘è½‰ç‚ºç›¸å°è·¯å¾‘ï¼ˆç§»é™¤ media/ å‰ç¶´ï¼‰
        relative_path = file_key.replace('media/', '', 1) if file_key.startswith('media/') else file_key
        
        # 4. åœ¨çŸ¥è­˜åº«ä¸­å‰µå»ºæª”æ¡ˆè¨˜éŒ„
        result = await self.create_knowledge_base_file(kb_id, filename, relative_path, parser_id)
        
        return result
    
    # === å‰µå»ºåŠŸèƒ½ ===
    
    async def create_user(self, email: str, name: str, password: str = "TempPassword123!", 
                         company: str = "Default Company", referral_code: str = None) -> Optional[Dict]:
        """å‰µå»ºç”¨æˆ¶å¸³è™Ÿ"""
        if not self.session:
            raise Exception("API Client session not initialized")
        
        if not referral_code:
            print("âš ï¸  æœªæä¾›æ¨è–¦ç¢¼ï¼Œå°‡ç•¥éç”¨æˆ¶å‰µå»ºï¼ˆå‡è¨­ç”¨æˆ¶å·²å­˜åœ¨ï¼‰")
            return None
        
        user_data = {
            'email': email,
            'password1': password,
            'password2': password,
            'name': name,
            'company': company,
            'referralCode': referral_code
        }
        
        url = self._build_api_url("auth/registration/")
        start_time = pd.Timestamp.now()
        
        self._log_api_request(url, 'POST', user_data)
        
        try:
            async with self.session.post(url, json=user_data) as response:
                duration = (pd.Timestamp.now() - start_time).total_seconds()
                response_text = await response.text()
                
                self._log_api_response(url, response.status, len(response_text), duration)
                
                if response.status in [200, 201]:
                    print(f"âœ… ç”¨æˆ¶å‰µå»ºæˆåŠŸ: {name}")
                    return await response.json()
                else:
                    print(f"âš ï¸  ç”¨æˆ¶ {email} å‰µå»ºå¤±æ•—ï¼ˆå¯èƒ½å·²å­˜åœ¨ï¼‰: {response.status}")
                    return None
        except Exception as e:
            print(f"âš ï¸  ç”¨æˆ¶ {email} å‰µå»ºå¤±æ•—: {e}")
            return None
    
    async def create_organization(self, name: str) -> Dict:
        """å‰µå»ºçµ„ç¹”"""
        if not self.session:
            raise Exception("API Client session not initialized")
        
        org_data = {'name': name}
        
        url = self._build_api_url("organizations/")
        start_time = pd.Timestamp.now()
        
        self._log_api_request(url, 'POST', org_data)
        
        async with self.session.post(url, json=org_data) as response:
            duration = (pd.Timestamp.now() - start_time).total_seconds()
            response_text = await response.text()
            
            self._log_api_response(url, response.status, len(response_text), duration)
            
            if response.status in [200, 201]:
                return await response.json()
            else:
                raise Exception(f"å‰µå»ºçµ„ç¹”å¤±æ•—: {response.status} - {response_text}")
    
    async def create_group(self, organization_id: str, name: str, permission_names: List[str]) -> Dict:
        """å‰µå»ºç¾¤çµ„"""
        if not self.session:
            raise Exception("API Client session not initialized")
        
        # å…ˆç²å–æ‰€æœ‰æ¬Šé™
        permissions = await self.get_permissions()
        permission_map = {p['name']: p['id'] for p in permissions if isinstance(p, dict)}
        
        # è½‰æ›æ¬Šé™åç¨±ç‚º ID
        permission_ids = []
        for perm_name in permission_names:
            if perm_name in permission_map:
                permission_ids.append(permission_map[perm_name])
        
        group_data = {
            'name': name,
            'permissions': permission_ids
        }
        
        url = self._build_api_url(f"organizations/{organization_id}/groups/")
        start_time = pd.Timestamp.now()
        
        self._log_api_request(url, 'POST', group_data)
        
        async with self.session.post(url, json=group_data) as response:
            duration = (pd.Timestamp.now() - start_time).total_seconds()
            response_text = await response.text()
            
            self._log_api_response(url, response.status, len(response_text), duration)
            
            if response.status in [200, 201]:
                return await response.json()
            else:
                raise Exception(f"å‰µå»ºç¾¤çµ„å¤±æ•—: {response.status} - {response_text}")
    
    async def add_member_to_organization(self, organization_id: str, email: str) -> Dict:
        """æ·»åŠ æˆå“¡åˆ°çµ„ç¹”"""
        if not self.session:
            raise Exception("API Client session not initialized")
        
        member_data = {'email': email}
        
        url = self._build_api_url(f"organizations/{organization_id}/members/")
        start_time = pd.Timestamp.now()
        
        self._log_api_request(url, 'POST', member_data)
        
        async with self.session.post(url, json=member_data) as response:
            duration = (pd.Timestamp.now() - start_time).total_seconds()
            response_text = await response.text()
            
            self._log_api_response(url, response.status, len(response_text), duration)
            
            if response.status in [200, 201]:
                return await response.json()
            else:
                raise Exception(f"æ·»åŠ æˆå“¡åˆ°çµ„ç¹”å¤±æ•—: {response.status} - {response_text}")
    
    async def add_members_to_group(self, organization_id: str, group_id: str, member_ids: List[str]) -> List[Dict]:
        """æ‰¹é‡æ·»åŠ æˆå“¡åˆ°ç¾¤çµ„"""
        if not self.session:
            raise Exception("API Client session not initialized")
        
        results = []
        for member_id in member_ids:
            member_data = {'member': member_id}
            
            url = self._build_api_url(f"organizations/{organization_id}/groups/{group_id}/group-members/")
            start_time = pd.Timestamp.now()
            
            self._log_api_request(url, 'POST', member_data)
            
            try:
                async with self.session.post(url, json=member_data) as response:
                    duration = (pd.Timestamp.now() - start_time).total_seconds()
                    response_text = await response.text()
                    
                    self._log_api_response(url, response.status, len(response_text), duration)
                    
                    if response.status in [200, 201]:
                        result = await response.json()
                        results.append(result)
                    else:
                        print(f"âš ï¸  æ·»åŠ æˆå“¡ {member_id} åˆ°ç¾¤çµ„å¤±æ•—: {response.status}")
            except Exception as e:
                print(f"âš ï¸  æ·»åŠ æˆå“¡ {member_id} åˆ°ç¾¤çµ„æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        return results


class ConversationManager:
    """å°è©±ç®¡ç†å™¨ï¼Œè™•ç†ç›¸åŒæå•è€…çš„å°è©±æœƒè©±"""
    
    def __init__(self):
        self.conversations: Dict[str, str] = {}
        self.questioner_context: Dict[str, List[str]] = {}  # å„²å­˜æ¯å€‹æå•è€…çš„å•é¡Œä¸Šä¸‹æ–‡
    
    def get_conversation_id(self, questioner: str) -> Optional[str]:
        return self.conversations.get(questioner)
    
    def set_conversation_id(self, questioner: str, conversation_id: str):
        self.conversations[questioner] = conversation_id
    
    def add_question_to_context(self, questioner: str, question: str):
        """æ·»åŠ å•é¡Œåˆ°æå•è€…çš„ä¸Šä¸‹æ–‡ä¸­"""
        if questioner not in self.questioner_context:
            self.questioner_context[questioner] = []
        self.questioner_context[questioner].append(question)
    
    def get_context_questions(self, questioner: str) -> List[str]:
        """ç²å–æå•è€…çš„ä¸Šä¸‹æ–‡å•é¡Œåˆ—è¡¨"""
        return self.questioner_context.get(questioner, [])
    
    def build_context_message(self, questioner: str, current_question: str) -> str:
        """æ§‹å»ºåŒ…å«ä¸Šä¸‹æ–‡çš„å®Œæ•´å•é¡Œ"""
        previous_questions = self.get_context_questions(questioner)
        
        if not previous_questions:
            # å¦‚æœæ²’æœ‰å‰é¢çš„å•é¡Œï¼Œç›´æ¥è¿”å›ç•¶å‰å•é¡Œ
            return current_question
        
        # æ§‹å»ºä¸Šä¸‹æ–‡è¨Šæ¯
        context_parts = []
        context_parts.append("é€™æ˜¯ä¸€ç³»åˆ—ç›¸é—œçš„å•é¡Œï¼š")
        context_parts.append("")
        
        # æ·»åŠ å‰é¢çš„å•é¡Œ
        for i, prev_question in enumerate(previous_questions, 1):
            context_parts.append(f"å•é¡Œ {i}ï¼š{prev_question}")
        
        # æ·»åŠ ç•¶å‰å•é¡Œ
        context_parts.append(f"å•é¡Œ {len(previous_questions) + 1}ï¼š{current_question}")
        context_parts.append("")
        context_parts.append("è«‹é‡å°é€™ä¸€ç³»åˆ—å•é¡Œæä¾›å®Œæ•´çš„å›ç­”ï¼Œç‰¹åˆ¥æ˜¯æœ€å¾Œä¸€å€‹å•é¡Œã€‚")
        
        return "\n".join(context_parts)


class CSVParser:
    """CSV æ–‡ä»¶è§£æå™¨ - æ•´åˆè‡ª deploy_from_csv.py"""
    
    def __init__(self, csv_file: str):
        self.csv_file = csv_file
        self.members = []
        self.groups_info = {}
        
    def parse(self) -> Tuple[List[Dict], Dict[str, List[str]]]:
        """è§£æ CSV æ–‡ä»¶ï¼Œè¿”å›æˆå“¡åˆ—è¡¨å’Œç¾¤çµ„ä¿¡æ¯"""
        print(f"ğŸ“„ æ­£åœ¨è§£æ CSV æ–‡ä»¶: {self.csv_file}")
        
        # ä½¿ç”¨ç·¨ç¢¼æª¢æ¸¬è®€å–CSVæ–‡ä»¶
        encoding = self._detect_file_encoding(self.csv_file)
        with open(self.csv_file, 'r', encoding=encoding) as file:
            reader = csv.DictReader(file)
            
            for row in reader:
                member = {
                    'id': row.get('æˆå“¡ ID', ''),
                    'name': row.get('å§“å', ''),
                    'email': row.get('é›»å­éƒµä»¶', ''),
                    'is_owner': row.get('æ˜¯å¦ç‚ºæ“æœ‰è€…', 'å¦') == 'æ˜¯',
                    'groups': row.get('æ‰€å±¬ç¾¤çµ„', ''),
                    'group_permissions': row.get('ç¾¤çµ„æ¬Šé™é…ç½®', '')
                }
                
                self.members.append(member)
                
                # è§£æç¾¤çµ„æ¬Šé™é…ç½®
                self._parse_group_permissions(member['group_permissions'])
        
        print(f"âœ… CSV è§£æå®Œæˆï¼Œæ‰¾åˆ° {len(self.members)} å€‹æˆå“¡")
        print(f"ğŸ“‹ æ‰¾åˆ°ç¾¤çµ„: {', '.join(self.groups_info.keys())}")
        
        return self.members, self.groups_info
    
    def _parse_group_permissions(self, group_permissions_str: str):
        """è§£æç¾¤çµ„æ¬Šé™é…ç½®å­—ç¬¦ä¸²"""
        if not group_permissions_str or group_permissions_str == 'ç„¡':
            return
        
        # å…ˆæŒ‰åˆ†è™Ÿåˆ†å‰²ä¸åŒçš„ç¾¤çµ„é…ç½®
        group_configs = [config.strip() for config in group_permissions_str.split(';') if config.strip()]
        
        for group_config in group_configs:
            # è§£ææ¯å€‹ç¾¤çµ„é…ç½®ï¼šç¾¤çµ„åç¨±(æ¬Šé™1, æ¬Šé™2, ...)
            pattern = r'^(.+?)\(([^)]*)\)$'
            match = re.match(pattern, group_config.strip())
            
            if match:
                group_name = match.group(1).strip()
                permissions_str = match.group(2).strip()
                
                if permissions_str == 'ç„¡æ¬Šé™':
                    permissions = []
                else:
                    permissions = [p.strip() for p in permissions_str.split(',') if p.strip()]
                
                if group_name not in self.groups_info:
                    self.groups_info[group_name] = permissions
            else:
                print(f"âš ï¸ ç„¡æ³•è§£æç¾¤çµ„é…ç½®: {group_config}")
    
    def _detect_file_encoding(self, file_path):
        """æª¢æ¸¬æ–‡ä»¶ç·¨ç¢¼"""
        import chardet
        
        # å¸¸è¦‹ç·¨ç¢¼æ ¼å¼
        encodings_to_try = ['utf-8-sig', 'utf-8', 'big5', 'gbk', 'cp950', 'cp1252']
        
        try:
            with open(file_path, 'rb') as file:
                raw_data = file.read()
                detected = chardet.detect(raw_data)
                detected_encoding = detected.get('encoding', '')
                confidence = detected.get('confidence', 0)
                
                print(f"ğŸ” æª¢æ¸¬åˆ°æ–‡ä»¶ç·¨ç¢¼: {detected_encoding} (ä¿¡å¿ƒåº¦: {confidence:.2f})")
                
                if confidence > 0.7 and detected_encoding:
                    return detected_encoding.lower()
        except Exception as e:
            print(f"ç·¨ç¢¼æª¢æ¸¬å¤±æ•—: {e}")
        
        # é€ä¸€å˜—è©¦ç·¨ç¢¼
        for encoding in encodings_to_try:
            try:
                with open(file_path, 'r', encoding=encoding) as test_file:
                    test_file.read(1024)  # è®€å–å‰1024å­—ç¯€æ¸¬è©¦
                print(f"âœ… ä½¿ç”¨ç·¨ç¢¼: {encoding}")
                return encoding
            except UnicodeDecodeError:
                continue
        
        # é»˜èªè¿”å›utf-8-sig
        print("âš ï¸ ç„¡æ³•ç¢ºå®šç·¨ç¢¼ï¼Œä½¿ç”¨é»˜èª: utf-8-sig")
        return 'utf-8-sig'


class BatchImportProcessor:
    """æ‰¹é‡åŒ¯å…¥è™•ç†å™¨ - æ•´åˆè‡ª deploy_from_csv.py"""
    
    def __init__(self, api_client: MaiAgentApiClient, csv_file: str, referral_code: str = None):
        self.api_client = api_client
        self.parser = CSVParser(csv_file)
        self.referral_code = referral_code
        self.users_cache = {}
        
    async def execute_import(self, organization_name: str = None, create_users: bool = False, 
                           log_callback=None) -> bool:
        """åŸ·è¡Œæ‰¹é‡åŒ¯å…¥"""
        try:
            if log_callback:
                log_callback("ğŸš€ é–‹å§‹ MaiAgent å¸³è™Ÿæ‰¹é‡åŒ¯å…¥")
                log_callback("=" * 60)
            
            # 1. è§£æ CSV
            members, groups_info = self.parser.parse()
            
            if not organization_name:
                organization_name = f"å°å…¥çµ„ç¹”_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            # 2. å‰µå»ºçµ„ç¹”
            if log_callback:
                log_callback(f"\nğŸ¢ å‰µå»ºçµ„ç¹”: {organization_name}")
            
            organization = await self.api_client.create_organization(organization_name)
            organization_id = organization['id']
            
            if log_callback:
                log_callback(f"âœ… çµ„ç¹”å‰µå»ºæˆåŠŸï¼ŒID: {organization_id}")
            
            # 3. å‰µå»ºç”¨æˆ¶ï¼ˆå¯é¸ï¼‰
            if create_users and self.referral_code:
                if log_callback:
                    log_callback(f"\nğŸ‘¤ é–‹å§‹å‰µå»ºç”¨æˆ¶å¸³è™Ÿ...")
                
                for member in members:
                    if member['email']:
                        await self.api_client.create_user(
                            member['email'], 
                            member['name'], 
                            referral_code=self.referral_code
                        )
            
            # 4. å‰µå»ºç¾¤çµ„
            if log_callback:
                log_callback(f"\nğŸ·ï¸ å‰µå»ºç¾¤çµ„...")
            
            group_id_map = {}
            for group_name, permissions in groups_info.items():
                try:
                    group = await self.api_client.create_group(organization_id, group_name, permissions)
                    group_id_map[group_name] = group['id']
                    if log_callback:
                        log_callback(f"âœ… ç¾¤çµ„ '{group_name}' å‰µå»ºæˆåŠŸ")
                except Exception as e:
                    if log_callback:
                        log_callback(f"âš ï¸ ç¾¤çµ„ '{group_name}' å‰µå»ºå¤±æ•—: {e}")
            
            # 5. æ·»åŠ æˆå“¡åˆ°çµ„ç¹”
            if log_callback:
                log_callback(f"\nğŸ‘¥ æ·»åŠ æˆå“¡åˆ°çµ„ç¹”...")
            
            member_email_to_id = {}
            for member in members:
                if member['email']:
                    try:
                        org_member = await self.api_client.add_member_to_organization(organization_id, member['email'])
                        if isinstance(org_member, dict) and 'id' in org_member:
                            member_email_to_id[member['email']] = org_member['id']
                        elif isinstance(org_member, dict) and 'member' in org_member:
                            member_email_to_id[member['email']] = org_member['member']['id']
                        if log_callback:
                            log_callback(f"âœ… æˆå“¡ {member['name']} å·²æ·»åŠ åˆ°çµ„ç¹”")
                    except Exception as e:
                        if log_callback:
                            log_callback(f"âš ï¸ æ·»åŠ æˆå“¡ {member['name']} å¤±æ•—: {e}")
            
            # 6. æ·»åŠ æˆå“¡åˆ°ç¾¤çµ„
            if log_callback:
                log_callback(f"\nğŸ”— å»ºç«‹ç¾¤çµ„æˆå“¡é—œä¿‚...")
            
            for member in members:
                if member['email'] in member_email_to_id and member['groups']:
                    member_id = member_email_to_id[member['email']]
                    member_groups = [g.strip() for g in member['groups'].split(';') if g.strip()]
                    
                    for group_name in member_groups:
                        if group_name in group_id_map:
                            try:
                                await self.api_client.add_members_to_group(
                                    organization_id, 
                                    group_id_map[group_name], 
                                    [member_id]
                                )
                                if log_callback:
                                    log_callback(f"âœ… æˆå“¡ {member['name']} å·²åŠ å…¥ç¾¤çµ„ {group_name}")
                            except Exception as e:
                                if log_callback:
                                    log_callback(f"âš ï¸ æ·»åŠ æˆå“¡ {member['name']} åˆ°ç¾¤çµ„ {group_name} å¤±æ•—: {e}")
            
            if log_callback:
                log_callback(f"\nâœ… MaiAgent å¸³è™Ÿæ‰¹é‡åŒ¯å…¥å®Œæˆï¼")
                log_callback(f"ğŸ“Š åŒ¯å…¥çµ±è¨ˆ:")
                log_callback(f"   å‰µå»ºçµ„ç¹”: {organization_name}")
                log_callback(f"   å‰µå»ºç¾¤çµ„æ•¸é‡: {len(group_id_map)}")
                log_callback(f"   æˆåŠŸæ·»åŠ æˆå“¡æ•¸é‡: {len(member_email_to_id)}")
            
            return True
            
        except Exception as e:
            if log_callback:
                log_callback(f"âŒ æ‰¹é‡åŒ¯å…¥å¤±æ•—: {str(e)}")
            return False


class EnhancedTextMatcher:
    """å¢å¼·ç‰ˆæ–‡å­—æ¯”å°å·¥å…·ï¼Œæ”¯æ´ RAG ç³»çµ±å„ªåŒ–"""
    
    @staticmethod
    def calculate_similarity(text1: str, text2: str, mode: str = "standard", expected_segments: List[str] = None) -> float:
        """è¨ˆç®—å…©å€‹æ–‡å­—çš„ç›¸ä¼¼åº¦ï¼ˆ0-1ä¹‹é–“ï¼‰
        
        Args:
            text1: ç¬¬ä¸€å€‹æ–‡å­—ï¼ˆé€šå¸¸æ˜¯AIå›è¦†æ®µè½ï¼‰
            text2: ç¬¬äºŒå€‹æ–‡å­—ï¼ˆé€šå¸¸æ˜¯é æœŸæ®µè½ï¼‰
            mode: è¨ˆç®—æ¨¡å¼ï¼Œ"standard" æˆ– "character_ratio"
            expected_segments: æ‰€æœ‰é æœŸæ®µè½åˆ—è¡¨ï¼ˆåƒ…åœ¨character_ratioæ¨¡å¼ä¸‹ä½¿ç”¨ï¼‰
        """
        if not text1 or not text2:
            return 0.0
            
        if mode == "character_ratio":
            # æ–°çš„å­—ç¬¦æ¯”ä¾‹æ¨¡å¼ï¼šåŒ¹é…å­—ç¬¦æ•¸ / æ‡‰åƒè€ƒçš„æ–‡ä»¶ç¯€é»ç¸½é•·åº¦
            return EnhancedTextMatcher._calculate_character_ratio_similarity(text1, text2, expected_segments)
        else:
            # æ¨™æº–æ¨¡å¼ï¼šä½¿ç”¨SequenceMatcher
            return SequenceMatcher(None, text1.lower().strip(), text2.lower().strip()).ratio()
    
    @staticmethod
    def _calculate_character_ratio_similarity(ai_chunk: str, expected_segment: str, expected_segments: List[str] = None) -> float:
        """è¨ˆç®—å­—ç¬¦æ¯”ä¾‹ç›¸ä¼¼åº¦ï¼šåŒ¹é…å­—ç¬¦æ•¸ / æ‡‰åƒè€ƒçš„æ–‡ä»¶ç¯€é»ç¸½é•·åº¦
        
        Args:
            ai_chunk: AIå›è¦†çš„æ–‡å­—æ®µè½
            expected_segment: é æœŸçš„æ–‡å­—æ®µè½
            expected_segments: æ‰€æœ‰é æœŸæ®µè½åˆ—è¡¨
        """
        if not ai_chunk or not expected_segment:
            return 0.0
            
        # é è™•ç†æ–‡å­—
        ai_text = ai_chunk.lower().strip()
        expected_text = expected_segment.lower().strip()
        
        # è¨ˆç®—åŒ¹é…çš„å­—ç¬¦æ•¸
        matcher = SequenceMatcher(None, ai_text, expected_text)
        matching_blocks = matcher.get_matching_blocks()
        matched_chars = sum(block.size for block in matching_blocks)
        
        # è¨ˆç®—æ‡‰åƒè€ƒçš„æ–‡ä»¶ç¯€é»ç¸½é•·åº¦
        if expected_segments:
            total_expected_length = sum(len(seg.strip()) for seg in expected_segments)
        else:
            total_expected_length = len(expected_text)
        
        # é¿å…é™¤é›¶éŒ¯èª¤
        if total_expected_length == 0:
            return 0.0
            
        # è¨ˆç®—æ¯”ä¾‹
        ratio = matched_chars / total_expected_length
        
        # ç¢ºä¿çµæœåœ¨0-1ä¹‹é–“
        return min(1.0, max(0.0, ratio))
    
    @staticmethod
    def contains_keywords(text: str, keywords: str) -> bool:
        """æª¢æŸ¥æ–‡å­—æ˜¯å¦åŒ…å«é—œéµè©ï¼ˆæ”¯æŒå¤šå€‹é—œéµè©ï¼Œç”¨é€—è™Ÿåˆ†éš”ï¼‰"""
        if not keywords:
            return False
        text_lower = text.lower()
        keyword_list = [kw.strip() for kw in keywords.split(',') if kw.strip()]
        return any(keyword.lower() in text_lower for keyword in keyword_list)
    
    @staticmethod
    def parse_expected_segments(expected_content: str, custom_separators: List[str] = None) -> List[str]:
        """è§£æé æœŸæ–‡ä»¶æ®µè½ï¼ˆæ”¯æ´å¤šå€‹æ®µè½å’Œè‡ªå®šç¾©åˆ†éš”ç¬¦ï¼‰"""
        if not expected_content:
            return []
        
        # æ”¯æ´å¤šç¨®åˆ†éš”æ–¹å¼ï¼ˆé è¨­ï¼‰
        default_separators = ['---', '|||', '\n\n']
        separators = custom_separators if custom_separators else default_separators
        
        segments = [expected_content]
        for sep in separators:
            new_segments = []
            for segment in segments:
                parts = segment.split(sep)
                new_segments.extend([s.strip() for s in parts if s.strip()])
            segments = new_segments
        
        return segments if len(segments) > 1 else [expected_content.strip()]
    
    @classmethod
    def check_citation_hit(cls, citation_nodes: List[Dict], expected_content: str, similarity_threshold: float = 0.3) -> Tuple[bool, str]:
        """æª¢æŸ¥å¼•ç”¨ç¯€é»å‘½ä¸­ï¼ˆå‘å¾Œå…¼å®¹æ–¹æ³•ï¼‰"""
        if not citation_nodes or not expected_content:
            return False, "ç„¡å¼•ç”¨ç¯€é»æˆ–é æœŸå…§å®¹ç‚ºç©º"
        
        best_match_score = 0.0
        best_match_content = ""
        
        for node in citation_nodes:
            if 'chatbotTextNode' in node and 'text' in node['chatbotTextNode']:
                node_content = node['chatbotTextNode']['text']
            elif 'chatbotTextNode' in node and 'content' in node['chatbotTextNode']:
                node_content = node['chatbotTextNode']['content']
            else:
                continue
                
            similarity = cls.calculate_similarity(node_content, expected_content)  # ä½¿ç”¨é è¨­standardæ¨¡å¼

                
            

                
            if similarity > best_match_score:
                best_match_score = similarity
                best_match_content = node_content
        
        is_hit = best_match_score >= similarity_threshold
        result_detail = f"æœ€ä½³åŒ¹é…åˆ†æ•¸: {best_match_score:.2f}"
        
        return is_hit, result_detail
    
    @classmethod
    def check_rag_enhanced_hit(cls, citation_nodes: List[Dict], expected_content: str, 
                             similarity_threshold: float = 0.3, top_k: Optional[int] = None,
                             custom_separators: List[str] = None, similarity_mode: str = "standard") -> Tuple[bool, Dict]:
        """RAG å¢å¼·çš„å‘½ä¸­æª¢æŸ¥ï¼Œæ”¯æ´å¤šæ®µè½å’Œè©³ç´°æŒ‡æ¨™"""
        if not citation_nodes or not expected_content:
            return False, {
                "error": "ç„¡å¼•ç”¨ç¯€é»æˆ–é æœŸå…§å®¹ç‚ºç©º",
                "hit_rate": 0.0,
                "hit_count": 0,
                "total_expected": 0,
                "total_chunks": 0,
                "precision": 0.0,
                "recall": 0.0,
                "f1_score": 0.0
            }
        
        # è§£æé æœŸæ®µè½
        expected_segments = cls.parse_expected_segments(expected_content, custom_separators)
        if not expected_segments:
            # å¦‚æœè§£æå¤±æ•—ï¼Œä½¿ç”¨åŸå§‹é‚è¼¯
            is_hit, detail = cls.check_citation_hit(citation_nodes, expected_content, similarity_threshold)
            return is_hit, {
                "hit_rate": 1.0 if is_hit else 0.0,
                "hit_count": 1 if is_hit else 0,
                "total_expected": 1,
                "total_chunks": len(citation_nodes),
                "precision": 1.0 if is_hit else 0.0,
                "recall": 1.0 if is_hit else 0.0,
                "f1_score": 1.0 if is_hit else 0.0,
                "detail": detail
            }
        
        # æå– RAG chunksï¼ˆå‹•æ…‹ä½¿ç”¨æ‰€æœ‰å¯ç”¨ç¯€é»æˆ–æŒ‡å®šæ•¸é‡ï¼‰
        effective_top_k = top_k if top_k is not None else len(citation_nodes)
        rag_chunks = []
        for i, node in enumerate(citation_nodes[:effective_top_k]):
            if 'chatbotTextNode' in node and 'text' in node['chatbotTextNode']:
                chunk_content = node['chatbotTextNode']['text']
            elif 'chatbotTextNode' in node and 'content' in node['chatbotTextNode']:
                chunk_content = node['chatbotTextNode']['content']
            else:
                continue
            
            rag_chunks.append({
                'index': i,
                'content': chunk_content,
                'matched': False
            })
        
        if not rag_chunks:
            return False, {
                "error": "ç„¡æœ‰æ•ˆçš„ RAG chunks",
                "hit_rate": 0.0,
                "hit_count": 0,
                "total_expected": len(expected_segments),
                "total_chunks": 0,
                "precision": 0.0,
                "recall": 0.0,
                "f1_score": 0.0
            }
        
        # è¨ˆç®—åŒ¹é…
        hit_count = 0
        matches = []
        
        for exp_idx, expected_seg in enumerate(expected_segments):
            segment_hit = False
            best_match = {"chunk_idx": -1, "similarity": 0.0}
            
            for chunk in rag_chunks:
                similarity = cls.calculate_similarity(chunk['content'], expected_seg, similarity_mode, expected_segments)
                
                if similarity >= similarity_threshold:
                    if not segment_hit:  # ç¬¬ä¸€æ¬¡æ‰¾åˆ°åŒ¹é…
                        hit_count += 1
                        segment_hit = True
                        chunk['matched'] = True
                    
                    if similarity > best_match['similarity']:
                        best_match = {
                            'chunk_idx': chunk['index'],
                            'similarity': similarity
                        }
            
            if segment_hit:
                matches.append({
                    'expected_idx': exp_idx,
                    'expected_segment': expected_seg[:50] + "..." if len(expected_seg) > 50 else expected_seg,
                    'best_match': best_match
                })
        
        # è¨ˆç®—è©³ç´°æŒ‡æ¨™
        relevant_chunks = sum(1 for chunk in rag_chunks if chunk['matched'])
        precision = relevant_chunks / len(rag_chunks) if rag_chunks else 0.0
        recall = hit_count / len(expected_segments) if expected_segments else 0.0
        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0
        hit_rate = hit_count / len(expected_segments) if expected_segments else 0.0
        
        is_hit = hit_rate > 0
        
        result = {
            "hit_rate": hit_rate,
            "hit_count": hit_count,
            "total_expected": len(expected_segments),
            "total_chunks": len(rag_chunks),
            "precision": precision,
            "recall": recall,
            "f1_score": f1_score,
            "relevant_chunks": relevant_chunks,
            "threshold_used": similarity_threshold,
            "top_k_used": top_k,
            "matches": matches
        }
        
        return is_hit, result
    
    @classmethod
    def check_citation_file_match(cls, citations: List[Dict], expected_files: str) -> Tuple[bool, Dict]:
        """æª¢æŸ¥åƒè€ƒæ–‡ä»¶æ˜¯å¦æ­£ç¢ºï¼ˆåƒ…æ”¯æ´UUIDåŒ¹é…ï¼Œé€—è™Ÿå’Œæ›è¡Œç¬¦åˆ†å‰²ï¼Œå…¨éƒ¨å‘½ä¸­åˆ¶ï¼‰"""
        if not citations or not expected_files:
            return False, {
                "detail": "ç„¡å¼•ç”¨æ–‡ä»¶æˆ–é æœŸæ–‡ä»¶ç‚ºç©º",
                "total_expected": 0,
                "total_matched": 0,
                "hit_rate": 0.0,
                "matched_files": [],
                "unmatched_files": [],
                "all_matched": False
            }
        
        # å…ˆç”¨æ›è¡Œç¬¦åˆ†å‰²ï¼Œå†ç”¨é€—è™Ÿåˆ†å‰²ï¼Œå»é™¤é‡è¤‡
        expected_file_list = []
        
        # å…ˆæŒ‰æ›è¡Œç¬¦åˆ†å‰²
        lines = expected_files.split('\n')
        for line in lines:
            line = line.strip()
            if line:
                # æ¯è¡Œå…§éƒ¨å¯èƒ½é‚„æœ‰é€—è™Ÿåˆ†å‰²çš„æ–‡ä»¶
                files_in_line = [f.strip() for f in line.split(',') if f.strip()]
                expected_file_list.extend(files_in_line)
        
        # å»é™¤é‡è¤‡çš„æ–‡ä»¶åç¨±/UUID
        expected_file_list = list(set(expected_file_list))
        
        # æ”¶é›†å¼•ç”¨æ–‡ä»¶çš„UUID
        cited_uuids = []
        
        for citation in citations:
            if 'id' in citation:
                cited_uuids.append(citation['id'])
        
        # è¨˜éŒ„æ¯å€‹æœŸæœ›æ–‡ä»¶çš„åŒ¹é…æƒ…æ³
        matched_expected_files = set()
        matches = []
        
        for expected_file in expected_file_list:
            # åªé€²è¡ŒUUIDç²¾ç¢ºåŒ¹é…
            if expected_file in cited_uuids:
                matches.append(f"{expected_file} -> UUIDåŒ¹é…")
                matched_expected_files.add(expected_file)
        
        # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
        total_expected = len(expected_file_list)
        total_matched = len(matched_expected_files)
        hit_rate = total_matched / total_expected if total_expected > 0 else 0.0
        
        # æ‰¾å‡ºæœªåŒ¹é…çš„æ–‡ä»¶
        unmatched_files = [f for f in expected_file_list if f not in matched_expected_files]
        
        # æ–°çš„åˆ¤æ–·é‚è¼¯ï¼šæ‰€æœ‰æœŸæœ›æ–‡ä»¶éƒ½å¿…é ˆè¢«åŒ¹é…
        all_matched = total_matched == total_expected
        is_correct = all_matched
        
        result_detail = {
            "detail": f"åŒ¹é…æ–‡ä»¶: {total_matched}/{total_expected} å€‹ (å‘½ä¸­ç‡: {hit_rate:.1%})",
            "total_expected": total_expected,
            "total_matched": total_matched,
            "hit_rate": hit_rate,
            "matched_files": list(matched_expected_files),
            "unmatched_files": unmatched_files,
            "all_matched": all_matched,
            "matches": matches
        }
        
        return is_correct, result_detail


class ScrollableFrame(ttk.Frame):
    """å¯æ»¾å‹•çš„æ¡†æ¶çµ„ä»¶"""
    
    def __init__(self, parent, *args, **kwargs):
        super().__init__(parent, *args, **kwargs)
        
        # å‰µå»º Canvas å’Œ Scrollbar
        self.canvas = tk.Canvas(self, highlightthickness=0)
        self.scrollbar = ttk.Scrollbar(self, orient="vertical", command=self.canvas.yview)
        self.scrollable_frame = ttk.Frame(self.canvas)
        
        # é…ç½®æ»¾å‹•å€åŸŸ
        self.scrollable_frame.bind(
            "<Configure>",
            lambda e: self.canvas.configure(scrollregion=self.canvas.bbox("all"))
        )
        
        # å‰µå»ºcanvasçª—å£
        self.canvas_window = self.canvas.create_window((0, 0), window=self.scrollable_frame, anchor="nw")
        
        # é…ç½®canvasçš„yscrollcommand
        self.canvas.configure(yscrollcommand=self.scrollbar.set)
        
        # å¸ƒå±€
        self.canvas.pack(side="left", fill="both", expand=True)
        self.scrollbar.pack(side="right", fill="y")
        
        # ç¶å®šcanvaså¯¬åº¦èª¿æ•´
        self.canvas.bind('<Configure>', self._on_canvas_configure)
        
        # ç¶å®šæ»‘é¼ æ»¾è¼ªäº‹ä»¶
        self._bind_mousewheel()
    
    def _on_canvas_configure(self, event):
        """ç•¶canvaså¤§å°æ”¹è®Šæ™‚èª¿æ•´scrollable_frameçš„å¯¬åº¦"""
        canvas_width = event.width
        self.canvas.itemconfig(self.canvas_window, width=canvas_width)
    
    def _bind_mousewheel(self):
        """ç¶å®šæ»‘é¼ æ»¾è¼ªäº‹ä»¶ï¼ˆæ”¯æ´ Windows å’Œ macOSï¼‰"""
        # é˜²æ­¢é‡è¤‡ç¶å®šçš„æ¨™è¨˜
        self._mousewheel_bound = False
        
        def _on_mousewheel(event):
            # æª¢æŸ¥æ»¾å‹•æ¢æ˜¯å¦å¯è¦‹/éœ€è¦
            if self.canvas.bbox("all"):
                canvas_height = self.canvas.winfo_height()
                content_height = self.canvas.bbox("all")[3]
                if content_height > canvas_height:
                    # Windows æ»¾è¼ªäº‹ä»¶
                    if event.delta:
                        self.canvas.yview_scroll(int(-1 * (event.delta / 120)), "units")
                    # macOS æ»¾è¼ªäº‹ä»¶
                    elif event.num == 4:
                        self.canvas.yview_scroll(-1, "units")
                    elif event.num == 5:
                        self.canvas.yview_scroll(1, "units")
        
        def _bind_to_mousewheel(event):
            # é¿å…é‡è¤‡ç¶å®š
            if not self._mousewheel_bound:
                self.canvas.bind_all("<MouseWheel>", _on_mousewheel)
                # macOS æ»¾è¼ªäº‹ä»¶
                self.canvas.bind_all("<Button-4>", _on_mousewheel)
                self.canvas.bind_all("<Button-5>", _on_mousewheel)
                self._mousewheel_bound = True
        
        def _unbind_from_mousewheel(event):
            if self._mousewheel_bound:
                self.canvas.unbind_all("<MouseWheel>")
                # macOS æ»¾è¼ªäº‹ä»¶
                self.canvas.unbind_all("<Button-4>")
                self.canvas.unbind_all("<Button-5>")
                self._mousewheel_bound = False
        
        # æ»‘é¼ é€²å…¥å’Œé›¢é–‹æ™‚ç¶å®š/è§£ç¶æ»¾è¼ªäº‹ä»¶
        self.canvas.bind('<Enter>', _bind_to_mousewheel)
        self.canvas.bind('<Leave>', _unbind_from_mousewheel)


class MaiAgentValidatorGUI:
    """MaiAgent é©—è­‰å·¥å…· GUI ä¸»é¡"""
    
    def __init__(self):
        self.root = tk.Tk()
        self.root.title(f"{__app_name__} v{__version__} - RAG å¢å¼·ç‰ˆ")
        self.root.geometry("900x700")
        self.root.resizable(True, True)
        
        # ä¿®å¾© macOS å‰ªè²¼æ¿å’Œäº‹ä»¶é‡è¤‡å•é¡Œ
        self._setup_macos_fixes()
        
        # è¨­å®šæ¨£å¼
        self.style = ttk.Style()
        self.style.theme_use('clam')
        
        # ç²å–ä¸»é¡ŒèƒŒæ™¯è‰²ç”¨æ–¼ tk çµ„ä»¶
        self.bg_color = self.style.lookup('TFrame', 'background') or self.root.cget('bg')
        
        # è®Šæ•¸
        self.csv_file_path = tk.StringVar()
        self.api_base_url = tk.StringVar(value="http://localhost:8000")
        self.api_key = tk.StringVar()
        self.similarity_threshold = tk.DoubleVar(value=0.3)
        self.max_concurrent = tk.IntVar(value=5)
        self.api_delay = tk.DoubleVar(value=1.0)  # API å‘¼å«é–“éš”å»¶é²æ™‚é–“ï¼ˆç§’ï¼‰
        self.max_retries = tk.IntVar(value=3)  # API è«‹æ±‚é‡è©¦æ¬¡æ•¸
        # å›ºå®šä½¿ç”¨ RAG æ¨¡å¼ï¼Œä¸å†æä¾›é–‹é—œ
        self.top_k = None  # å‹•æ…‹ï¼šæ ¹æ“š API å›å‚³çš„å¼•ç”¨ç¯€é»æ•¸é‡æ±ºå®š
        self.selected_chatbot_id = None
        self.validation_data = []
        self.conversation_manager = ConversationManager()
        self.text_matcher = EnhancedTextMatcher()
        
        # query_metadata ç›¸é—œåƒæ•¸
        self.knowledge_base_id = tk.StringVar()
        self.label_id = tk.StringVar()
        self.enable_query_metadata = tk.BooleanVar(value=False)
        
        # ä¸Šä¸‹æ–‡çµ„åˆç›¸é—œåƒæ•¸
        self.enable_context_combination = tk.BooleanVar(value=True)
        
        # é©—è­‰æ§åˆ¶è®Šæ•¸
        self.validation_stopped = False
        self.completed_questions = 0
        
        # æ®µè½åˆ†éš”ç¬¦è¨­å®š
        self.separator_vars = {
            '---': tk.BooleanVar(value=True),      # ä¸‰å€‹é€£å­—ç¬¦
            '|||': tk.BooleanVar(value=True),      # ä¸‰å€‹è±ç·š
            '\n\n': tk.BooleanVar(value=True),     # é›™æ›è¡Œ
            '###': tk.BooleanVar(value=False),     # ä¸‰å€‹äº•è™Ÿ
            '===': tk.BooleanVar(value=False),     # ä¸‰å€‹ç­‰è™Ÿ
            '...': tk.BooleanVar(value=False),     # ä¸‰å€‹é»
        }
        
        # ç›¸ä¼¼åº¦è¨ˆç®—æ¨¡å¼è¨­å®š
        self.similarity_mode = tk.StringVar(value="standard")  # standard æˆ– character_ratio
        
        # çµ„ç¹”ç®¡ç†ç›¸é—œè®Šæ•¸
        self.org_export_api_key = tk.StringVar()
        self.org_export_base_url = tk.StringVar(value="https://api.maiagent.ai/api/v1/")
        self.deploy_csv_file = tk.StringVar()
        self.deploy_api_key = tk.StringVar()
        self.deploy_base_url = tk.StringVar(value="http://localhost:8000/api/v1/")
        self.deploy_org_name = tk.StringVar()
        self.deploy_create_users = tk.BooleanVar(value=False)
        self.deploy_referral_code = tk.StringVar()
        self.current_deployment_task = None
        self.export_organizations = []
        self.selected_export_org_id = None
        
        # çŸ¥è­˜åº«ç®¡ç†ç›¸é—œè®Šæ•¸
        self.kb_api_key = tk.StringVar()
        self.kb_base_url = tk.StringVar(value="http://localhost:8000/api/v1/")
        self.kb_export_dir = tk.StringVar()
        self.knowledge_bases = []
        self.selected_kb_id = None
        self.kb_files = []
        self.selected_files = {}  # ç”¨æ–¼å­˜å„²æ–‡ä»¶é¸æ“‡ç‹€æ…‹
        
        # æ—¥èªŒç®¡ç†
        self.gui_logger = logging.getLogger(f"{__name__}.GUI")
        self.api_logger = logging.getLogger(f"{__name__}.API")
        self.validation_logger = logging.getLogger(f"{__name__}.Validation")
        
        # GUI é‹è¡Œç‹€æ…‹æ¨™èªŒ
        self.gui_running = True
        self._in_logger_callback = False
        self._in_log_message = False
        
        # æ—¥èªŒé™æµæ©Ÿåˆ¶ - æ›´åš´æ ¼çš„æ§åˆ¶
        self._log_queue_size = 0
        self._max_concurrent_logs = 2  # é™ä½åˆ°2å€‹ä¸¦ç™¼
        self._last_log_time = 0
        self._log_throttle_active = False
        self._emergency_throttle = False  # ç·Šæ€¥é™æµæ¨™èªŒ
        self._consecutive_errors = 0  # é€£çºŒéŒ¯èª¤è¨ˆæ•¸
        
        # ç°¡åŒ–æ—¥èªŒå‡½æ•¸ï¼ˆç·Šæ€¥ä½¿ç”¨ï¼‰
        self._emergency_log = lambda msg: print(f"[EMERGENCY] {msg}") if hasattr(self, '_emergency_throttle') and self._emergency_throttle else None
        
        # éœé»˜æ¨¡å¼ - å®Œå…¨ç¦ç”¨GUIæ—¥èªŒæ›´æ–°
        self._silent_mode = False
        self._simple_console_log = lambda msg: print(f"[SIMPLE] {msg}")
        self._download_in_progress = False
        
        self.create_widgets()
        
        # è¨˜éŒ„å•Ÿå‹•æ—¥èªŒ
        self.log_info(f"{__app_name__} v{__version__} å·²å•Ÿå‹•")
        self.log_info(f"æ—¥èªŒç³»çµ±å·²åˆå§‹åŒ–ï¼Œæ—¥èªŒç›®éŒ„: {Path('logs').absolute()}")
    
    def _setup_macos_fixes(self):
        """è¨­å®š macOS ç‰¹å®šçš„ä¿®å¾©"""
        if platform.system() == 'Darwin':  # macOS
            # è¨­å®šå‰ªè²¼æ¿æ›´æ–°é–“éš”
            self.root.after(100, self._periodic_clipboard_update)
            
            # ä¿®å¾©æ–‡æœ¬çµ„ä»¶çš„é‡è¤‡è¼¸å…¥å•é¡Œ
            self.root.option_add('*Text.highlightThickness', 1)
            
    def _periodic_clipboard_update(self):
        """å®šæœŸæ›´æ–°å‰ªè²¼æ¿ç‹€æ…‹ä»¥é˜²æ­¢é‡è¤‡ï¼ˆç·šç¨‹å®‰å…¨ï¼‰"""
        if not self.gui_running:
            return
            
        try:
            # å®šæœŸæ¸…ç†å‰ªè²¼æ¿ç‹€æ…‹ï¼Œä½†åªåœ¨ GUI é‹è¡Œæ™‚
            if self.gui_running:
                self.root.after(1000, self._periodic_clipboard_update)
        except:
            pass
    
    def api_logger_callback(self, method_name, *args, **kwargs):
        """APIæ—¥èªŒå›èª¿å‡½æ•¸ - å•Ÿç”¨è©³ç´°æ—¥èªŒç‰ˆæœ¬ï¼ˆå¸¶å®‰å…¨ä¿è­·ï¼‰"""
        
        # æª¢æŸ¥æ˜¯å¦å·²åˆå§‹åŒ–å®Œæˆï¼Œé¿å…åˆå§‹åŒ–æœŸé–“çš„èª¿ç”¨
        if not hasattr(self, 'root') or not hasattr(self, 'log_text'):
            return
        
        # ä¸‹è¼‰æœŸé–“éœé»˜æ¨¡å¼ - å®Œå…¨ç¦ç”¨APIæ—¥èªŒè™•ç†
        if getattr(self, '_download_in_progress', False):
            # å®Œå…¨è·³éAPIæ—¥èªŒè™•ç†ï¼Œé¿å…ä»»ä½•GUIæ›´æ–°
            return
        
        # é˜²æ­¢éæ­¸èª¿ç”¨å’Œ GUI é—œé–‰å¾Œçš„èª¿ç”¨
        if not getattr(self, 'gui_running', True):
            return
            
        # æ·»åŠ éæ­¸ä¿è­·
        if getattr(self, '_in_logger_callback', False):
            return
            
        # å¢å¼·ç·Šæ€¥é™æµæª¢æŸ¥
        if getattr(self, '_emergency_throttle', False):
            return
            
        # æ—¥èªŒé™æµ - APIæ—¥èªŒæ¿€é€²é™åˆ¶
        if getattr(self, '_log_queue_size', 0) > 0:  # APIæ—¥èªŒä¸å…è¨±ä»»ä½•ä¸¦ç™¼
            return
            
        # æ·»åŠ èª¿ç”¨æ·±åº¦æª¢æŸ¥
        try:
            frame_count = len([frame for frame in __import__('inspect').stack()])
            if frame_count > 30:  # é™ä½é–¾å€¼ï¼Œæ›´æ—©è¿”å›
                return
        except:
            # å¦‚æœæª¢æŸ¥å¤±æ•—ï¼Œè¿”å›è€Œä¸æ˜¯ç¹¼çºŒ
            return
            
        try:
            self._in_logger_callback = True
            
            if method_name == 'log_api_request' and len(args) >= 2:
                url, method = args[0], args[1]
                payload = args[2] if len(args) > 2 else None
                try:
                    self.log_api_request(url, method, payload)
                except:
                    # å¦‚æœæ—¥èªŒå¤±æ•—ï¼Œç›´æ¥æ‰“å°
                    print(f"APIè«‹æ±‚: {method} {url}")
            elif method_name == 'log_api_response' and len(args) >= 2:
                url, status_code = args[0], args[1]
                response_size = args[2] if len(args) > 2 else 0
                duration = args[3] if len(args) > 3 else None
                try:
                    self.log_api_response(url, status_code, response_size, duration)
                except:
                    # å¦‚æœæ—¥èªŒå¤±æ•—ï¼Œç›´æ¥æ‰“å°
                    print(f"APIå›æ‡‰: {url} | ç‹€æ…‹ç¢¼: {status_code}")
            elif method_name == 'log_info' and len(args) >= 1:
                message = args[0]
                logger_name = args[1] if len(args) > 1 else 'API'
                try:
                    self.log_info(message, logger_name)
                except:
                    # å¦‚æœæ—¥èªŒå¤±æ•—ï¼Œç›´æ¥æ‰“å°
                    print(f"INFO: {message}")
            elif method_name == 'log_error' and len(args) >= 1:
                message = args[0]
                logger_name = args[1] if len(args) > 1 else 'API'
                try:
                    self.log_error(message, logger_name)
                except:
                    # å¦‚æœæ—¥èªŒå¤±æ•—ï¼Œç›´æ¥æ‰“å°
                    print(f"ERROR: {message}")
        except Exception as e:
            # å®Œå…¨éœé»˜çš„éŒ¯èª¤è™•ç†ï¼Œé¿å…ä»»ä½•å¯èƒ½çš„éæ­¸èª¿ç”¨
            # åªæœ‰åœ¨é–‹ç™¼æ¨¡å¼ä¸‹æ‰æ‰“å°
            try:
                print(f"Logger callback silent error: {type(e).__name__}")
            except:
                pass
        finally:
            self._in_logger_callback = False
    
    def create_widgets(self):
        """å‰µå»º GUI çµ„ä»¶"""
        # å‰µå»ºç­†è¨˜æœ¬æ¨™ç±¤é 
        notebook = ttk.Notebook(self.root)
        notebook.pack(fill='both', expand=True, padx=10, pady=10)
        
        # è¨­å®šé é¢
        self.create_settings_tab(notebook)
        
        # é©—è­‰é é¢
        self.create_validation_tab(notebook)
        
        # çµæœé é¢
        self.create_results_tab(notebook)
        
        # çµ„ç¹”ç®¡ç†é é¢
        self.create_organization_tab(notebook)
        
    def create_settings_tab(self, notebook):
        """å‰µå»ºè¨­å®šæ¨™ç±¤é ï¼ˆå¸¶æ»¾å‹•æ¢ï¼‰"""
        settings_frame = ttk.Frame(notebook)
        notebook.add(settings_frame, text="è¨­å®š")
        
        # å‰µå»ºå¯æ»¾å‹•çš„ä¸»æ¡†æ¶
        scrollable_container = ScrollableFrame(settings_frame)
        scrollable_container.pack(fill='both', expand=True, padx=10, pady=10)
        
        # ä¸»æ¡†æ¶ï¼ˆåœ¨æ»¾å‹•å€åŸŸå…§ï¼‰
        main_frame = scrollable_container.scrollable_frame
        
        # æ·»åŠ å…§é‚Šè·
        padding_frame = ttk.Frame(main_frame)
        padding_frame.pack(fill='both', expand=True, padx=10, pady=10)
        
        # æ–‡ä»¶é¸æ“‡
        file_frame = ttk.LabelFrame(padding_frame, text="æ¸¬è©¦æ–‡ä»¶", padding=10)
        file_frame.pack(fill='x', pady=(0, 10))
        
        ttk.Label(file_frame, text="æ¸¬è©¦æ–‡ä»¶è·¯å¾‘ (CSV/Excel)ï¼š").pack(anchor='w')
        file_path_frame = ttk.Frame(file_frame)
        file_path_frame.pack(fill='x', pady=(5, 0))
        
        ttk.Entry(file_path_frame, textvariable=self.csv_file_path, width=60).pack(side='left', fill='x', expand=True)
        ttk.Button(file_path_frame, text="ç€è¦½", command=self.browse_csv_file).pack(side='right', padx=(5, 0))
        
        # API è¨­å®š
        api_frame = ttk.LabelFrame(padding_frame, text="API è¨­å®š", padding=10)
        api_frame.pack(fill='x', pady=(0, 10))
        
        ttk.Label(api_frame, text="API åŸºç¤ URLï¼š").pack(anchor='w')
        ttk.Entry(api_frame, textvariable=self.api_base_url, width=60).pack(fill='x', pady=(5, 10))
        
        ttk.Label(api_frame, text="API é‡‘é‘°ï¼š").pack(anchor='w')
        ttk.Entry(api_frame, textvariable=self.api_key, width=60, show="*").pack(fill='x', pady=(5, 0))
        
        # Query Metadata è¨­å®š
        query_metadata_frame = ttk.LabelFrame(padding_frame, text="æŸ¥è©¢å…ƒæ•¸æ“šè¨­å®š (Query Metadata)", padding=10)
        query_metadata_frame.pack(fill='x', pady=(0, 10))
        
        # å•Ÿç”¨/åœç”¨ query_metadata
        enable_checkbox = tk.Checkbutton(
            query_metadata_frame,
            text="å•Ÿç”¨ Query Metadataï¼ˆæŒ‡å®šçŸ¥è­˜åº«å’Œæ¨™ç±¤éæ¿¾ï¼‰",
            variable=self.enable_query_metadata,
            indicatoron=1,
            relief='flat',
            borderwidth=0,
            highlightthickness=0,
            bg=self.bg_color,
            activebackground=self.bg_color,
            font=('Arial', 9),
            cursor='hand2',
            anchor='w',
            pady=2,
            command=self.on_query_metadata_toggle
        )
        enable_checkbox.pack(anchor='w', pady=(0, 10))
        
        # çŸ¥è­˜åº«IDè¼¸å…¥
        self.kb_id_frame = ttk.Frame(query_metadata_frame)
        self.kb_id_frame.pack(fill='x', pady=(0, 5))
        
        ttk.Label(self.kb_id_frame, text="çŸ¥è­˜åº« IDï¼š").pack(anchor='w')
        kb_id_entry = ttk.Entry(self.kb_id_frame, textvariable=self.knowledge_base_id, width=60)
        kb_id_entry.pack(fill='x', pady=(5, 0))
        
        # æ¨™ç±¤IDè¼¸å…¥
        self.label_id_frame = ttk.Frame(query_metadata_frame)
        self.label_id_frame.pack(fill='x', pady=(0, 5))
        
        ttk.Label(self.label_id_frame, text="æ¨™ç±¤ IDï¼ˆé¸å¡«ï¼‰ï¼š").pack(anchor='w')
        label_id_entry = ttk.Entry(self.label_id_frame, textvariable=self.label_id, width=60)
        label_id_entry.pack(fill='x', pady=(5, 0))
        
        # èªªæ˜æ–‡å­—
        help_text = ttk.Label(
            query_metadata_frame,
            text="  â†³ çŸ¥è­˜åº«IDå’Œæ¨™ç±¤IDç”¨æ–¼é™åˆ¶RAGæª¢ç´¢ç¯„åœã€‚ä¸å¡«å¯«æ¨™ç±¤IDå‰‡ä½¿ç”¨çŸ¥è­˜åº«æ‰€æœ‰å…§å®¹ã€‚",
            font=('Arial', 8),
            foreground='gray'
        )
        help_text.pack(anchor='w', pady=(5, 0))
        
        # åˆå§‹ç‹€æ…‹è¨­å®šç‚ºåœç”¨
        self.on_query_metadata_toggle()
        
        # ä¸Šä¸‹æ–‡çµ„åˆè¨­å®š
        context_frame = ttk.LabelFrame(padding_frame, text="å°è©±ä¸Šä¸‹æ–‡è¨­å®š", padding=10)
        context_frame.pack(fill='x', pady=(0, 10))
        
        # å•Ÿç”¨/åœç”¨ä¸Šä¸‹æ–‡çµ„åˆ
        context_checkbox = tk.Checkbutton(
            context_frame,
            text="å•Ÿç”¨åŒä¸€æå•è€…å•é¡Œä¸Šä¸‹æ–‡çµ„åˆ",
            variable=self.enable_context_combination,
            indicatoron=1,
            relief='flat',
            borderwidth=0,
            highlightthickness=0,
            bg=self.bg_color,
            activebackground=self.bg_color,
            font=('Arial', 9),
            cursor='hand2',
            anchor='w',
            pady=2
        )
        context_checkbox.pack(anchor='w', pady=(0, 5))
        
        # èªªæ˜æ–‡å­—
        context_help = ttk.Label(
            context_frame,
            text="  â†³ ç•¶åŒä¸€æå•è€…æœ‰å¤šå€‹å•é¡Œæ™‚ï¼Œåœ¨é–‹å§‹æ–°å°è©±æ™‚æœƒå°‡å‰é¢çš„å•é¡Œä¸€èµ·ç™¼é€çµ¦AIä½œç‚ºä¸Šä¸‹æ–‡",
            font=('Arial', 8),
            foreground='gray'
        )
        context_help.pack(anchor='w', pady=(0, 0))
        
        # é©—è­‰åƒæ•¸
        param_frame = ttk.LabelFrame(padding_frame, text="é©—è­‰åƒæ•¸", padding=10)
        param_frame.pack(fill='x', pady=(0, 10))
        
        # ç³»çµ±å›ºå®šä½¿ç”¨ RAG å¢å¼·æ¨¡å¼ï¼Œæª¢ç´¢ç‰‡æ®µæ•¸é‡å‹•æ…‹èª¿æ•´
        
        # ç›¸ä¼¼åº¦è¨ˆç®—æ¨¡å¼é¸æ“‡
        ttk.Label(param_frame, text="ç›¸ä¼¼åº¦è¨ˆç®—æ¨¡å¼ï¼š").pack(anchor='w', pady=(0, 5))
        similarity_mode_frame = ttk.Frame(param_frame)
        similarity_mode_frame.pack(fill='x', pady=(0, 10))
        
        ttk.Radiobutton(similarity_mode_frame, text="æ¨™æº–æ¨¡å¼ (SequenceMatcher)", 
                       variable=self.similarity_mode, value="standard").pack(anchor='w')
        ttk.Radiobutton(similarity_mode_frame, text="å­—ç¬¦æ¯”ä¾‹æ¨¡å¼ (åŒ¹é…å­—ç¬¦æ•¸/æ‡‰åƒè€ƒç¯€é»)", 
                       variable=self.similarity_mode, value="character_ratio").pack(anchor='w')
        
        # æ·»åŠ æ¨¡å¼èªªæ˜
        mode_help = ttk.Label(param_frame, text="  â†³ æ¨™æº–æ¨¡å¼ï¼šåŸºæ–¼æœ€é•·å…¬å…±å­åºåˆ— | å­—ç¬¦æ¯”ä¾‹æ¨¡å¼ï¼šåŒ¹é…å­—ç¬¦æ•¸é™¤ä»¥é æœŸæ®µè½ç¸½é•·åº¦", 
                             font=('Arial', 8), foreground='gray')
        mode_help.pack(anchor='w', pady=(0, 10))
        
        ttk.Label(param_frame, text="ç›¸ä¼¼åº¦é–¾å€¼ (0.0-1.0)ï¼š").pack(anchor='w')
        ttk.Scale(param_frame, from_=0.0, to=1.0, variable=self.similarity_threshold, orient='horizontal').pack(fill='x', pady=(5, 5))
        threshold_label = ttk.Label(param_frame, text="")
        threshold_label.pack(anchor='w')
        self.similarity_threshold.trace_add('write', lambda *args: threshold_label.config(text=f"ç•¶å‰å€¼: {self.similarity_threshold.get():.2f}"))
        
        ttk.Label(param_frame, text="æœ€å¤§ä¸¦ç™¼æå•è€…æ•¸ï¼š").pack(anchor='w')
        ttk.Scale(param_frame, from_=1, to=20, variable=self.max_concurrent, orient='horizontal').pack(fill='x', pady=(5, 5))
        concurrent_label = ttk.Label(param_frame, text="")
        concurrent_label.pack(anchor='w')
        self.max_concurrent.trace_add('write', lambda *args: concurrent_label.config(text=f"ç•¶å‰å€¼: {self.max_concurrent.get()}"))
        
        ttk.Label(param_frame, text="API å‘¼å«å»¶é²æ™‚é–“ (ç§’)ï¼š").pack(anchor='w', pady=(10, 0))
        ttk.Scale(param_frame, from_=0.0, to=5.0, variable=self.api_delay, orient='horizontal').pack(fill='x', pady=(5, 5))
        delay_label = ttk.Label(param_frame, text="")
        delay_label.pack(anchor='w')
        self.api_delay.trace_add('write', lambda *args: delay_label.config(text=f"ç•¶å‰å€¼: {self.api_delay.get():.1f} ç§’"))
        
        # æ·»åŠ èªªæ˜æ–‡å­—
        delay_help = ttk.Label(param_frame, text="  â†³ é€£çºŒ API å‘¼å«ä¹‹é–“çš„å»¶é²æ™‚é–“ï¼Œæœ‰åŠ©æ–¼é¿å…é™æµ", 
                              font=('Arial', 8), foreground='gray')
        delay_help.pack(anchor='w')
        
        ttk.Label(param_frame, text="API è«‹æ±‚é‡è©¦æ¬¡æ•¸ï¼š").pack(anchor='w', pady=(10, 0))
        ttk.Scale(param_frame, from_=1, to=10, variable=self.max_retries, orient='horizontal').pack(fill='x', pady=(5, 5))
        retries_label = ttk.Label(param_frame, text="")
        retries_label.pack(anchor='w')
        self.max_retries.trace_add('write', lambda *args: retries_label.config(text=f"ç•¶å‰å€¼: {self.max_retries.get()} æ¬¡"))
        
        # æ·»åŠ èªªæ˜æ–‡å­—
        retries_help = ttk.Label(param_frame, text="  â†³ é‡åˆ°ç¶²è·¯éŒ¯èª¤æ™‚çš„é‡è©¦æ¬¡æ•¸ï¼Œæœ‰åŠ©æ–¼è™•ç†è‡¨æ™‚é€£æ¥å•é¡Œ", 
                               font=('Arial', 8), foreground='gray')
        retries_help.pack(anchor='w')
        
        # æ®µè½åˆ†éš”ç¬¦é¸æ“‡
        separator_frame = ttk.LabelFrame(padding_frame, text="æ®µè½åˆ†éš”ç¬¦è¨­å®š", padding=10)
        separator_frame.pack(fill='x', pady=(0, 10))
        
        ttk.Label(separator_frame, text="é¸æ“‡ç”¨æ–¼åˆ†å‰²é æœŸæ–‡ä»¶æ®µè½çš„åˆ†éš”ç¬¦ï¼š").pack(anchor='w', pady=(0, 5))
        
        # å‰µå»ºå…©æ¬„çš„è¤‡é¸æ¡†å¸ƒå±€
        checkbox_frame = ttk.Frame(separator_frame)
        checkbox_frame.pack(fill='x')
        
        left_column = ttk.Frame(checkbox_frame)
        left_column.pack(side='left', fill='both', expand=True)
        
        right_column = ttk.Frame(checkbox_frame)
        right_column.pack(side='right', fill='both', expand=True)
        
        # åˆ†éš”ç¬¦é¸é …é…ç½®
        separator_configs = [
            ('---', 'ä¸‰å€‹é€£å­—ç¬¦ (---)', 'ç”¨æ–¼æ¨™è¨˜æ®µè½åˆ†ç•Œ'),
            ('|||', 'ä¸‰å€‹è±ç·š (|||)', 'å‚ç›´åˆ†éš”ç¬¦è™Ÿ'),
            ('\n\n', 'é›™æ›è¡Œç¬¦ (\\n\\n)', 'ç©ºè¡Œåˆ†éš”æ®µè½'),
            ('###', 'ä¸‰å€‹äº•è™Ÿ (###)', 'Markdown æ¨™é¡Œæ ¼å¼'),
            ('===', 'ä¸‰å€‹ç­‰è™Ÿ (===)', 'æ°´å¹³åˆ†éš”ç·š'),
            ('...', 'ä¸‰å€‹é»è™Ÿ (...)', 'çœç•¥è™Ÿåˆ†éš”ç¬¦')
        ]
        
        # æ·»åŠ è¤‡é¸æ¡†
        for i, (sep_key, display_text, description) in enumerate(separator_configs):
            parent_frame = left_column if i < 3 else right_column
            
            checkbox_item_frame = ttk.Frame(parent_frame)
            checkbox_item_frame.pack(fill='x', pady=2)
            
            # ä½¿ç”¨æ¨™æº– Checkbutton ä»¥ç²å¾—æ‰“å‹¾æ¨£å¼
            checkbox = tk.Checkbutton(
                checkbox_item_frame, 
                text=display_text,
                variable=self.separator_vars[sep_key],
                indicatoron=1,  # é¡¯ç¤ºæ¨™æº–çš„å‹¾é¸æ¡†è€ŒéæŒ‰éˆ•æ¨£å¼
                relief='flat',  # å¹³é¢é¢¨æ ¼
                borderwidth=0,  # ç„¡é‚Šæ¡†
                highlightthickness=0,  # ç„¡é«˜äº®é‚Šæ¡†
                bg=self.bg_color,  # ä½¿ç”¨ä¸»é¡ŒèƒŒæ™¯è‰²
                activebackground=self.bg_color,  # æ»‘é¼ æ‡¸åœæ™‚çš„èƒŒæ™¯è‰²
                font=('Arial', 9),  # è¨­å®šå­—é«”
                cursor='hand2',  # æ»‘é¼ æŒ‡æ¨™è®Šç‚ºæ‰‹å‹
                anchor='w',  # æ–‡å­—å·¦å°é½Š
                pady=2  # å‚ç›´é–“è·
            )
            checkbox.pack(anchor='w')
            
            # æ·»åŠ æè¿°æ¨™ç±¤
            desc_label = ttk.Label(
                checkbox_item_frame, 
                text=f"  â†³ {description}",
                font=('Arial', 8),
                foreground='gray'
            )
            desc_label.pack(anchor='w', padx=(20, 0))
        
        # åˆ†éš”ç¬¦é è¦½å’Œæ¸¬è©¦
        preview_frame = ttk.Frame(separator_frame)
        preview_frame.pack(fill='x', pady=(10, 0))
        
        ttk.Button(preview_frame, text="æ¸¬è©¦åˆ†éš”ç¬¦", command=self.test_separators).pack(side='left')
        ttk.Button(preview_frame, text="é‡è¨­ç‚ºé è¨­", command=self.reset_separators).pack(side='left', padx=(10, 0))
        
        # æ“ä½œæŒ‰éˆ•
        button_frame = ttk.Frame(padding_frame)
        button_frame.pack(fill='x', pady=(20, 0))
        
        ttk.Button(button_frame, text="æ¸¬è©¦é€£æ¥", command=self.test_connection).pack(side='left')
        ttk.Button(button_frame, text="è¼‰å…¥è¨­å®š", command=self.load_config).pack(side='left', padx=(10, 0))
        ttk.Button(button_frame, text="å„²å­˜è¨­å®š", command=self.save_config).pack(side='left', padx=(10, 0))
        ttk.Button(button_frame, text="é—œæ–¼ç¨‹å¼", command=self.show_about).pack(side='right')
        
    def create_validation_tab(self, notebook):
        """å‰µå»ºé©—è­‰æ¨™ç±¤é ï¼ˆå¸¶æ»¾å‹•æ¢ï¼‰"""
        validation_frame = ttk.Frame(notebook)
        notebook.add(validation_frame, text="é©—è­‰")
        
        # å‰µå»ºå¯æ»¾å‹•çš„ä¸»æ¡†æ¶
        scrollable_container = ScrollableFrame(validation_frame)
        scrollable_container.pack(fill='both', expand=True, padx=10, pady=10)
        
        # ä¸»æ¡†æ¶ï¼ˆåœ¨æ»¾å‹•å€åŸŸå…§ï¼‰
        main_frame = scrollable_container.scrollable_frame
        
        # æ·»åŠ å…§é‚Šè·
        padding_frame = ttk.Frame(main_frame)
        padding_frame.pack(fill='both', expand=True, padx=10, pady=10)
        
        # èŠå¤©æ©Ÿå™¨äººé¸æ“‡
        bot_frame = ttk.LabelFrame(padding_frame, text="èŠå¤©æ©Ÿå™¨äººé¸æ“‡", padding=10)
        bot_frame.pack(fill='x', pady=(0, 10))
        
        self.bot_listbox = tk.Listbox(bot_frame, height=5)
        self.bot_listbox.pack(fill='x', pady=(0, 10))
        
        ttk.Button(bot_frame, text="é‡æ–°è¼‰å…¥æ©Ÿå™¨äººåˆ—è¡¨", command=self.refresh_chatbots).pack(side='left')
        
        # é©—è­‰æ§åˆ¶
        control_frame = ttk.LabelFrame(padding_frame, text="é©—è­‰æ§åˆ¶", padding=10)
        control_frame.pack(fill='x', pady=(0, 10))
        
        self.start_button = ttk.Button(control_frame, text="é–‹å§‹é©—è­‰", command=self.start_validation)
        self.start_button.pack(side='left')
        
        self.stop_button = ttk.Button(control_frame, text="åœæ­¢é©—è­‰", command=self.stop_validation, state='disabled')
        self.stop_button.pack(side='left', padx=(10, 0))
        
        self.retry_failed_button = ttk.Button(control_frame, text="é‡æ¸¬å¤±æ•—å•é¡Œ", command=self.retry_failed_from_csv)
        self.retry_failed_button.pack(side='left', padx=(10, 0))
        
        # é€²åº¦é¡¯ç¤º
        progress_frame = ttk.LabelFrame(padding_frame, text="é€²åº¦", padding=10)
        progress_frame.pack(fill='x', pady=(0, 10))
        
        self.progress_bar = ttk.Progressbar(progress_frame, mode='determinate')
        self.progress_bar.pack(fill='x', pady=(0, 5))
        
        self.progress_label = ttk.Label(progress_frame, text="æº–å‚™ä¸­...")
        self.progress_label.pack(anchor='w')
        
        # æ—¥èªŒé¡¯ç¤ºï¼ˆå„ªåŒ–ç‰ˆï¼‰
        log_frame = ttk.LabelFrame(padding_frame, text="ğŸ“‹ åŸ·è¡Œæ—¥èªŒ", padding=10)
        log_frame.pack(fill='both', expand=True)
        
        # æ—¥èªŒæ§åˆ¶æŒ‰éˆ•ï¼ˆç¬¬ä¸€è¡Œï¼‰
        log_control_frame1 = ttk.Frame(log_frame)
        log_control_frame1.pack(fill='x', pady=(0, 5))
        
        ttk.Button(log_control_frame1, text="ğŸ—‘ï¸ æ¸…ç©ºæ—¥èªŒ", command=self.clear_log_display).pack(side='left')
        ttk.Button(log_control_frame1, text="ğŸ“¤ åŒ¯å‡ºæ—¥èªŒ", command=self.export_logs).pack(side='left', padx=(5, 0))
        ttk.Button(log_control_frame1, text="ğŸ“ é–‹å•Ÿæ—¥èªŒè³‡æ–™å¤¾", command=self.open_log_folder).pack(side='left', padx=(5, 0))
        
        # è‡ªå‹•æ»¾å‹•æ§åˆ¶
        self.auto_scroll_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(log_control_frame1, text="ğŸ”„ è‡ªå‹•æ»¾å‹•", variable=self.auto_scroll_var).pack(side='left', padx=(20, 0))
        
        # æ—¥èªŒéæ¿¾æ§åˆ¶ï¼ˆç¬¬äºŒè¡Œï¼‰
        log_control_frame2 = ttk.Frame(log_frame)
        log_control_frame2.pack(fill='x', pady=(0, 5))
        
        # æ—¥èªŒç´šåˆ¥éæ¿¾
        ttk.Label(log_control_frame2, text="ğŸšï¸ é¡¯ç¤ºç´šåˆ¥:").pack(side='left')
        self.log_level_var = tk.StringVar(value="INFO")
        log_level_combo = ttk.Combobox(log_control_frame2, textvariable=self.log_level_var, 
                                      values=["ALL", "DEBUG", "INFO", "WARNING", "ERROR"], 
                                      width=8, state="readonly")
        log_level_combo.pack(side='left', padx=(5, 0))
        log_level_combo.bind('<<ComboboxSelected>>', self.on_log_level_changed)
        
        # æ—¥èªŒé¡å‹éæ¿¾
        ttk.Label(log_control_frame2, text="ğŸ“‚ æ—¥èªŒé¡å‹:").pack(side='left', padx=(15, 5))
        self.log_type_var = tk.StringVar(value="ALL")
        log_type_combo = ttk.Combobox(log_control_frame2, textvariable=self.log_type_var,
                                     values=["ALL", "GUI", "API", "Validation", "Retry"],
                                     width=8, state="readonly")
        log_type_combo.pack(side='left')
        log_type_combo.bind('<<ComboboxSelected>>', self.on_log_type_changed)
        
        # æœç´¢åŠŸèƒ½
        ttk.Label(log_control_frame2, text="ğŸ” æœç´¢:").pack(side='left', padx=(15, 5))
        self.log_search_var = tk.StringVar()
        search_entry = ttk.Entry(log_control_frame2, textvariable=self.log_search_var, width=15)
        search_entry.pack(side='left')
        search_entry.bind('<KeyRelease>', self.on_log_search_changed)
        ttk.Button(log_control_frame2, text="âŒ", command=self.clear_log_search, width=3).pack(side='left', padx=(2, 0))
        
        # çµ±è¨ˆä¿¡æ¯
        self.log_stats_label = ttk.Label(log_control_frame2, text="", font=('Arial', 8))
        self.log_stats_label.pack(side='right')
        
        # å‰µå»ºæ—¥èªŒæ–‡æœ¬æ¡†ï¼ˆå„ªåŒ–ç‰ˆï¼‰
        self.log_text = scrolledtext.ScrolledText(log_frame, height=15, state='disabled', wrap='word')
        self.log_text.pack(fill='both', expand=True)
        
        # é…ç½®æ—¥èªŒæ–‡æœ¬æ¡†çš„å­—é«”å’Œé¡è‰²
        self.setup_log_text_styling()
        
        # åˆå§‹åŒ–æ—¥èªŒçµ±è¨ˆ
        self.log_stats = {
            'DEBUG': 0,
            'INFO': 0,
            'WARNING': 0,
            'ERROR': 0,
            'total': 0
        }
        
    def create_results_tab(self, notebook):
        """å‰µå»ºçµæœæ¨™ç±¤é ï¼ˆå¸¶æ»¾å‹•æ¢ï¼‰"""
        results_frame = ttk.Frame(notebook)
        notebook.add(results_frame, text="çµæœ")
        
        # å‰µå»ºå¯æ»¾å‹•çš„ä¸»æ¡†æ¶
        scrollable_container = ScrollableFrame(results_frame)
        scrollable_container.pack(fill='both', expand=True, padx=10, pady=10)
        
        # ä¸»æ¡†æ¶ï¼ˆåœ¨æ»¾å‹•å€åŸŸå…§ï¼‰
        main_frame = scrollable_container.scrollable_frame
        
        # æ·»åŠ å…§é‚Šè·
        padding_frame = ttk.Frame(main_frame)
        padding_frame.pack(fill='both', expand=True, padx=10, pady=10)
        
        # çµ±è¨ˆçµæœ
        stats_frame = ttk.LabelFrame(padding_frame, text="çµ±è¨ˆçµæœ", padding=10)
        stats_frame.pack(fill='x', pady=(0, 10))
        
        self.stats_text = tk.Text(stats_frame, height=10, state='disabled')
        self.stats_text.pack(fill='x')
        
        # æ“ä½œæŒ‰éˆ•
        button_frame = ttk.Frame(padding_frame)
        button_frame.pack(fill='x', pady=(0, 10))
        
        ttk.Button(button_frame, text="é–‹å•Ÿçµæœæ–‡ä»¶", command=self.open_results_file).pack(side='left')
        ttk.Button(button_frame, text="é–‹å•Ÿçµæœè³‡æ–™å¤¾", command=self.open_results_folder).pack(side='left', padx=(10, 0))
        ttk.Button(button_frame, text="è¼¸å‡º Excel", command=self.export_to_excel).pack(side='left', padx=(10, 0))
        ttk.Button(button_frame, text="æª¢è¦–æ—¥èªŒçµ±è¨ˆ", command=self.show_log_stats).pack(side='left', padx=(10, 0))
        
        # è©³ç´°çµæœ
        details_frame = ttk.LabelFrame(padding_frame, text="è©³ç´°çµæœ", padding=10)
        details_frame.pack(fill='both', expand=True)
        
        # å‰µå»ºæ¨¹ç‹€æª¢è¦–
        columns = ('ç·¨è™Ÿ', 'æå•è€…', 'å•é¡Œ', 'AIå›è¦†', 'å¼•ç”¨å‘½ä¸­', 'æ–‡ä»¶æ­£ç¢º')
        self.results_tree = ttk.Treeview(details_frame, columns=columns, show='headings', height=15)
        
        for col in columns:
            self.results_tree.heading(col, text=col)
            if col == 'å•é¡Œ' or col == 'AIå›è¦†':
                self.results_tree.column(col, width=200)
            else:
                self.results_tree.column(col, width=80)
        
        # æ·»åŠ æ»¾å‹•æ¢
        scrollbar = ttk.Scrollbar(details_frame, orient='vertical', command=self.results_tree.yview)
        self.results_tree.configure(yscrollcommand=scrollbar.set)
        
        self.results_tree.pack(side='left', fill='both', expand=True)
        scrollbar.pack(side='right', fill='y')

    def browse_csv_file(self):
        """ç€è¦½é¸æ“‡ CSV æˆ– Excel æ–‡ä»¶"""
        filename = filedialog.askopenfilename(
            title="é¸æ“‡æ¸¬è©¦æ–‡ä»¶ (CSV æˆ– Excel)",
            filetypes=[
                ("æ”¯æ´çš„æ–‡ä»¶", "*.csv *.xlsx *.xls"), 
                ("CSV files", "*.csv"), 
                ("Excel files", "*.xlsx *.xls"),
                ("All files", "*.*")
            ]
        )
        if filename:
            self.csv_file_path.set(filename)
            
    def test_connection(self):
        """æ¸¬è©¦ API é€£æ¥"""
        if not self.api_key.get():
            messagebox.showerror("éŒ¯èª¤", "è«‹è¼¸å…¥ API é‡‘é‘°")
            return
            
        def test_async():
            try:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                async def test():
                    async with MaiAgentApiClient(self.api_base_url.get(), self.api_key.get(), self.api_logger_callback) as client:
                        chatbots = await client.get_chatbots()
                        return len(chatbots)
                
                count = loop.run_until_complete(test())
                loop.close()
                
                self.root.after(0, lambda: messagebox.showinfo("æˆåŠŸ", f"é€£æ¥æˆåŠŸï¼æ‰¾åˆ° {count} å€‹èŠå¤©æ©Ÿå™¨äºº"))
                
            except Exception as e:
                error_msg = str(e)
                self.root.after(0, lambda: messagebox.showerror("éŒ¯èª¤", f"é€£æ¥å¤±æ•—ï¼š{error_msg}"))
        
        threading.Thread(target=test_async, daemon=True).start()
        
    def refresh_chatbots(self):
        """é‡æ–°è¼‰å…¥èŠå¤©æ©Ÿå™¨äººåˆ—è¡¨"""
        if not self.api_key.get():
            messagebox.showerror("éŒ¯èª¤", "è«‹å…ˆè¨­å®š API é‡‘é‘°")
            return
            
        def refresh_async():
            try:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                async def fetch():
                    async with MaiAgentApiClient(self.api_base_url.get(), self.api_key.get(), self.api_logger_callback) as client:
                        return await client.get_chatbots()
                
                chatbots = loop.run_until_complete(fetch())
                loop.close()
                
                # æ›´æ–° UI
                self.root.after(0, lambda: self.update_chatbot_list(chatbots))
                
            except Exception as e:
                error_msg = str(e)
                self.root.after(0, lambda: messagebox.showerror("éŒ¯èª¤", f"è¼‰å…¥å¤±æ•—ï¼š{error_msg}"))
        
        threading.Thread(target=refresh_async, daemon=True).start()
        
    def update_chatbot_list(self, chatbots):
        """æ›´æ–°èŠå¤©æ©Ÿå™¨äººåˆ—è¡¨"""
        self.bot_listbox.delete(0, tk.END)
        self.chatbots = chatbots
        
        for i, bot in enumerate(chatbots):
            self.bot_listbox.insert(tk.END, f"{bot.get('name', 'Unknown')} (ID: {bot.get('id')})")
            
    def start_validation(self):
        """é–‹å§‹é©—è­‰"""
        # æª¢æŸ¥è¨­å®š
        if not self.csv_file_path.get():
            messagebox.showerror("éŒ¯èª¤", "è«‹é¸æ“‡æ¸¬è©¦æ–‡ä»¶ (CSV æˆ– Excel)")
            return
            
        if not self.api_key.get():
            messagebox.showerror("éŒ¯èª¤", "è«‹è¨­å®š API é‡‘é‘°")
            return
            
        selection = self.bot_listbox.curselection()
        if not selection:
            messagebox.showerror("éŒ¯èª¤", "è«‹é¸æ“‡èŠå¤©æ©Ÿå™¨äºº")
            return
            
        self.selected_chatbot_id = self.chatbots[selection[0]]['id']
        
        # é‡è¨­åœæ­¢æ¨™å¿—å’Œé€²åº¦è¨ˆæ•¸å™¨
        self.validation_stopped = False
        self.completed_questions = 0
        
        # æ›´æ–° UI ç‹€æ…‹
        self.start_button.config(state='disabled')
        self.stop_button.config(state='normal')
        self.progress_bar['value'] = 0
        self.progress_label.config(text="æº–å‚™ä¸­...")
        
        # æ¸…ç©ºæ—¥èªŒ
        self.log_text.config(state='normal')
        self.log_text.delete(1.0, tk.END)
        self.log_text.config(state='disabled')
        
        # é–‹å§‹é©—è­‰
        threading.Thread(target=self.run_validation, daemon=True).start()
        
    def stop_validation(self):
        """åœæ­¢é©—è­‰"""
        self.validation_stopped = True
        self.start_button.config(state='normal')
        self.stop_button.config(state='disabled')
        self.log_warning("æ­£åœ¨åœæ­¢é©—è­‰ï¼Œè«‹ç¨å€™...")
        
    def run_validation(self):
        """åŸ·è¡Œé©—è­‰ï¼ˆåœ¨èƒŒæ™¯åŸ·è¡Œç·’ä¸­ï¼‰"""
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            # è¼‰å…¥æ•¸æ“š
            self.log_info("æ­£åœ¨è¼‰å…¥æ¸¬è©¦æ•¸æ“š...")
            validation_data = self.load_csv_data()
            
            total_questions = len(validation_data)
            self.progress_bar['maximum'] = total_questions
            self.log_info(f"è¼‰å…¥å®Œæˆï¼Œå…± {total_questions} å€‹å•é¡Œ")
            
            # åŸ·è¡Œé©—è­‰
            selected_seps = self.get_selected_separators()
            self.log_info(f"é–‹å§‹åŸ·è¡Œé©—è­‰...")
            self.log_info(f"ä½¿ç”¨çš„åˆ†éš”ç¬¦: {', '.join(selected_seps)}")
            results = loop.run_until_complete(self.process_validation(validation_data))
            
            # è¨ˆç®—çµ±è¨ˆ
            self.log_info("è¨ˆç®—çµ±è¨ˆçµæœ...")
            stats = self.calculate_statistics(results)
            
            # è¼¸å‡ºçµæœï¼ˆé è¨­ç‚º CSV æ ¼å¼ï¼‰
            output_file = f"validation_results_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv"
            self.log_info(f"åŒ¯å‡ºçµæœåˆ° CSV: {output_file}")
            self.export_results(results, output_file, stats)
            
            # æ›´æ–° UI
            self.log_info("é©—è­‰å®Œæˆï¼Œæ›´æ–°çµæœé¡¯ç¤º")
            self.root.after(0, lambda: self.show_results(results, stats, output_file))
            
        except Exception as e:
            error_msg = str(e)
            self.root.after(0, lambda: messagebox.showerror("éŒ¯èª¤", f"é©—è­‰éç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{error_msg}"))
        finally:
            # æª¢æŸ¥æ˜¯å¦æ˜¯æ­£å¸¸å®Œæˆé‚„æ˜¯è¢«åœæ­¢
            if self.validation_stopped:
                self.root.after(0, lambda: self.log_warning("é©—è­‰å·²åœæ­¢"))
            # é‡è¨­ UI ç‹€æ…‹
            self.root.after(0, lambda: self.reset_validation_ui())
            
    def load_csv_data(self):
        """è¼‰å…¥ CSV æˆ– Excel æ•¸æ“š"""
        file_path = self.csv_file_path.get()
        file_extension = os.path.splitext(file_path)[1].lower()
        
        try:
            # æ ¹æ“šæ–‡ä»¶æ“´å±•åé¸æ“‡é©ç•¶çš„è®€å–æ–¹æ³•
            if file_extension == '.csv':
                df = self._read_csv_with_encoding_detection(file_path)
            elif file_extension in ['.xlsx', '.xls']:
                df = pd.read_excel(file_path, engine='openpyxl' if file_extension == '.xlsx' else None)
            else:
                raise ValueError(f"ä¸æ”¯æ´çš„æ–‡ä»¶æ ¼å¼: {file_extension}")
            
            # æª¢æŸ¥å¿…è¦çš„æ¬„ä½ - æ”¯æ´å¤šç¨®æ¬„ä½åç¨±
            required_columns = ['ç·¨è™Ÿ', 'æå•è€…']
            actual_columns = list(df.columns)
            missing_columns = [col for col in required_columns if col not in actual_columns]
            
            # æª¢æŸ¥å•é¡Œå…§å®¹æ¬„ä½ï¼ˆæ”¯æ´å¤šç¨®åç¨±ï¼‰
            question_column = None
            for possible_name in ['å•é¡Œæè¿°', 'å°è©±å…§å®¹', 'å•é¡Œå…§å®¹', 'å…§å®¹']:
                if possible_name in actual_columns:
                    question_column = possible_name
                    break
            
            if not question_column:
                missing_columns.append('å•é¡Œæè¿°/å°è©±å…§å®¹')
            
            if missing_columns:
                self.log_error(f"æ–‡ä»¶ç¼ºå°‘å¿…è¦æ¬„ä½: {', '.join(missing_columns)}")
                self.log_error(f"å¯¦éš›æ¬„ä½: {', '.join(actual_columns)}")
                raise ValueError(f"æ–‡ä»¶ç¼ºå°‘å¿…è¦æ¬„ä½: {', '.join(missing_columns)}\\n\\nå¯¦éš›æ¬„ä½: {', '.join(actual_columns)}\\n\\nè«‹ç¢ºä¿æ–‡ä»¶åŒ…å«ä»¥ä¸‹æ¬„ä½ï¼šç·¨è™Ÿã€æå•è€…ã€å•é¡Œæè¿°/å°è©±å…§å®¹")
            
            self.log_info(f"æˆåŠŸè¼‰å…¥æ–‡ä»¶ï¼Œå…± {len(df)} è¡Œæ•¸æ“š")
            self.log_info(f"ä½¿ç”¨ '{question_column}' ä½œç‚ºå•é¡Œå…§å®¹æ¬„ä½")
            self.log_info(f"æ–‡ä»¶æ¬„ä½: {', '.join(actual_columns)}")
            
            validation_rows = []
            for _, row in df.iterrows():
                validation_row = ValidationRow(
                    ç·¨è™Ÿ=str(row['ç·¨è™Ÿ']),
                    æå•è€…=str(row['æå•è€…']),
                    å•é¡Œæè¿°=str(row[question_column]),  # ä½¿ç”¨å‹•æ…‹æª¢æ¸¬åˆ°çš„æ¬„ä½åç¨±
                    å»ºè­°_or_æ­£ç¢ºç­”æ¡ˆ=str(row.get('å»ºè­° or æ­£ç¢ºç­”æ¡ˆ (if have)', '')),
                    æ‡‰åƒè€ƒçš„æ–‡ä»¶=str(row.get('æ‡‰åƒè€ƒçš„æ–‡ä»¶', '')),
                    æ‡‰åƒè€ƒçš„æ–‡ä»¶æ®µè½=str(row.get('æ‡‰åƒè€ƒçš„æ–‡ä»¶æ®µè½', '')),
                    æ‡‰åƒè€ƒæ–‡ä»¶UUID=str(row.get('æ‡‰åƒè€ƒæ–‡ä»¶UUID', '')),  # æ–°å¢UUIDæ¬„ä½
                    æ˜¯å¦æª¢ç´¢KMæ¨è–¦=str(row.get('æ˜¯å¦æª¢ç´¢KMæ¨è–¦', ''))  # æ–°å¢æ¬„ä½
                )
                validation_rows.append(validation_row)
                
            return validation_rows
            
        except Exception as e:
            self.log_error(f"è¼‰å…¥æ–‡ä»¶å¤±æ•—: {str(e)}")
            raise
        
    async def process_validation(self, validation_data):
        """è™•ç†é©—è­‰ - æ”¯æ´ä½µç™¼è™•ç†å¤šå€‹æå•è€…"""
        # æ¸…ç©ºå°è©±ç®¡ç†å™¨çš„ä¸Šä¸‹æ–‡ï¼ˆæ–°çš„é©—è­‰é–‹å§‹ï¼‰
        self.conversation_manager.conversations.clear()
        self.conversation_manager.questioner_context.clear()
        self.log_info("å·²æ¸…ç©ºå°è©±ä¸Šä¸‹æ–‡ï¼Œé–‹å§‹æ–°çš„é©—è­‰")
        
        # ç¯©é¸éœ€è¦æª¢ç´¢KMæ¨è–¦çš„è¨˜éŒ„
        filtered_data = []
        skipped_count = 0
        
        for row in validation_data:
            if row.æ˜¯å¦æª¢ç´¢KMæ¨è–¦.strip() == "æ˜¯":
                filtered_data.append(row)
            else:
                skipped_count += 1
                # ç‚ºè·³éçš„è¨˜éŒ„è¨­ç½®é è¨­å€¼
                row.AIåŠ©ç†å›è¦† = "è·³éé©—è­‰ï¼ˆæœªæ¨™è¨˜ç‚ºæª¢ç´¢KMæ¨è–¦ï¼‰"
                row.å¼•ç”¨ç¯€é»æ˜¯å¦å‘½ä¸­ = "è·³é"
                row.åƒè€ƒæ–‡ä»¶æ˜¯å¦æ­£ç¢º = "è·³é"
                row.å›è¦†æ˜¯å¦æ»¿æ„ = "è·³é"
        
        self.log_info(f"ç¸½å…± {len(validation_data)} ç­†è¨˜éŒ„")
        self.log_info(f"éœ€è¦é©—è­‰çš„è¨˜éŒ„: {len(filtered_data)} ç­†ï¼ˆæ¨™è¨˜ç‚ºã€Œæ˜¯ã€ï¼‰")
        self.log_info(f"è·³éçš„è¨˜éŒ„: {skipped_count} ç­†ï¼ˆæœªæ¨™è¨˜ç‚ºã€Œæ˜¯ã€ï¼‰")
        
        if len(filtered_data) == 0:
            self.log_warning("æ²’æœ‰æ¨™è¨˜ç‚ºã€Œæ˜¯ã€çš„è¨˜éŒ„éœ€è¦é©—è­‰")
            return validation_data  # è¿”å›åŸå§‹æ•¸æ“šï¼ˆåŒ…å«è·³éçš„è¨˜éŒ„ï¼‰
        
        # æŒ‰æå•è€…åˆ†çµ„ï¼ˆåªè™•ç†éœ€è¦é©—è­‰çš„è¨˜éŒ„ï¼‰
        user_groups = {}
        for row in filtered_data:
            user = row.æå•è€…
            if user not in user_groups:
                user_groups[user] = []
            user_groups[user].append(row)
        
        self.log_info(f"ç™¼ç¾ {len(user_groups)} å€‹ä¸åŒçš„æå•è€…")
        self.log_info(f"æå•è€…åˆ—è¡¨: {', '.join(user_groups.keys())}")
        max_concurrent_users = self.max_concurrent.get()
        self.log_info(f"é–‹å§‹ä½µç™¼è™•ç†ï¼Œæœ€å¤šåŒæ™‚è™•ç† {max_concurrent_users} å€‹æå•è€…")
        
        # å‰µå»ºé€²åº¦è¿½è¹¤é–
        progress_lock = asyncio.Lock()
        
        # å‰µå»ºçµæœå­—å…¸ï¼Œç”¨æ–¼å¿«é€ŸæŸ¥æ‰¾
        results_dict = {}
        
        async with MaiAgentApiClient(self.api_base_url.get(), self.api_key.get(), self.api_logger_callback) as client:
            # ä½¿ç”¨ Semaphore æ§åˆ¶ä½µç™¼æ•¸é‡
            semaphore = asyncio.Semaphore(max_concurrent_users)
            
            # å‰µå»ºæ¯å€‹æå•è€…çš„è™•ç†ä»»å‹™
            tasks = []
            for user, user_questions in user_groups.items():
                task = self.process_user_questions(client, user, user_questions, semaphore, len(validation_data), progress_lock, results_dict)
                tasks.append(task)
            
            # ä½µç™¼åŸ·è¡Œæ‰€æœ‰æå•è€…çš„ä»»å‹™
            await asyncio.gather(*tasks, return_exceptions=True)
            
            # === é‡è©¦å¤±æ•—å•é¡Œæª¢æŸ¥èˆ‡é‡æ–°æ¸¬è©¦ ===
            await self.check_and_retry_failed_questions(client, filtered_data, results_dict, progress_lock, len(validation_data))
        
        # æŒ‰åŸå§‹é †åºæ•´ç†çµæœï¼ˆåŒ…å«æ‰€æœ‰è¨˜éŒ„ï¼šé©—è­‰çš„å’Œè·³éçš„ï¼‰
        results = []
        for row in validation_data:
            if row.ç·¨è™Ÿ in results_dict:
                # ä½¿ç”¨é©—è­‰çµæœ
                results.append(results_dict[row.ç·¨è™Ÿ])
            else:
                # æª¢æŸ¥æ˜¯å¦ç‚ºè·³éçš„è¨˜éŒ„
                if row.æ˜¯å¦æª¢ç´¢KMæ¨è–¦.strip() != "æ˜¯":
                    # å·²ç¶“åœ¨ç¯©é¸éšæ®µè¨­ç½®äº†è·³éç‹€æ…‹ï¼Œç›´æ¥ä½¿ç”¨
                    # ç¢ºä¿è·³éçš„è¨˜éŒ„å…·æœ‰æ‰€æœ‰çµ±è¨ˆå±¬æ€§
                    row.precision = 0.0
                    row.recall = 0.0
                    row.f1_score = 0.0
                    row.hit_rate = 0.0
                else:
                    # æ¨™è¨˜ç‚ºã€Œæ˜¯ã€ä½†æœªè™•ç†çš„è¨˜éŒ„ï¼ˆå¯èƒ½å› ç‚ºåœæ­¢æˆ–éŒ¯èª¤ï¼‰
                    if not row.AIåŠ©ç†å›è¦† or row.AIåŠ©ç†å›è¦† == "":
                        row.AIåŠ©ç†å›è¦† = "æœªè™•ç†ï¼ˆé©—è­‰ä¸­æ–·ï¼‰"
                    
                    # ç¢ºä¿æœªè™•ç†çš„ row å…·æœ‰æ‰€æœ‰çµ±è¨ˆå±¬æ€§
                    row.precision = 0.0
                    row.recall = 0.0
                    row.f1_score = 0.0
                    row.hit_rate = 0.0
                    if not row.å¼•ç”¨ç¯€é»æ˜¯å¦å‘½ä¸­:
                        row.å¼•ç”¨ç¯€é»æ˜¯å¦å‘½ä¸­ = "å¦"
                    if not row.åƒè€ƒæ–‡ä»¶æ˜¯å¦æ­£ç¢º:
                        row.åƒè€ƒæ–‡ä»¶æ˜¯å¦æ­£ç¢º = "å¦"
                    if not row.å›è¦†æ˜¯å¦æ»¿æ„:
                        row.å›è¦†æ˜¯å¦æ»¿æ„ = "å¦"
                
                results.append(row)
                    
        return results
    
    async def check_and_retry_failed_questions(self, client, filtered_data, results_dict, progress_lock, total_questions):
        """æª¢æŸ¥ä¸¦é‡è©¦å¤±æ•—çš„å•é¡Œ"""
        if self.validation_stopped:
            self.log_info("é©—è­‰å·²åœæ­¢ï¼Œè·³éå¤±æ•—å•é¡Œé‡è©¦æª¢æŸ¥")
            return
            
        # è­˜åˆ¥å¤±æ•—çš„å•é¡Œ
        failed_questions = []
        for row in filtered_data:
            if row.ç·¨è™Ÿ in results_dict:
                result = results_dict[row.ç·¨è™Ÿ]
                # æª¢æŸ¥æ˜¯å¦ç‚ºé‡è©¦å¤±æ•—çš„å•é¡Œ
                if (hasattr(result, 'AIåŠ©ç†å›è¦†') and 
                    result.AIåŠ©ç†å›è¦† and 
                    (result.AIåŠ©ç†å›è¦†.startswith("éŒ¯èª¤:") or 
                     "API è«‹æ±‚åœ¨" in result.AIåŠ©ç†å›è¦† or 
                     "æ¬¡é‡è©¦å¾Œä»ç„¶å¤±æ•—" in result.AIåŠ©ç†å›è¦†)):
                    failed_questions.append(row)
            else:
                # æœªè™•ç†çš„å•é¡Œä¹Ÿç®—å¤±æ•—
                failed_questions.append(row)
        
        if not failed_questions:
            self.log_info("âœ… æ‰€æœ‰å•é¡Œéƒ½å·²æˆåŠŸé©—è­‰ï¼Œç„¡éœ€é‡è©¦")
            return
        
        # è¨˜éŒ„å¤±æ•—å•é¡Œçµ±è¨ˆ
        self.log_warning(f"ğŸ” ç™¼ç¾ {len(failed_questions)} å€‹å¤±æ•—å•é¡Œï¼Œæº–å‚™é€²è¡Œé‡è©¦...")
        
        # æŒ‰æå•è€…åˆ†çµ„å¤±æ•—å•é¡Œ
        failed_user_groups = {}
        for row in failed_questions:
            user = row.æå•è€…
            if user not in failed_user_groups:
                failed_user_groups[user] = []
            failed_user_groups[user].append(row)
        
        self.log_info(f"ğŸ“Š å¤±æ•—å•é¡Œåˆ†å¸ƒï¼š{', '.join([f'{user}({len(questions)}é¡Œ)' for user, questions in failed_user_groups.items()])}")
        
        # é‡è©¦é…ç½®ï¼šé™ä½ä½µç™¼æ•¸ï¼Œå¢åŠ å»¶é²å’Œé‡è©¦æ¬¡æ•¸
        retry_max_concurrent = max(1, self.max_concurrent.get() // 2)  # é™ä½ä½µç™¼æ•¸
        retry_delay = self.api_delay.get() * 2  # å¢åŠ å»¶é²
        retry_attempts = min(self.max_retries.get() + 2, 8)  # å¢åŠ é‡è©¦æ¬¡æ•¸ï¼Œæœ€å¤š8æ¬¡
        
        self.log_info(f"ğŸ”„ é‡è©¦é…ç½®ï¼šä½µç™¼æ•¸={retry_max_concurrent}, å»¶é²={retry_delay}ç§’, é‡è©¦æ¬¡æ•¸={retry_attempts}")
        
        # ä½¿ç”¨æ›´ä¿å®ˆçš„ä½µç™¼æ§åˆ¶é€²è¡Œé‡è©¦
        retry_semaphore = asyncio.Semaphore(retry_max_concurrent)
        retry_tasks = []
        
        for user, user_questions in failed_user_groups.items():
            if self.validation_stopped:
                break
            task = self.retry_user_questions(client, user, user_questions, retry_semaphore, 
                                           total_questions, progress_lock, results_dict, 
                                           retry_delay, retry_attempts)
            retry_tasks.append(task)
        
        if retry_tasks:
            self.log_info(f"ğŸš€ é–‹å§‹é‡è©¦ {len(retry_tasks)} å€‹æå•è€…çš„å¤±æ•—å•é¡Œ...")
            await asyncio.gather(*retry_tasks, return_exceptions=True)
            
            # æª¢æŸ¥é‡è©¦çµæœ
            still_failed = []
            retry_success = 0
            for row in failed_questions:
                if row.ç·¨è™Ÿ in results_dict:
                    result = results_dict[row.ç·¨è™Ÿ]
                    if (hasattr(result, 'AIåŠ©ç†å›è¦†') and 
                        result.AIåŠ©ç†å›è¦† and 
                        not (result.AIåŠ©ç†å›è¦†.startswith("éŒ¯èª¤:") or 
                             "API è«‹æ±‚åœ¨" in result.AIåŠ©ç†å›è¦† or 
                             "æ¬¡é‡è©¦å¾Œä»ç„¶å¤±æ•—" in result.AIåŠ©ç†å›è¦†)):
                        retry_success += 1
                    else:
                        still_failed.append(row.ç·¨è™Ÿ)
                else:
                    still_failed.append(row.ç·¨è™Ÿ)
            
            # å ±å‘Šé‡è©¦çµæœ
            self.log_info(f"ğŸ“ˆ é‡è©¦å®Œæˆçµ±è¨ˆï¼š")
            self.log_info(f"   âœ… é‡è©¦æˆåŠŸï¼š{retry_success} é¡Œ")
            self.log_info(f"   âŒ ä»ç„¶å¤±æ•—ï¼š{len(still_failed)} é¡Œ")
            
            if still_failed:
                self.log_warning(f"âš ï¸ ä»¥ä¸‹å•é¡Œç¶“é‡è©¦å¾Œä»ç„¶å¤±æ•—ï¼š{', '.join(still_failed[:10])}" + 
                               (f" ç­‰{len(still_failed)}é¡Œ" if len(still_failed) > 10 else ""))
            else:
                self.log_info("ğŸ‰ æ‰€æœ‰å¤±æ•—å•é¡Œéƒ½å·²æˆåŠŸé‡è©¦å®Œæˆï¼")
        else:
            self.log_warning("é‡è©¦ä»»å‹™å‰µå»ºå¤±æ•—æˆ–é©—è­‰å·²åœæ­¢")
    
    async def retry_user_questions(self, client, user, user_questions, semaphore, total_questions, 
                                 progress_lock, results_dict, retry_delay, retry_attempts):
        """é‡è©¦ç‰¹å®šæå•è€…çš„å¤±æ•—å•é¡Œ"""
        async with semaphore:
            if self.validation_stopped:
                return
                
            self.log_info(f"ğŸ”„ é–‹å§‹é‡è©¦æå•è€… '{user}' çš„ {len(user_questions)} å€‹å¤±æ•—å•é¡Œ")
            
            for row in user_questions:
                if self.validation_stopped:
                    break
                    
                try:
                    # æ¸…é™¤ä¹‹å‰çš„éŒ¯èª¤ç‹€æ…‹
                    row.AIåŠ©ç†å›è¦† = ""
                    row.å¼•ç”¨ç¯€é»æ˜¯å¦å‘½ä¸­ = ""
                    row.åƒè€ƒæ–‡ä»¶æ˜¯å¦æ­£ç¢º = ""
                    
                    # ä½¿ç”¨æ›´ä¿å®ˆçš„é‡è©¦è¨­å®šè™•ç†å•é¡Œ
                    result = await self.process_single_question_with_retry(
                        client, row, retry_attempts, retry_delay)
                    
                    # æ›´æ–°çµæœ
                    async with progress_lock:
                        # æ¨™è¨˜ç‚ºé‡è©¦æˆåŠŸ
                        result._retry_info = "é‡è©¦æˆåŠŸ"
                        results_dict[row.ç·¨è™Ÿ] = result
                        
                        # æ›´æ–°é€²åº¦é¡¯ç¤ºï¼ˆé‡è©¦ï¼‰
                        progress_msg = f"[é‡è©¦-{user}] å®Œæˆå•é¡Œ {row.ç·¨è™Ÿ} | å¤±æ•—å•é¡Œé‡è©¦ä¸­"
                        self.root.after(0, lambda msg=progress_msg: self.update_progress(
                            self.completed_questions, total_questions, msg))
                    
                    self.log_validation_result(row.ç·¨è™Ÿ, True, 
                                             f"[é‡è©¦-{user}] é‡è©¦æˆåŠŸï¼Œå›è¦†é•·åº¦: {len(result.AIåŠ©ç†å›è¦†)} å­—å…ƒ")
                    
                except Exception as e:
                    self.log_error(f"é‡è©¦æå•è€… '{user}' çš„å•é¡Œ {row.ç·¨è™Ÿ} ä»ç„¶å¤±æ•—: {str(e)}", 'Retry')
                    
                    # æ¨™è¨˜ç‚ºæœ€çµ‚å¤±æ•—
                    async with progress_lock:
                        row.AIåŠ©ç†å›è¦† = f"é‡è©¦å¤±æ•—: {str(e)}"
                        row.precision = 0.0
                        row.recall = 0.0
                        row.f1_score = 0.0
                        row.hit_rate = 0.0
                        row.å¼•ç”¨ç¯€é»æ˜¯å¦å‘½ä¸­ = "å¦"
                        row.åƒè€ƒæ–‡ä»¶æ˜¯å¦æ­£ç¢º = "å¦"
                        row.å›è¦†æ˜¯å¦æ»¿æ„ = "å¦"
                        
                        results_dict[row.ç·¨è™Ÿ] = row
                        
                        progress_msg = f"[é‡è©¦-{user}] å•é¡Œ {row.ç·¨è™Ÿ} æœ€çµ‚å¤±æ•— | å¤±æ•—å•é¡Œé‡è©¦ä¸­"
                        self.root.after(0, lambda msg=progress_msg: self.update_progress(
                            self.completed_questions, total_questions, msg))
                
                # é‡è©¦é–“éš”å»¶é²
                if not self.validation_stopped:
                    await asyncio.sleep(retry_delay)
            
            self.log_info(f"ğŸ æå•è€… '{user}' çš„å¤±æ•—å•é¡Œé‡è©¦å®Œæˆ")
    
    async def process_single_question_with_retry(self, client, validation_row, max_retries, delay):
        """ä½¿ç”¨è‡ªå®šç¾©é‡è©¦åƒæ•¸è™•ç†å–®å€‹å•é¡Œ"""
        # ç²å–æˆ–å‰µå»ºå°è©±
        conversation_id = self.conversation_manager.get_conversation_id(validation_row.æå•è€…)
        
        # æ§‹å»ºè¦ç™¼é€çš„å•é¡Œå…§å®¹ï¼ˆé‡è©¦æ™‚ä½¿ç”¨åŸå§‹å•é¡Œï¼Œå› ç‚ºä¸Šä¸‹æ–‡å·²ç¶“åœ¨åˆæ¬¡è™•ç†æ™‚å»ºç«‹ï¼‰
        message_content = validation_row.å•é¡Œæè¿°
        
        # å¦‚æœé€™æ˜¯é‡è©¦ä¸”æ²’æœ‰å°è©±IDï¼Œèªªæ˜æ˜¯é‡æ–°é–‹å§‹å°è©±ï¼Œéœ€è¦æ§‹å»ºä¸Šä¸‹æ–‡
        if conversation_id is None and self.enable_context_combination.get():
            # æª¢æŸ¥æ˜¯å¦æœ‰ä¹‹å‰çš„å•é¡Œéœ€è¦çµ„åˆï¼ˆæ’é™¤ç•¶å‰å•é¡Œæœ¬èº«ï¼‰
            previous_questions = self.conversation_manager.get_context_questions(validation_row.æå•è€…)
            # ç§»é™¤æœ€å¾Œä¸€å€‹å•é¡Œï¼ˆç•¶å‰å•é¡Œï¼‰ï¼Œåªä½¿ç”¨å‰é¢çš„å•é¡Œä½œç‚ºä¸Šä¸‹æ–‡
            if previous_questions and len(previous_questions) > 1:
                context_questions = previous_questions[:-1]  # æ’é™¤ç•¶å‰å•é¡Œ
                if context_questions:
                    context_parts = []
                    context_parts.append("é€™æ˜¯ä¸€ç³»åˆ—ç›¸é—œçš„å•é¡Œï¼š")
                    context_parts.append("")
                    
                    # æ·»åŠ å‰é¢çš„å•é¡Œ
                    for i, prev_question in enumerate(context_questions, 1):
                        context_parts.append(f"å•é¡Œ {i}ï¼š{prev_question}")
                    
                    # æ·»åŠ ç•¶å‰å•é¡Œ
                    context_parts.append(f"å•é¡Œ {len(context_questions) + 1}ï¼š{validation_row.å•é¡Œæè¿°}")
                    context_parts.append("")
                    context_parts.append("è«‹é‡å°é€™ä¸€ç³»åˆ—å•é¡Œæä¾›å®Œæ•´çš„å›ç­”ï¼Œç‰¹åˆ¥æ˜¯æœ€å¾Œä¸€å€‹å•é¡Œã€‚")
                    
                    message_content = "\n".join(context_parts)
                    
                    self.log_info(
                        f"é‡è©¦æ™‚ç‚ºæå•è€… '{validation_row.æå•è€…}' é‡æ–°æ§‹å»ºä¸Šä¸‹æ–‡ï¼ŒåŒ…å« {len(context_questions)} å€‹å‰é¢çš„å•é¡Œ", 
                        'Validation'
                    )
        
        # æ§‹å»º query_metadataï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
        query_metadata = None
        if self.enable_query_metadata.get() and self.knowledge_base_id.get().strip():
            knowledge_bases = [
                {
                    "knowledge_base_id": self.knowledge_base_id.get().strip(),
                    "has_user_selected_all": True
                }
            ]
            
            query_metadata = {
                "knowledge_bases": knowledge_bases
            }
            
            # å¦‚æœæä¾›äº†æ¨™ç±¤IDï¼Œæ·»åŠ æ¨™ç±¤éæ¿¾
            if self.label_id.get().strip():
                query_metadata["label_relations"] = {
                    "operator": "OR",
                    "conditions": [
                        {"label_id": self.label_id.get().strip()}
                    ]
                }
        
        # ç™¼é€å•é¡Œï¼ˆä½¿ç”¨è‡ªå®šç¾©é‡è©¦æ©Ÿåˆ¶ï¼‰
        response = await client.send_message(
            self.selected_chatbot_id,
            message_content,  # ä½¿ç”¨æ§‹å»ºçš„å…§å®¹
            conversation_id,
            max_retries=max_retries,
            query_metadata=query_metadata
        )
        
        # è¨­å®šå°è©± IDï¼ˆå¦‚æœæ˜¯æ–°å°è©±ï¼‰
        if not conversation_id and response.conversation_id:
            self.conversation_manager.set_conversation_id(validation_row.æå•è€…, response.conversation_id)
        
        # é€²è¡Œ RAG å¢å¼·é©—è­‰
        actual_chunks_count = len(response.citations) if response.citations else 0
        citation_hit, rag_metrics = self.text_matcher.check_rag_enhanced_hit(
            response.citations,
            validation_row.æ‡‰åƒè€ƒçš„æ–‡ä»¶æ®µè½,
            self.similarity_threshold.get(),
            actual_chunks_count,  # ä½¿ç”¨å¯¦éš›å›å‚³çš„ç¯€é»æ•¸é‡
            self.get_selected_separators(),  # ä½¿ç”¨ç”¨æˆ¶é¸æ“‡çš„åˆ†éš”ç¬¦
            self.similarity_mode.get()  # ä½¿ç”¨ç”¨æˆ¶é¸æ“‡çš„ç›¸ä¼¼åº¦è¨ˆç®—æ¨¡å¼
        )
        
        # æ›´æ–°é©—è­‰è¡Œçš„çµæœ
        validation_row.AIåŠ©ç†å›è¦† = response.content
        validation_row.precision = rag_metrics['precision']
        validation_row.recall = rag_metrics['recall']
        validation_row.f1_score = rag_metrics['f1_score']
        validation_row.hit_rate = rag_metrics['hit_rate']
        validation_row.å¼•ç”¨ç¯€é»æ˜¯å¦å‘½ä¸­ = "æ˜¯" if citation_hit else "å¦"
        
        # åƒ…ä½¿ç”¨æ‡‰åƒè€ƒæ–‡ä»¶UUIDé€²è¡ŒåŒ¹é…
        expected_files = validation_row.æ‡‰åƒè€ƒæ–‡ä»¶UUID.strip()
        
        if expected_files:
            file_match, file_stats = self.text_matcher.check_citation_file_match(
                response.citations,
                expected_files
            )
            validation_row.åƒè€ƒæ–‡ä»¶æ˜¯å¦æ­£ç¢º = "æ˜¯" if file_match else "å¦"
        else:
            # å¦‚æœæ²’æœ‰UUIDï¼Œè·³éæ–‡ä»¶åŒ¹é…
            file_match = False
            file_stats = {
                "detail": "ç„¡UUIDè³‡æ–™ï¼Œè·³éæ–‡ä»¶åŒ¹é…",
                "total_expected": 0,
                "total_matched": 0,
                "hit_rate": 0.0,
                "matched_files": [],
                "unmatched_files": [],
                "all_matched": False
            }
            validation_row.åƒè€ƒæ–‡ä»¶æ˜¯å¦æ­£ç¢º = "æœªæª¢æ¸¬"
        
        # å„²å­˜åƒè€ƒæ–‡ä»¶å‘½ä¸­çµ±è¨ˆæ•¸æ“š
        validation_row.åƒè€ƒæ–‡ä»¶å‘½ä¸­ç‡ = file_stats.get('hit_rate', 0.0)
        validation_row.æœŸæœ›æ–‡ä»¶ç¸½æ•¸ = file_stats.get('total_expected', 0)
        validation_row.å‘½ä¸­æ–‡ä»¶æ•¸ = file_stats.get('total_matched', 0)
        
        # UUIDæ ¼å¼çš„å‘½ä¸­å’Œæœªå‘½ä¸­æ–‡ä»¶ä¿¡æ¯
        matched_files = file_stats.get('matched_files', [])
        validation_row.å‘½ä¸­æ–‡ä»¶ = ', '.join(matched_files) if matched_files else ""
        
        unmatched_files = file_stats.get('unmatched_files', [])
        validation_row.æœªå‘½ä¸­æ–‡ä»¶ = ', '.join(unmatched_files) if unmatched_files else ""
        
        # å‹•æ…‹æ·»åŠ åƒè€ƒæ–‡ä»¶æ¬„ä½
        self._add_citation_file_fields(validation_row, response.citations)
        
        # æ·»åŠ å»¶é²
        await asyncio.sleep(delay)
        
        return validation_row
    
    def _read_csv_with_encoding_detection(self, file_path):
        """ä½¿ç”¨ç·¨ç¢¼æª¢æ¸¬è®€å–CSVæ–‡ä»¶"""
        import chardet
        
        # å¸¸è¦‹çš„ç·¨ç¢¼æ ¼å¼åˆ—è¡¨ï¼ˆæŒ‰å„ªå…ˆç´šæ’åºï¼‰
        encodings_to_try = [
            'utf-8-sig',    # UTF-8 with BOM (Excelå¸¸ç”¨)
            'utf-8',        # æ¨™æº–UTF-8
            'big5',         # ç¹é«”ä¸­æ–‡
            'gbk',          # ç°¡é«”ä¸­æ–‡
            'cp950',        # Windowsç¹é«”ä¸­æ–‡
            'cp1252',       # Windows Western
            'iso-8859-1',   # Latin-1
            'ascii'         # ç´”ASCII
        ]
        
        # å…ˆå˜—è©¦æª¢æ¸¬æ–‡ä»¶ç·¨ç¢¼
        try:
            with open(file_path, 'rb') as file:
                raw_data = file.read()
                detected = chardet.detect(raw_data)
                detected_encoding = detected.get('encoding', '')
                confidence = detected.get('confidence', 0)
                
                self.log_info(f"ğŸ” æª¢æ¸¬åˆ°æ–‡ä»¶ç·¨ç¢¼: {detected_encoding} (ä¿¡å¿ƒåº¦: {confidence:.2f})")
                
                # å¦‚æœæª¢æ¸¬ä¿¡å¿ƒåº¦è¼ƒé«˜ï¼Œå„ªå…ˆä½¿ç”¨æª¢æ¸¬åˆ°çš„ç·¨ç¢¼
                if confidence > 0.7 and detected_encoding:
                    encodings_to_try.insert(0, detected_encoding.lower())
        except Exception as e:
            self.log_warning(f"ç·¨ç¢¼æª¢æ¸¬å¤±æ•—: {e}")
        
        # é€ä¸€å˜—è©¦ä¸åŒç·¨ç¢¼
        last_error = None
        for encoding in encodings_to_try:
            try:
                self.log_info(f"ğŸ”„ å˜—è©¦ä½¿ç”¨ç·¨ç¢¼: {encoding}")
                df = pd.read_csv(file_path, encoding=encoding)
                self.log_info(f"âœ… æˆåŠŸä½¿ç”¨ç·¨ç¢¼ {encoding} è®€å–æ–‡ä»¶")
                return df
            except UnicodeDecodeError as e:
                last_error = e
                self.log_warning(f"âŒ ç·¨ç¢¼ {encoding} è®€å–å¤±æ•—: {str(e)[:100]}")
                continue
            except Exception as e:
                last_error = e
                self.log_warning(f"âŒ ä½¿ç”¨ç·¨ç¢¼ {encoding} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)[:100]}")
                continue
        
        # å¦‚æœæ‰€æœ‰ç·¨ç¢¼éƒ½å¤±æ•—ï¼Œæ‹‹å‡ºéŒ¯èª¤
        raise ValueError(f"ç„¡æ³•è®€å–CSVæ–‡ä»¶ï¼Œå·²å˜—è©¦å¤šç¨®ç·¨ç¢¼æ ¼å¼ã€‚æœ€å¾ŒéŒ¯èª¤: {last_error}")
    
    def setup_log_text_styling(self):
        """è¨­ç½®æ—¥èªŒæ–‡æœ¬æ¡†çš„æ¨£å¼"""
        # è¨­ç½®å­—é«”
        self.log_text.configure(font=('Consolas', 9))
        
        # é…ç½®æ—¥èªŒç´šåˆ¥é¡è‰²å’Œæ¨£å¼
        self.log_text.tag_config('debug', foreground='#808080', font=('Consolas', 9, 'italic'))
        self.log_text.tag_config('info', foreground='#000000', font=('Consolas', 9))
        self.log_text.tag_config('warning', foreground='#FF8C00', font=('Consolas', 9, 'bold'))
        self.log_text.tag_config('error', foreground='#DC143C', font=('Consolas', 9, 'bold'))
        self.log_text.tag_config('critical', foreground='#8B0000', font=('Consolas', 9, 'bold'))
        
        # é…ç½®æ—¥èªŒé¡å‹æ¨£å¼
        self.log_text.tag_config('gui_tag', foreground='#4169E1')
        self.log_text.tag_config('api_tag', foreground='#32CD32')
        self.log_text.tag_config('validation_tag', foreground='#FF69B4')
        self.log_text.tag_config('retry_tag', foreground='#FFD700')
        
        # é…ç½®æ™‚é–“æˆ³æ¨£å¼
        self.log_text.tag_config('timestamp', foreground='#696969', font=('Consolas', 8))
        
        # é…ç½®é«˜äº®æœç´¢çµæœ
        self.log_text.tag_config('search_highlight', background='#FFFF00', foreground='#000000')
    
    def on_log_level_changed(self, event=None):
        """æ—¥èªŒç´šåˆ¥éæ¿¾è®Šæ›´è™•ç†"""
        self.refresh_log_display()
    
    def on_log_type_changed(self, event=None):
        """æ—¥èªŒé¡å‹éæ¿¾è®Šæ›´è™•ç†"""
        self.refresh_log_display()
    
    def on_log_search_changed(self, event=None):
        """æœç´¢å…§å®¹è®Šæ›´è™•ç†"""
        self.refresh_log_display()
    
    def clear_log_search(self):
        """æ¸…ç©ºæœç´¢"""
        self.log_search_var.set("")
        self.refresh_log_display()
    
    def on_query_metadata_toggle(self):
        """åˆ‡æ› Query Metadata è¼¸å…¥æ¬„ä½çš„å•Ÿç”¨ç‹€æ…‹"""
        state = 'normal' if self.enable_query_metadata.get() else 'disabled'
        
        # è¨­å®šçŸ¥è­˜åº«IDæ¬„ä½
        for widget in self.kb_id_frame.winfo_children():
            if isinstance(widget, ttk.Entry):
                widget.config(state=state)
        
        # è¨­å®šæ¨™ç±¤IDæ¬„ä½
        for widget in self.label_id_frame.winfo_children():
            if isinstance(widget, ttk.Entry):
                widget.config(state=state)
    
    def refresh_log_display(self):
        """åˆ·æ–°æ—¥èªŒé¡¯ç¤ºï¼ˆæ ¹æ“šéæ¿¾æ¢ä»¶ï¼‰"""
        if not hasattr(self, 'log_text'):
            return
            
        try:
            # ç²å–éæ¿¾æ¢ä»¶
            level_filter = self.log_level_var.get()
            type_filter = self.log_type_var.get()
            search_text = self.log_search_var.get().lower()
            
            # æ¸…ç©ºç•¶å‰é¡¯ç¤º
            self.log_text.config(state='normal')
            self.log_text.delete('1.0', tk.END)
            
            # é‡æ–°é¡¯ç¤ºç¬¦åˆæ¢ä»¶çš„æ—¥èªŒï¼ˆé€™è£¡æ‡‰è©²å¾å…§å­˜ä¸­çš„æ—¥èªŒç·©å­˜é‡æ–°è¼‰å…¥ï¼‰
            # ç”±æ–¼åŸå§‹å¯¦ç¾æ²’æœ‰æ—¥èªŒç·©å­˜ï¼Œé€™è£¡å…ˆå¯¦ç¾åŸºæœ¬åŠŸèƒ½
            self.log_text.config(state='disabled')
            
            self.update_log_stats()
            
        except Exception as e:
            pass  # éœé»˜è™•ç†åˆ·æ–°éŒ¯èª¤
    
    def update_log_stats(self):
        """æ›´æ–°æ—¥èªŒçµ±è¨ˆä¿¡æ¯"""
        if hasattr(self, 'log_stats_label'):
            stats_text = f"ğŸ“Š DEBUG:{self.log_stats['DEBUG']} | INFO:{self.log_stats['INFO']} | WARNING:{self.log_stats['WARNING']} | ERROR:{self.log_stats['ERROR']} | ç¸½è¨ˆ:{self.log_stats['total']}"
            self.log_stats_label.config(text=stats_text)
    
    def get_log_level_icon(self, level):
        """ç²å–æ—¥èªŒç´šåˆ¥åœ–æ¨™"""
        icons = {
            'DEBUG': 'ğŸ”',
            'INFO': 'â„¹ï¸',
            'WARNING': 'âš ï¸',
            'ERROR': 'âŒ',
            'CRITICAL': 'ğŸš¨'
        }
        return icons.get(level.upper(), 'â„¹ï¸')
    
    def get_log_type_icon(self, logger_name):
        """ç²å–æ—¥èªŒé¡å‹åœ–æ¨™"""
        icons = {
            'GUI': 'ğŸ–¥ï¸',
            'API': 'ğŸŒ',
            'Validation': 'âœ…',
            'Retry': 'ğŸ”„'
        }
        return icons.get(logger_name, 'ğŸ“')
    
    def retry_failed_from_csv(self):
        """å¾CSVæ–‡ä»¶è¼‰å…¥ä¸¦é‡æ¸¬å¤±æ•—å•é¡Œ"""
        # é¸æ“‡ä¹‹å‰çš„é©—è­‰çµæœCSVæ–‡ä»¶
        from tkinter import filedialog, messagebox
        
        csv_file = filedialog.askopenfilename(
            title="é¸æ“‡é©—è­‰çµæœCSVæ–‡ä»¶",
            filetypes=[
                ("CSV files", "*.csv"),
                ("All files", "*.*")
            ]
        )
        
        if not csv_file:
            return
        
        try:
            # æª¢æŸ¥APIè¨­å®š
            if not self.api_key.get():
                messagebox.showerror("éŒ¯èª¤", "è«‹å…ˆåœ¨è¨­å®šé é¢ä¸­è¨­å®š API é‡‘é‘°")
                return
            
            # æª¢æŸ¥æ˜¯å¦é¸æ“‡äº†Chatbot
            selection = self.bot_listbox.curselection()
            if not selection:
                messagebox.showerror("éŒ¯èª¤", "è«‹é¸æ“‡èŠå¤©æ©Ÿå™¨äºº")
                return
            
            self.selected_chatbot_id = self.chatbots[selection[0]]['id']
            
            # è¼‰å…¥CSVä¸¦è­˜åˆ¥å¤±æ•—å•é¡Œ
            self.log_info(f"æ­£åœ¨è¼‰å…¥é©—è­‰çµæœæ–‡ä»¶: {csv_file}")
            failed_data = self.load_failed_questions_from_csv(csv_file)
            
            if not failed_data:
                messagebox.showinfo("è³‡è¨Š", "æ²’æœ‰ç™¼ç¾éœ€è¦é‡æ¸¬çš„å¤±æ•—å•é¡Œ")
                return
            
            # ç¢ºèªé‡æ¸¬
            result = messagebox.askyesno(
                "ç¢ºèªé‡æ¸¬", 
                f"ç™¼ç¾ {len(failed_data)} å€‹å¤±æ•—å•é¡Œéœ€è¦é‡æ¸¬ã€‚\n\n"
                f"é€™å°‡æœƒï¼š\n"
                f"â€¢ é‡æ–°ç™¼é€é€™äº›å•é¡Œåˆ°AIåŠ©ç†\n"
                f"â€¢ ä½¿ç”¨ç•¶å‰çš„é©—è­‰åƒæ•¸è¨­å®š\n"
                f"â€¢ è¦†è“‹åŸå§‹çš„å¤±æ•—çµæœ\n\n"
                f"æ˜¯å¦ç¹¼çºŒï¼Ÿ"
            )
            
            if not result:
                return
            
            # é‡è¨­é©—è­‰ç‹€æ…‹
            self.validation_stopped = False
            self.completed_questions = 0
            
            # æ›´æ–°UIç‹€æ…‹
            self.retry_failed_button.config(state='disabled')
            self.start_button.config(state='disabled')
            self.stop_button.config(state='normal')
            self.progress_bar['value'] = 0
            self.progress_bar['maximum'] = len(failed_data)
            self.progress_label.config(text="æ­£åœ¨é‡æ¸¬å¤±æ•—å•é¡Œ...")
            
            # æ¸…ç©ºæ—¥èªŒ
            self.log_text.config(state='normal')
            self.log_text.delete(1.0, tk.END)
            self.log_text.config(state='disabled')
            
            # é–‹å§‹é‡æ¸¬ï¼ˆå‚³éåŸå§‹CSVæ–‡ä»¶è·¯å¾‘ç”¨æ–¼æ•´åˆï¼‰
            import threading
            self.original_csv_file = csv_file  # ä¿å­˜åŸå§‹CSVæ–‡ä»¶è·¯å¾‘
            threading.Thread(target=self.run_retry_validation, args=(failed_data, csv_file), daemon=True).start()
            
        except Exception as e:
            messagebox.showerror("éŒ¯èª¤", f"è¼‰å…¥å¤±æ•—å•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
    
    def load_failed_questions_from_csv(self, csv_file):
        """å¾CSVæ–‡ä»¶ä¸­è¼‰å…¥å¤±æ•—çš„å•é¡Œ"""
        import pandas as pd
        
        try:
            # è®€å–CSVæ–‡ä»¶ï¼ˆä½¿ç”¨ç·¨ç¢¼æª¢æ¸¬ï¼‰
            df = self._read_csv_with_encoding_detection(csv_file)
            
            # æª¢æŸ¥å¿…è¦æ¬„ä½
            required_columns = ['ç·¨è™Ÿ', 'æå•è€…', 'AIåŠ©ç†å›è¦†']
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            if missing_columns:
                raise ValueError(f"CSVæ–‡ä»¶ç¼ºå°‘å¿…è¦æ¬„ä½: {', '.join(missing_columns)}")
            
            # è­˜åˆ¥å¤±æ•—å•é¡Œ
            failed_rows = []
            debug_info = []
            
            for _, row in df.iterrows():
                ai_reply = str(row.get('AIåŠ©ç†å›è¦†', ''))
                row_id = str(row.get('ç·¨è™Ÿ', 'Unknown'))
                
                # æª¢æŸ¥æ˜¯å¦ç‚ºå¤±æ•—å•é¡Œï¼ˆå¢å¼·ç‰ˆï¼‰
                failure_reasons = []
                
                if ai_reply.startswith("éŒ¯èª¤:"):
                    failure_reasons.append("éŒ¯èª¤é–‹é ­")
                if ai_reply.startswith("é‡è©¦å¤±æ•—:"):
                    failure_reasons.append("é‡è©¦å¤±æ•—é–‹é ­")
                if "API è«‹æ±‚åœ¨" in ai_reply:
                    failure_reasons.append("APIè«‹æ±‚å¤±æ•—")
                if "æ¬¡é‡è©¦å¾Œä»ç„¶å¤±æ•—" in ai_reply:
                    failure_reasons.append("é‡è©¦æ¬¡æ•¸ç”¨ç›¡")
                if ai_reply.strip() == "" or ai_reply.lower() == "nan" or pd.isna(row.get('AIåŠ©ç†å›è¦†')):
                    failure_reasons.append("ç©ºå›è¦†")
                if ai_reply == "æœªè™•ç†ï¼ˆé©—è­‰ä¸­æ–·ï¼‰":
                    failure_reasons.append("é©—è­‰ä¸­æ–·")
                if "é€£æ¥" in ai_reply and ("éŒ¯èª¤" in ai_reply or "å¤±æ•—" in ai_reply):
                    failure_reasons.append("é€£æ¥å•é¡Œ")
                if "é€¾æ™‚" in ai_reply or "timeout" in ai_reply.lower():
                    failure_reasons.append("é€¾æ™‚å•é¡Œ")
                if "ä¼ºæœå™¨" in ai_reply and "éŒ¯èª¤" in ai_reply:
                    failure_reasons.append("ä¼ºæœå™¨éŒ¯èª¤")
                
                is_failed = len(failure_reasons) > 0
                
                # è¨˜éŒ„èª¿è©¦ä¿¡æ¯
                debug_info.append({
                    'ç·¨è™Ÿ': row_id,
                    'æå•è€…': str(row.get('æå•è€…', '')),
                    'AIå›è¦†å‰50å­—': ai_reply[:50] + ('...' if len(ai_reply) > 50 else ''),
                    'æ˜¯å¦å¤±æ•—': is_failed,
                    'å¤±æ•—åŸå› ': ', '.join(failure_reasons) if failure_reasons else 'ç„¡'
                })
                
                if is_failed:
                    # æŸ¥æ‰¾å•é¡Œæè¿°æ¬„ä½
                    question_column = None
                    for possible_name in ['å•é¡Œæè¿°', 'å°è©±å…§å®¹', 'å•é¡Œå…§å®¹', 'å…§å®¹']:
                        if possible_name in df.columns:
                            question_column = possible_name
                            break
                    
                    if not question_column:
                        self.log_warning(f"ç„¡æ³•æ‰¾åˆ°å•é¡Œæè¿°æ¬„ä½ï¼Œè·³éå•é¡Œ {row.get('ç·¨è™Ÿ', 'Unknown')}")
                        continue
                    
                    # å‰µå»ºValidationRowå°è±¡
                    validation_row = ValidationRow(
                        ç·¨è™Ÿ=str(row.get('ç·¨è™Ÿ', '')),
                        æå•è€…=str(row.get('æå•è€…', '')),
                        å•é¡Œæè¿°=str(row.get(question_column, '')),
                        å»ºè­°_or_æ­£ç¢ºç­”æ¡ˆ=str(row.get('å»ºè­° or æ­£ç¢ºç­”æ¡ˆ (if have)', '')),
                        æ‡‰åƒè€ƒçš„æ–‡ä»¶=str(row.get('æ‡‰åƒè€ƒçš„æ–‡ä»¶', '')),
                        æ‡‰åƒè€ƒçš„æ–‡ä»¶æ®µè½=str(row.get('æ‡‰åƒè€ƒçš„æ–‡ä»¶æ®µè½', '')),
                        æ˜¯å¦æª¢ç´¢KMæ¨è–¦=str(row.get('æ˜¯å¦æª¢ç´¢KMæ¨è–¦', 'æ˜¯'))  # é»˜èªç‚ºæ˜¯ï¼Œå› ç‚ºæ˜¯å¤±æ•—å•é¡Œ
                    )
                    
                    failed_rows.append(validation_row)
            
            # è¼¸å‡ºè©³ç´°çš„è­˜åˆ¥çµæœ
            self.log_info(f"ğŸ” CSVå¤±æ•—å•é¡Œè­˜åˆ¥çµæœï¼š")
            self.log_info(f"ğŸ“Š ç¸½è¨˜éŒ„æ•¸: {len(df)} ç­†")
            self.log_info(f"âŒ è­˜åˆ¥å‡ºå¤±æ•—å•é¡Œ: {len(failed_rows)} å€‹")
            self.log_info(f"âœ… æˆåŠŸå•é¡Œ: {len(df) - len(failed_rows)} å€‹")
            
            # è¼¸å‡ºæ¯ç­†è¨˜éŒ„çš„è­˜åˆ¥è©³æƒ…
            self.log_info("ğŸ“‹ è©³ç´°è­˜åˆ¥çµæœï¼š")
            for info in debug_info:
                status_icon = "âŒ" if info['æ˜¯å¦å¤±æ•—'] else "âœ…"
                self.log_info(f"{status_icon} {info['ç·¨è™Ÿ']} | {info['æå•è€…']} | {info['å¤±æ•—åŸå› ']} | {info['AIå›è¦†å‰50å­—']}")
            
            self.log_info(f"ğŸ¯ ç¸½çµï¼šå¾ {len(df)} ç­†è¨˜éŒ„ä¸­è­˜åˆ¥å‡º {len(failed_rows)} å€‹å¤±æ•—å•é¡Œ")
            
            # é¡¯ç¤ºå¤±æ•—å•é¡Œçš„è©³ç´°ä¿¡æ¯
            if failed_rows:
                failed_users = {}
                for row in failed_rows:
                    user = row.æå•è€…
                    if user not in failed_users:
                        failed_users[user] = 0
                    failed_users[user] += 1
                
                user_info = ', '.join([f"{user}({count}é¡Œ)" for user, count in failed_users.items()])
                self.log_info(f"å¤±æ•—å•é¡Œåˆ†å¸ƒ: {user_info}")
            
            return failed_rows
            
        except Exception as e:
            self.log_error(f"è¼‰å…¥CSVæ–‡ä»¶å¤±æ•—: {str(e)}")
            raise
    
    def run_retry_validation(self, failed_data, original_csv_file):
        """åŸ·è¡Œé‡æ¸¬é©—è­‰ï¼ˆåœ¨èƒŒæ™¯åŸ·è¡Œç·’ä¸­ï¼‰"""
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            self.log_info(f"é–‹å§‹é‡æ¸¬ {len(failed_data)} å€‹å¤±æ•—å•é¡Œ...")
            
            # åŸ·è¡Œé‡æ¸¬é©—è­‰
            results = loop.run_until_complete(self.process_retry_validation(failed_data))
            
            # è¨ˆç®—çµ±è¨ˆ
            self.log_info("è¨ˆç®—é‡æ¸¬çµ±è¨ˆçµæœ...")
            stats = self.calculate_retry_statistics(results)
            
            # è¼¸å‡ºæ•´åˆçµæœï¼ˆé‡æ¸¬çµæœèˆ‡åŸå§‹CSVæ•´åˆï¼‰
            import os
            import pandas as pd
            base_name = os.path.splitext(original_csv_file)[0]
            
            # ç”Ÿæˆå…©å€‹æ–‡ä»¶ï¼šé‡æ¸¬çµæœå’Œæ•´åˆçµæœ
            retry_only_file = f"{base_name}_retry_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv"
            integrated_file = f"{base_name}_integrated_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv"
            
            self.log_info(f"åŒ¯å‡ºé‡æ¸¬çµæœåˆ° CSV: {retry_only_file}")
            self.export_retry_results(results, retry_only_file, stats)
            
            self.log_info(f"æ•´åˆé‡æ¸¬çµæœèˆ‡åŸå§‹æ•¸æ“š: {integrated_file}")
            self.export_integrated_results(results, original_csv_file, integrated_file, stats)
            
            # æ›´æ–° UI
            self.log_info("é‡æ¸¬å®Œæˆï¼Œæ›´æ–°çµæœé¡¯ç¤º")
            self.root.after(0, lambda: self.show_retry_results(results, stats, retry_only_file, integrated_file))
            
        except Exception as e:
            error_msg = str(e)
            self.root.after(0, lambda: messagebox.showerror("éŒ¯èª¤", f"é‡æ¸¬éç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{error_msg}"))
        finally:
            # é‡è¨­ UI ç‹€æ…‹
            self.root.after(0, lambda: self.reset_retry_ui())
    
    async def process_retry_validation(self, failed_data):
        """è™•ç†é‡æ¸¬é©—è­‰ - å°ˆé–€ç”¨æ–¼é‡æ¸¬å¤±æ•—å•é¡Œ"""
        if not failed_data:
            return []
        
        self.log_info(f"é–‹å§‹é‡æ¸¬ {len(failed_data)} å€‹å¤±æ•—å•é¡Œ")
        
        # æŒ‰æå•è€…åˆ†çµ„
        user_groups = {}
        for row in failed_data:
            user = row.æå•è€…
            if user not in user_groups:
                user_groups[user] = []
            user_groups[user].append(row)
        
        self.log_info(f"é‡æ¸¬ç›®æ¨™: {len(user_groups)} å€‹æå•è€…")
        
        # ä½¿ç”¨æ›´ä¿å®ˆçš„ä½µç™¼è¨­å®šé€²è¡Œé‡æ¸¬
        max_concurrent_users = max(1, self.max_concurrent.get() // 2)
        self.log_info(f"é‡æ¸¬ä½µç™¼è¨­å®š: {max_concurrent_users} å€‹æå•è€…")
        
        # å‰µå»ºé€²åº¦è¿½è¹¤é–
        progress_lock = asyncio.Lock()
        
        # å‰µå»ºçµæœå­—å…¸
        results_dict = {}
        
        async with MaiAgentApiClient(self.api_base_url.get(), self.api_key.get(), self.api_logger_callback) as client:
            # ä½¿ç”¨ Semaphore æ§åˆ¶ä½µç™¼æ•¸é‡
            semaphore = asyncio.Semaphore(max_concurrent_users)
            
            # å‰µå»ºæ¯å€‹æå•è€…çš„è™•ç†ä»»å‹™
            tasks = []
            for user, user_questions in user_groups.items():
                task = self.process_retry_user_questions(client, user, user_questions, semaphore, 
                                                       len(failed_data), progress_lock, results_dict)
                tasks.append(task)
            
            # ä½µç™¼åŸ·è¡Œæ‰€æœ‰æå•è€…çš„ä»»å‹™
            await asyncio.gather(*tasks, return_exceptions=True)
        
        # æ•´ç†çµæœ
        results = []
        for row in failed_data:
            if row.ç·¨è™Ÿ in results_dict:
                results.append(results_dict[row.ç·¨è™Ÿ])
            else:
                # æœªè™•ç†çš„å•é¡Œï¼Œä¿æŒåŸç‹€
                row.AIåŠ©ç†å›è¦† = "é‡æ¸¬æœªå®Œæˆï¼ˆå¯èƒ½è¢«åœæ­¢ï¼‰"
                results.append(row)
        
        return results
    
    async def process_retry_user_questions(self, client, user, user_questions, semaphore, 
                                         total_questions, progress_lock, results_dict):
        """è™•ç†é‡æ¸¬ç”¨æˆ¶å•é¡Œ"""
        async with semaphore:
            if self.validation_stopped:
                return
                
            self.log_info(f"ğŸ”„ é–‹å§‹é‡æ¸¬æå•è€… '{user}' çš„ {len(user_questions)} å€‹å•é¡Œ")
            
            for row in user_questions:
                if self.validation_stopped:
                    break
                    
                try:
                    # ä½¿ç”¨æ›´ä¿å®ˆçš„è¨­å®šè™•ç†å•é¡Œ
                    retry_delay = self.api_delay.get() * 2
                    retry_attempts = min(self.max_retries.get() + 3, 10)
                    
                    result = await self.process_single_question_with_retry(
                        client, row, retry_attempts, retry_delay)
                    
                    # æ›´æ–°çµæœ
                    async with progress_lock:
                        # æ¨™è¨˜ç‚ºé‡æ¸¬æˆåŠŸ
                        result._retry_info = "CSVé‡æ¸¬æˆåŠŸ"
                        results_dict[row.ç·¨è™Ÿ] = result
                        self.completed_questions += 1
                        
                        # æ›´æ–°é€²åº¦é¡¯ç¤º
                        progress_msg = f"[é‡æ¸¬-{user}] å®Œæˆå•é¡Œ {row.ç·¨è™Ÿ} | é€²åº¦ {self.completed_questions}/{total_questions}"
                        self.root.after(0, lambda msg=progress_msg: self.update_progress(
                            self.completed_questions, total_questions, msg))
                    
                    self.log_validation_result(row.ç·¨è™Ÿ, True, 
                                             f"[é‡æ¸¬-{user}] æˆåŠŸï¼Œå›è¦†é•·åº¦: {len(result.AIåŠ©ç†å›è¦†)} å­—å…ƒ")
                    
                except Exception as e:
                    self.log_error(f"é‡æ¸¬æå•è€… '{user}' çš„å•é¡Œ {row.ç·¨è™Ÿ} å¤±æ•—: {str(e)}", 'Retry')
                    
                    # æ¨™è¨˜ç‚ºé‡æ¸¬å¤±æ•—
                    async with progress_lock:
                        row.AIåŠ©ç†å›è¦† = f"é‡æ¸¬ä»å¤±æ•—: {str(e)}"
                        row.precision = 0.0
                        row.recall = 0.0
                        row.f1_score = 0.0
                        row.hit_rate = 0.0
                        row.å¼•ç”¨ç¯€é»æ˜¯å¦å‘½ä¸­ = "å¦"
                        row.åƒè€ƒæ–‡ä»¶æ˜¯å¦æ­£ç¢º = "å¦"
                        row.å›è¦†æ˜¯å¦æ»¿æ„ = "å¦"
                        
                        results_dict[row.ç·¨è™Ÿ] = row
                        self.completed_questions += 1
                        
                        progress_msg = f"[é‡æ¸¬-{user}] å•é¡Œ {row.ç·¨è™Ÿ} ä»å¤±æ•— | é€²åº¦ {self.completed_questions}/{total_questions}"
                        self.root.after(0, lambda msg=progress_msg: self.update_progress(
                            self.completed_questions, total_questions, msg))
                
                # é‡æ¸¬é–“éš”å»¶é²
                if not self.validation_stopped:
                    await asyncio.sleep(retry_delay)
            
            self.log_info(f"ğŸ æå•è€… '{user}' çš„é‡æ¸¬å®Œæˆ")
    
    def calculate_retry_statistics(self, results):
        """è¨ˆç®—é‡æ¸¬çµ±è¨ˆçµæœ"""
        total_queries = len(results)
        if total_queries == 0:
            return {
                'total_retry_queries': 0,
                'retry_success_count': 0,
                'retry_failed_count': 0,
                'retry_success_rate': 0.0
            }
        
        retry_success_count = 0
        retry_failed_count = 0
        
        for row in results:
            if hasattr(row, 'AIåŠ©ç†å›è¦†') and row.AIåŠ©ç†å›è¦†:
                if (row.AIåŠ©ç†å›è¦†.startswith("é‡æ¸¬ä»å¤±æ•—:") or 
                    row.AIåŠ©ç†å›è¦† == "é‡æ¸¬æœªå®Œæˆï¼ˆå¯èƒ½è¢«åœæ­¢ï¼‰"):
                    retry_failed_count += 1
                else:
                    retry_success_count += 1
        
        return {
            'total_retry_queries': total_queries,
            'retry_success_count': retry_success_count,
            'retry_failed_count': retry_failed_count,
            'retry_success_rate': (retry_success_count / total_queries * 100) if total_queries > 0 else 0.0
        }
    
    def export_retry_results(self, results, output_file, stats):
        """è¼¸å‡ºé‡æ¸¬çµæœåˆ° CSV"""
        import pandas as pd
        
        output_data = []
        
        try:
            for row in results:
                try:
                    # åŸºæœ¬ä¿¡æ¯
                    row_data = {
                        'ç·¨è™Ÿ': str(row.ç·¨è™Ÿ),
                        'æå•è€…': str(row.æå•è€…),
                        'å•é¡Œæè¿°': str(row.å•é¡Œæè¿°),
                        'å»ºè­° or æ­£ç¢ºç­”æ¡ˆ (if have)': str(row.å»ºè­°_or_æ­£ç¢ºç­”æ¡ˆ),
                        'æ‡‰åƒè€ƒçš„æ–‡ä»¶': str(row.æ‡‰åƒè€ƒçš„æ–‡ä»¶),
                        'æ‡‰åƒè€ƒçš„æ–‡ä»¶æ®µè½': str(row.æ‡‰åƒè€ƒçš„æ–‡ä»¶æ®µè½),
                        'æ˜¯å¦æª¢ç´¢KMæ¨è–¦': str(row.æ˜¯å¦æª¢ç´¢KMæ¨è–¦),
                        'AIåŠ©ç†å›è¦†': str(row.AIåŠ©ç†å›è¦†),
                        'å¼•ç”¨ç¯€é»æ˜¯å¦å‘½ä¸­': str(row.å¼•ç”¨ç¯€é»æ˜¯å¦å‘½ä¸­),
                        'åƒè€ƒæ–‡ä»¶æ˜¯å¦æ­£ç¢º': str(row.åƒè€ƒæ–‡ä»¶æ˜¯å¦æ­£ç¢º),
                        'å›è¦†æ˜¯å¦æ»¿æ„': str(row.å›è¦†æ˜¯å¦æ»¿æ„),
                        # é‡æ¸¬æ¨™è¨˜
                        'é‡æ¸¬ç‹€æ…‹': 'æˆåŠŸ' if not (row.AIåŠ©ç†å›è¦†.startswith("é‡æ¸¬ä»å¤±æ•—:") or 
                                                  row.AIåŠ©ç†å›è¦† == "é‡æ¸¬æœªå®Œæˆï¼ˆå¯èƒ½è¢«åœæ­¢ï¼‰") else 'å¤±æ•—'
                    }
                    
                    output_data.append(row_data)
                    
                except Exception as e:
                    self.log_warning(f"è¼¸å‡ºé‡æ¸¬è¨˜éŒ„å¤±æ•— [{row.ç·¨è™Ÿ if hasattr(row, 'ç·¨è™Ÿ') else 'Unknown'}]: {str(e)}")
                    continue
            
            # å‰µå»º DataFrame ä¸¦å¯«å…¥ CSV
            df = pd.DataFrame(output_data)
            df.to_csv(output_file, index=False, encoding='utf-8-sig')
            
            self.log_info(f"é‡æ¸¬çµæœå·²è¼¸å‡ºåˆ°: {output_file}")
            self.log_info(f"é‡æ¸¬çµ±è¨ˆ: æˆåŠŸ {stats['retry_success_count']} é¡Œ, å¤±æ•— {stats['retry_failed_count']} é¡Œ")
            
        except Exception as e:
            self.log_error(f"è¼¸å‡ºé‡æ¸¬çµæœå¤±æ•—: {str(e)}")
            raise
    
    def export_integrated_results(self, retry_results, original_csv_file, output_file, stats):
        """è¼¸å‡ºæ•´åˆçµæœåˆ°CSVï¼ˆé‡æ¸¬çµæœèˆ‡åŸå§‹æ•¸æ“šæ•´åˆï¼‰"""
        import pandas as pd
        
        try:
            # è®€å–åŸå§‹CSVæ–‡ä»¶
            self.log_info("è®€å–åŸå§‹CSVæ–‡ä»¶...")
            original_df = self._read_csv_with_encoding_detection(original_csv_file)
            
            # å‰µå»ºé‡æ¸¬çµæœæ˜ å°„ï¼ˆä»¥ç·¨è™Ÿç‚ºéµï¼‰
            retry_map = {}
            for row in retry_results:
                retry_map[str(row.ç·¨è™Ÿ)] = row
            
            # æ•´åˆæ•¸æ“š
            integrated_data = []
            updated_count = 0
            
            for _, original_row in original_df.iterrows():
                row_id = str(original_row.get('ç·¨è™Ÿ', ''))
                
                # æª¢æŸ¥æ˜¯å¦æœ‰é‡æ¸¬çµæœ
                if row_id in retry_map:
                    retry_row = retry_map[row_id]
                    updated_count += 1
                    
                    # ä½¿ç”¨é‡æ¸¬å¾Œçš„æ•¸æ“š
                    row_data = {
                        'ç·¨è™Ÿ': str(retry_row.ç·¨è™Ÿ),
                        'æå•è€…': str(retry_row.æå•è€…),
                        'å•é¡Œæè¿°': str(retry_row.å•é¡Œæè¿°),
                        'å»ºè­° or æ­£ç¢ºç­”æ¡ˆ (if have)': str(retry_row.å»ºè­°_or_æ­£ç¢ºç­”æ¡ˆ),
                        'æ‡‰åƒè€ƒçš„æ–‡ä»¶': str(retry_row.æ‡‰åƒè€ƒçš„æ–‡ä»¶),
                        'æ‡‰åƒè€ƒçš„æ–‡ä»¶æ®µè½': str(retry_row.æ‡‰åƒè€ƒçš„æ–‡ä»¶æ®µè½),
                        'æ˜¯å¦æª¢ç´¢KMæ¨è–¦': str(retry_row.æ˜¯å¦æª¢ç´¢KMæ¨è–¦),
                        'AIåŠ©ç†å›è¦†': str(retry_row.AIåŠ©ç†å›è¦†),
                        'å¼•ç”¨ç¯€é»æ˜¯å¦å‘½ä¸­': str(retry_row.å¼•ç”¨ç¯€é»æ˜¯å¦å‘½ä¸­),
                        'åƒè€ƒæ–‡ä»¶æ˜¯å¦æ­£ç¢º': str(retry_row.åƒè€ƒæ–‡ä»¶æ˜¯å¦æ­£ç¢º),
                        'å›è¦†æ˜¯å¦æ»¿æ„': str(retry_row.å›è¦†æ˜¯å¦æ»¿æ„),
                        'é‡æ¸¬ç‹€æ…‹': 'é‡æ¸¬æˆåŠŸ' if not (retry_row.AIåŠ©ç†å›è¦†.startswith("é‡æ¸¬ä»å¤±æ•—:") or 
                                                  retry_row.AIåŠ©ç†å›è¦† == "é‡æ¸¬æœªå®Œæˆï¼ˆå¯èƒ½è¢«åœæ­¢ï¼‰") else 'é‡æ¸¬å¤±æ•—'
                    }
                    
                    # å¦‚æœæœ‰RAGæŒ‡æ¨™ï¼Œä¹Ÿè¦æ›´æ–°
                    if hasattr(retry_row, 'Precision'):
                        row_data['Precision'] = getattr(retry_row, 'Precision', 0.0)
                        row_data['Recall'] = getattr(retry_row, 'Recall', 0.0)
                        row_data['F1-Score'] = getattr(retry_row, 'F1-Score', 0.0)
                        row_data['Hit Rate'] = getattr(retry_row, 'Hit Rate', 0.0)
                    
                else:
                    # ä½¿ç”¨åŸå§‹æ•¸æ“šï¼Œä½†æ·»åŠ é‡æ¸¬ç‹€æ…‹æ¨™è¨˜
                    row_data = {}
                    for col in original_df.columns:
                        row_data[col] = str(original_row.get(col, ''))
                    
                    # å¦‚æœæ²’æœ‰é‡æ¸¬ç‹€æ…‹æ¬„ä½ï¼Œæ–°å¢ä¸€å€‹
                    if 'é‡æ¸¬ç‹€æ…‹' not in row_data:
                        row_data['é‡æ¸¬ç‹€æ…‹'] = 'æœªé‡æ¸¬'
                
                integrated_data.append(row_data)
            
            # å‰µå»º DataFrame ä¸¦å¯«å…¥ CSV
            df = pd.DataFrame(integrated_data)
            df.to_csv(output_file, index=False, encoding='utf-8-sig')
            
            self.log_info(f"âœ… æ•´åˆçµæœå·²è¼¸å‡ºåˆ°: {output_file}")
            self.log_info(f"ğŸ“Š æ•´åˆçµ±è¨ˆ: åŸå§‹è¨˜éŒ„ {len(original_df)} ç­†, é‡æ¸¬æ›´æ–° {updated_count} ç­†")
            self.log_info(f"ğŸ”„ é‡æ¸¬çµæœ: æˆåŠŸ {stats['retry_success_count']} é¡Œ, å¤±æ•— {stats['retry_failed_count']} é¡Œ")
            
            return output_file
            
        except Exception as e:
            self.log_error(f"è¼¸å‡ºæ•´åˆçµæœå¤±æ•—: {str(e)}")
            raise
    
    def show_retry_results(self, results, stats, retry_file, integrated_file=None):
        """é¡¯ç¤ºé‡æ¸¬çµæœ"""
        if hasattr(self, 'stats_text'):
            self.stats_text.config(state='normal')
            self.stats_text.delete(1.0, tk.END)
            
            # æ ¹æ“šæ˜¯å¦æœ‰æ•´åˆæ–‡ä»¶æ±ºå®šé¡¯ç¤ºå…§å®¹
            if integrated_file:
                stats_str = f"""=== é‡æ¸¬é©—è­‰çµ±è¨ˆçµæœ ===
ç¸½é‡æ¸¬å•é¡Œæ•¸: {stats['total_retry_queries']}
é‡æ¸¬æˆåŠŸæ•¸: {stats['retry_success_count']}
é‡æ¸¬å¤±æ•—æ•¸: {stats['retry_failed_count']}
é‡æ¸¬æˆåŠŸç‡: {stats['retry_success_rate']:.2f}%

ğŸ”„ é‡æ¸¬çµæœæ–‡ä»¶: {retry_file}
ğŸ“‹ æ•´åˆå®Œæ•´æ–‡ä»¶: {integrated_file}
"""
            else:
                stats_str = f"""=== é‡æ¸¬é©—è­‰çµ±è¨ˆçµæœ ===
ç¸½é‡æ¸¬å•é¡Œæ•¸: {stats['total_retry_queries']}
é‡æ¸¬æˆåŠŸæ•¸: {stats['retry_success_count']}
é‡æ¸¬å¤±æ•—æ•¸: {stats['retry_failed_count']}
é‡æ¸¬æˆåŠŸç‡: {stats['retry_success_rate']:.2f}%

é‡æ¸¬çµæœå·²è¼¸å‡ºåˆ°: {retry_file}
"""
            
            self.stats_text.insert(1.0, stats_str)
            self.stats_text.config(state='disabled')
        
        # é¡¯ç¤ºæˆåŠŸè¨Šæ¯
        if integrated_file:
            messagebox.showinfo(
                "é‡æ¸¬å®Œæˆ", 
                f"é‡æ¸¬å®Œæˆï¼\n\n"
                f"ç¸½å•é¡Œæ•¸: {stats['total_retry_queries']}\n"
                f"æˆåŠŸ: {stats['retry_success_count']} é¡Œ\n"
                f"å¤±æ•—: {stats['retry_failed_count']} é¡Œ\n"
                f"æˆåŠŸç‡: {stats['retry_success_rate']:.1f}%\n\n"
                f"ğŸ”„ é‡æ¸¬çµæœæ–‡ä»¶: {retry_file}\n"
                f"ğŸ“‹ æ•´åˆå®Œæ•´æ–‡ä»¶: {integrated_file}\n\n"
                f"æ•´åˆæ–‡ä»¶åŒ…å«æ‰€æœ‰åŸå§‹è¨˜éŒ„å’Œé‡æ¸¬æ›´æ–°ï¼"
            )
        else:
            messagebox.showinfo(
                "é‡æ¸¬å®Œæˆ", 
                f"é‡æ¸¬å®Œæˆï¼\n\n"
                f"ç¸½å•é¡Œæ•¸: {stats['total_retry_queries']}\n"
                f"æˆåŠŸ: {stats['retry_success_count']} é¡Œ\n"
                f"å¤±æ•—: {stats['retry_failed_count']} é¡Œ\n"
                f"æˆåŠŸç‡: {stats['retry_success_rate']:.1f}%\n\n"
                f"çµæœå·²ä¿å­˜åˆ°: {retry_file}"
            )
    
    def reset_retry_ui(self):
        """é‡è¨­é‡æ¸¬UIç‹€æ…‹"""
        self.retry_failed_button.config(state='normal')
        self.start_button.config(state='normal')
        self.stop_button.config(state='disabled')
        self.progress_label.config(text="é‡æ¸¬å®Œæˆ")
    
    async def process_user_questions(self, client, user, user_questions, semaphore, total_questions, progress_lock, results_dict):
        """è™•ç†å–®å€‹æå•è€…çš„æ‰€æœ‰å•é¡Œ"""
        async with semaphore:  # æ§åˆ¶ä½µç™¼æ•¸é‡
            self.log_info(f"é–‹å§‹è™•ç†æå•è€… '{user}' çš„ {len(user_questions)} å€‹å•é¡Œ")
            
            for i, row in enumerate(user_questions):
                # æª¢æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
                if self.validation_stopped:
                    self.log_warning(f"æå•è€… '{user}' çš„è™•ç†å·²åœæ­¢")
                    break
                
                try:
                    # è™•ç†å–®å€‹å•é¡Œ
                    result = await self.process_single_question(client, row)
                    
                    # ç·šç¨‹å®‰å…¨åœ°æ›´æ–°çµæœå’Œé€²åº¦
                    async with progress_lock:
                        results_dict[row.ç·¨è™Ÿ] = result
                        self.completed_questions += 1
                        
                        # æ›´æ–°é€²åº¦é¡¯ç¤º
                        progress_msg = f"[{user}] å®Œæˆå•é¡Œ {row.ç·¨è™Ÿ} | ç¸½é€²åº¦ {self.completed_questions}/{total_questions}"
                        self.root.after(0, lambda msg=progress_msg: self.update_progress(self.completed_questions, total_questions, msg))
                    
                    # è¨˜éŒ„æˆåŠŸ
                    self.log_validation_result(row.ç·¨è™Ÿ, True, f"[{user}] å›è¦†é•·åº¦: {len(result.AIåŠ©ç†å›è¦†)} å­—å…ƒ")
                    
                except Exception as e:
                    self.log_error(f"è™•ç†æå•è€… '{user}' çš„å•é¡Œ {row.ç·¨è™Ÿ} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}", 'Validation')
                    # å³ä½¿å‡ºéŒ¯ä¹Ÿè¦æ›´æ–°é€²åº¦ï¼Œä¸¦ç¢ºä¿ row å…·æœ‰æ‰€æœ‰å¿…è¦çš„å±¬æ€§
                    async with progress_lock:
                        row.AIåŠ©ç†å›è¦† = f"éŒ¯èª¤: {str(e)}"
                        
                        # ç¢ºä¿éŒ¯èª¤çš„ row å…·æœ‰æ‰€æœ‰çµ±è¨ˆå±¬æ€§
                        row.precision = 0.0
                        row.recall = 0.0
                        row.f1_score = 0.0
                        row.hit_rate = 0.0
                        row.å¼•ç”¨ç¯€é»æ˜¯å¦å‘½ä¸­ = "å¦"
                        row.åƒè€ƒæ–‡ä»¶æ˜¯å¦æ­£ç¢º = "å¦"
                        row.å›è¦†æ˜¯å¦æ»¿æ„ = "å¦"
                        
                        results_dict[row.ç·¨è™Ÿ] = row
                        self.completed_questions += 1
                        
                        progress_msg = f"[{user}] è™•ç†å•é¡Œ {row.ç·¨è™Ÿ} (éŒ¯èª¤) | ç¸½é€²åº¦ {self.completed_questions}/{total_questions}"
                        self.root.after(0, lambda msg=progress_msg: self.update_progress(self.completed_questions, total_questions, msg))
            
            self.log_info(f"æå•è€… '{user}' è™•ç†å®Œæˆ")
        
    async def process_single_question(self, client, validation_row):
        """è™•ç†å–®å€‹å•é¡Œ"""
        # ç²å–æˆ–å‰µå»ºå°è©±
        conversation_id = self.conversation_manager.get_conversation_id(validation_row.æå•è€…)
        
        # æ§‹å»ºè¦ç™¼é€çš„å•é¡Œå…§å®¹
        if conversation_id is None:
            # é€™æ˜¯æ–°å°è©±ï¼Œæª¢æŸ¥æ˜¯å¦éœ€è¦çµ„åˆå‰é¢çš„å•é¡Œ
            if self.enable_context_combination.get():
                message_content = self.conversation_manager.build_context_message(
                    validation_row.æå•è€…, 
                    validation_row.å•é¡Œæè¿°
                )
                
                # è¨˜éŒ„ä¸Šä¸‹æ–‡æ§‹å»ºæƒ…æ³
                previous_questions = self.conversation_manager.get_context_questions(validation_row.æå•è€…)
                if previous_questions:
                    self.log_info(
                        f"æå•è€… '{validation_row.æå•è€…}' é–‹å§‹æ–°å°è©±ï¼Œçµ„åˆäº† {len(previous_questions)} å€‹å‰é¢çš„å•é¡Œ", 
                        'Validation'
                    )
                else:
                    self.log_info(
                        f"æå•è€… '{validation_row.æå•è€…}' é–‹å§‹æ–°å°è©±ï¼Œæ²’æœ‰å‰é¢çš„å•é¡Œ", 
                        'Validation'
                    )
            else:
                # ä¸Šä¸‹æ–‡çµ„åˆå·²åœç”¨ï¼Œç›´æ¥ä½¿ç”¨ç•¶å‰å•é¡Œ
                message_content = validation_row.å•é¡Œæè¿°
                self.log_info(
                    f"æå•è€… '{validation_row.æå•è€…}' é–‹å§‹æ–°å°è©±ï¼ˆä¸Šä¸‹æ–‡çµ„åˆå·²åœç”¨ï¼‰", 
                    'Validation'
                )
        else:
            # é€™æ˜¯å·²å­˜åœ¨å°è©±çš„å»¶çºŒï¼Œç›´æ¥ä½¿ç”¨ç•¶å‰å•é¡Œ
            message_content = validation_row.å•é¡Œæè¿°
            self.log_info(
                f"æå•è€… '{validation_row.æå•è€…}' ç¹¼çºŒç¾æœ‰å°è©± {conversation_id}", 
                'Validation'
            )
        
        # å°‡ç•¶å‰å•é¡Œæ·»åŠ åˆ°ä¸Šä¸‹æ–‡ä¸­ï¼ˆç”¨æ–¼å¾ŒçºŒå•é¡Œï¼‰
        self.conversation_manager.add_question_to_context(validation_row.æå•è€…, validation_row.å•é¡Œæè¿°)
        
        # æ§‹å»º query_metadataï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
        query_metadata = None
        if self.enable_query_metadata.get() and self.knowledge_base_id.get().strip():
            knowledge_bases = [
                {
                    "knowledge_base_id": self.knowledge_base_id.get().strip(),
                    "has_user_selected_all": True
                }
            ]
            
            query_metadata = {
                "knowledge_bases": knowledge_bases
            }
            
            # å¦‚æœæä¾›äº†æ¨™ç±¤IDï¼Œæ·»åŠ æ¨™ç±¤éæ¿¾
            if self.label_id.get().strip():
                query_metadata["label_relations"] = {
                    "operator": "OR",
                    "conditions": [
                        {"label_id": self.label_id.get().strip()}
                    ]
                }
            
            self.log_info(f"ä½¿ç”¨ Query Metadata: {query_metadata}", 'Validation')
        
        # ç™¼é€å•é¡Œï¼ˆä½¿ç”¨é‡è©¦æ©Ÿåˆ¶ï¼‰
        response = await client.send_message(
            self.selected_chatbot_id, 
            message_content,  # ä½¿ç”¨æ§‹å»ºçš„å®Œæ•´å…§å®¹
            conversation_id,
            max_retries=self.max_retries.get(),
            query_metadata=query_metadata
        )
        
        # æ›´æ–°å°è©± ID
        self.conversation_manager.set_conversation_id(validation_row.æå•è€…, response.conversation_id)
        
        # å¡«å…¥å›è¦†çµæœ
        validation_row.AIåŠ©ç†å›è¦† = response.content
        validation_row._raw_citation_nodes = response.citation_nodes
        validation_row._raw_citations = response.citations
        
        # å‹•æ…‹æ·»åŠ å¼•ç”¨ç¯€é»æ¬„ä½
        self._add_citation_node_fields(validation_row, response.citation_nodes)
        
        # å‹•æ…‹æ·»åŠ åƒè€ƒæ–‡ä»¶æ¬„ä½
        self._add_citation_file_fields(validation_row, response.citations)
        
        # é€²è¡Œæ–‡å­—æ¯”å°é©—è­‰ï¼ˆå›ºå®šä½¿ç”¨ RAG å¢å¼·æ¨¡å¼ï¼‰
        # å‹•æ…‹æ ¹æ“šå¯¦éš›å›å‚³çš„å¼•ç”¨ç¯€é»æ•¸é‡æ±ºå®šç‰‡æ®µæ•¸
        actual_chunks_count = len(response.citation_nodes) if response.citation_nodes else 0
        
        citation_hit, rag_result = self.text_matcher.check_rag_enhanced_hit(
            response.citation_nodes, 
            validation_row.æ‡‰åƒè€ƒçš„æ–‡ä»¶æ®µè½,
            self.similarity_threshold.get(),
            actual_chunks_count,  # ä½¿ç”¨å¯¦éš›å›å‚³çš„ç¯€é»æ•¸é‡
            self.get_selected_separators(),  # ä½¿ç”¨ç”¨æˆ¶é¸æ“‡çš„åˆ†éš”ç¬¦
            self.similarity_mode.get()  # ä½¿ç”¨ç”¨æˆ¶é¸æ“‡çš„ç›¸ä¼¼åº¦è¨ˆç®—æ¨¡å¼
        )
        
        # å„²å­˜è©³ç´°æŒ‡æ¨™
        validation_row.precision = rag_result.get('precision', 0.0)
        validation_row.recall = rag_result.get('recall', 0.0)
        validation_row.f1_score = rag_result.get('f1_score', 0.0)
        validation_row.hit_rate = rag_result.get('hit_rate', 0.0)
        
        validation_row.å¼•ç”¨ç¯€é»æ˜¯å¦å‘½ä¸­ = "æ˜¯" if citation_hit else "å¦"
        
        # åƒ…ä½¿ç”¨æ‡‰åƒè€ƒæ–‡ä»¶UUIDé€²è¡ŒåŒ¹é…
        expected_files = validation_row.æ‡‰åƒè€ƒæ–‡ä»¶UUID.strip()
        
        if expected_files:
            file_match, file_stats = self.text_matcher.check_citation_file_match(
                response.citations,
                expected_files
            )
            validation_row.åƒè€ƒæ–‡ä»¶æ˜¯å¦æ­£ç¢º = "æ˜¯" if file_match else "å¦"
        else:
            # å¦‚æœæ²’æœ‰UUIDï¼Œè·³éæ–‡ä»¶åŒ¹é…
            file_match = False
            file_stats = {
                "detail": "ç„¡UUIDè³‡æ–™ï¼Œè·³éæ–‡ä»¶åŒ¹é…",
                "total_expected": 0,
                "total_matched": 0,
                "hit_rate": 0.0,
                "matched_files": [],
                "unmatched_files": [],
                "all_matched": False
            }
            validation_row.åƒè€ƒæ–‡ä»¶æ˜¯å¦æ­£ç¢º = "æœªæª¢æ¸¬"
        
        # å„²å­˜åƒè€ƒæ–‡ä»¶å‘½ä¸­çµ±è¨ˆæ•¸æ“š
        validation_row.åƒè€ƒæ–‡ä»¶å‘½ä¸­ç‡ = file_stats.get('hit_rate', 0.0)
        validation_row.æœŸæœ›æ–‡ä»¶ç¸½æ•¸ = file_stats.get('total_expected', 0)
        validation_row.å‘½ä¸­æ–‡ä»¶æ•¸ = file_stats.get('total_matched', 0)
        
        # UUIDæ ¼å¼çš„å‘½ä¸­å’Œæœªå‘½ä¸­æ–‡ä»¶ä¿¡æ¯
        matched_files = file_stats.get('matched_files', [])
        validation_row.å‘½ä¸­æ–‡ä»¶ = ', '.join(matched_files) if matched_files else ""
        
        unmatched_files = file_stats.get('unmatched_files', [])
        validation_row.æœªå‘½ä¸­æ–‡ä»¶ = ', '.join(unmatched_files) if unmatched_files else ""
        
        # å›è¦†æ˜¯å¦æ»¿æ„ä¿æŒç©ºç™½ï¼Œä¾›å®¢æˆ¶æ‰‹å‹•è¼¸å…¥
        # validation_row.å›è¦†æ˜¯å¦æ»¿æ„ é è¨­ç‚ºç©ºå­—ä¸²ï¼Œä¸è‡ªå‹•å¡«å¯«
        
        # API å‘¼å«å»¶é²ï¼ˆé¿å…è§¸ç™¼é™æµï¼‰
        delay_time = self.api_delay.get()
        if delay_time > 0:
            await asyncio.sleep(delay_time)
                        
        return validation_row

    def _add_citation_node_fields(self, validation_row, citation_nodes):
        """å‹•æ…‹æ·»åŠ å¼•ç”¨ç¯€é»æ¬„ä½"""
        for i, node in enumerate(citation_nodes, 1):
            chinese_num = self.get_chinese_number(i)
            field_name = f'å¼•ç”¨ç¯€é»{chinese_num}'
            
            # æå–ç¯€é»æ–‡æœ¬å…§å®¹
            content = ""
            if 'chatbotTextNode' in node and 'text' in node['chatbotTextNode']:
                content = node['chatbotTextNode']['text']
            elif 'content' in node.get('chatbotTextNode', {}):
                content = node['chatbotTextNode']['content']
            elif 'text' in node:
                content = node['text']
            
            # å‹•æ…‹æ·»åŠ åˆ° validation_row ç‰©ä»¶
            setattr(validation_row, field_name, content)

    def _add_citation_file_fields(self, validation_row, citations):
        """å‹•æ…‹æ·»åŠ åƒè€ƒæ–‡ä»¶æ¬„ä½ï¼ˆä½¿ç”¨æ–‡ä»¶UUIDï¼Œéæ¿¾é‡è¤‡ï¼‰"""
        # æ”¶é›†æ‰€æœ‰æ–‡ä»¶UUIDï¼Œè‡ªå‹•éæ¿¾é‡è¤‡
        unique_file_ids = set()
        
        for citation in citations:
            file_id = citation.get('id', '').strip()
            if file_id:  # åªæ·»åŠ éç©ºUUID
                unique_file_ids.add(file_id)
        
        # å°‡UUIDè½‰æ›ç‚ºæ’åºçš„åˆ—è¡¨
        file_id_list = sorted(list(unique_file_ids))
        
        # ç‚ºæ¯å€‹æ–‡ä»¶UUIDæ·»åŠ ç¨ç«‹æ¬„ä½
        for i, file_id in enumerate(file_id_list, 1):
            chinese_num = self.get_chinese_number(i)
            field_name = f'åƒè€ƒæ–‡ä»¶{chinese_num}'
            setattr(validation_row, field_name, file_id)

    def calculate_statistics(self, results):
        """è¨ˆç®—å¢å¼·çµ±è¨ˆçµæœ"""
        total_queries = len(results)
        if total_queries == 0:
            return {
                'total_queries': 0, 
                'citation_hit_rate': 0.0, 
                'file_match_rate': 0.0, 
                'top_10_hit_rate': 0.0,
                'avg_precision': 0.0,
                'avg_recall': 0.0,
                'avg_f1_score': 0.0,
                'avg_hit_rate': 0.0,
                'total_expected_segments': 0,
                'total_hit_segments': 0,
                'total_retrieved_chunks': 0,
                # åƒè€ƒæ–‡ä»¶çµ±è¨ˆ
                'avg_file_hit_rate': 0.0,
                'total_expected_files': 0,
                'total_matched_files': 0,
                'file_level_hit_rate': 0.0,
                # é‡è©¦çµ±è¨ˆ
                'retry_success_count': 0,
                'retry_failed_count': 0,
                'original_failed_count': 0
            }
        
        # åŸºæœ¬çµ±è¨ˆ
        citation_hits = sum(1 for row in results if row.å¼•ç”¨ç¯€é»æ˜¯å¦å‘½ä¸­ == "æ˜¯")
        file_matches = sum(1 for row in results if row.åƒè€ƒæ–‡ä»¶æ˜¯å¦æ­£ç¢º == "æ˜¯")
        
        # RAG å¢å¼·çµ±è¨ˆ
        total_precision = sum(row.precision for row in results)
        total_recall = sum(row.recall for row in results)
        total_f1_score = sum(row.f1_score for row in results)
        total_hit_rate = sum(row.hit_rate for row in results)
        
        # è¨ˆç®—æ®µè½ç´šçµ±è¨ˆ
        total_expected_segments = 0
        total_hit_segments = 0
        total_retrieved_chunks = 0
        total_relevant_chunks = 0
        
        for row in results:
            if row.æ‡‰åƒè€ƒçš„æ–‡ä»¶æ®µè½:
                expected_segments = self.text_matcher.parse_expected_segments(row.æ‡‰åƒè€ƒçš„æ–‡ä»¶æ®µè½)
                total_expected_segments += len(expected_segments)
                total_hit_segments += int(row.hit_rate * len(expected_segments))
                
                # ç´¯è¨ˆæª¢ç´¢ç›¸é—œçµ±è¨ˆï¼ˆRAG æ¨¡å¼å›ºå®šå•Ÿç”¨ï¼‰
                if row.precision > 0:
                    # æ³¨ï¼šretrieved_chunks æ•¸é‡åœ¨å„å€‹æŸ¥è©¢ä¸­å¯èƒ½ä¸åŒï¼ˆå‹•æ…‹èª¿æ•´ï¼‰
                    # é€™è£¡åªè¨˜éŒ„æœ‰æ•ˆçš„ç²¾ç¢ºåº¦å’Œå¬å›ç‡
                    pass
        
        # è¨ˆç®—åƒè€ƒæ–‡ä»¶çµ±è¨ˆ
        total_expected_files = sum(row.æœŸæœ›æ–‡ä»¶ç¸½æ•¸ for row in results)
        total_matched_files = sum(row.å‘½ä¸­æ–‡ä»¶æ•¸ for row in results)
        total_file_hit_rate = sum(row.åƒè€ƒæ–‡ä»¶å‘½ä¸­ç‡ for row in results)
        
        # è¨ˆç®—é‡è©¦çµ±è¨ˆ
        retry_success_count = 0
        retry_failed_count = 0
        original_failed_count = 0
        
        for row in results:
            if hasattr(row, 'AIåŠ©ç†å›è¦†') and row.AIåŠ©ç†å›è¦†:
                if row.AIåŠ©ç†å›è¦†.startswith("éŒ¯èª¤:") or "API è«‹æ±‚åœ¨" in row.AIåŠ©ç†å›è¦†:
                    original_failed_count += 1
                elif row.AIåŠ©ç†å›è¦†.startswith("é‡è©¦å¤±æ•—:"):
                    retry_failed_count += 1
                elif "é‡è©¦æˆåŠŸ" in getattr(row, '_retry_info', ''):  # å¦‚æœæœ‰é‡è©¦æ¨™è¨˜
                    retry_success_count += 1
        
        return {
            'total_queries': total_queries,
            'citation_hit_rate': citation_hits / total_queries * 100,
            'file_match_rate': file_matches / total_queries * 100,
            'top_10_hit_rate': citation_hits / total_queries * 100,  # å‚³çµ±è¨ˆç®—
            'avg_precision': total_precision / total_queries * 100,
            'avg_recall': total_recall / total_queries * 100,
            'avg_f1_score': total_f1_score / total_queries * 100,
            'avg_hit_rate': total_hit_rate / total_queries * 100,  # æ®µè½ç´šå‘½ä¸­ç‡
            'segment_level_hit_rate': (total_hit_segments / total_expected_segments * 100) if total_expected_segments > 0 else 0.0,
            'total_expected_segments': total_expected_segments,
            'total_hit_segments': total_hit_segments,
            'total_retrieved_chunks': total_retrieved_chunks,
            # æ–°å¢åƒè€ƒæ–‡ä»¶çµ±è¨ˆ
            'avg_file_hit_rate': total_file_hit_rate / total_queries * 100,
            'total_expected_files': total_expected_files,
            'total_matched_files': total_matched_files,
            'file_level_hit_rate': (total_matched_files / total_expected_files * 100) if total_expected_files > 0 else 0.0,
            # é‡è©¦çµ±è¨ˆ
            'retry_success_count': retry_success_count,
            'retry_failed_count': retry_failed_count,
            'original_failed_count': original_failed_count,
            'rag_mode_enabled': True  # å›ºå®šå•Ÿç”¨ RAG æ¨¡å¼
        }
        
    def export_results(self, results, output_file, stats):
        """è¼¸å‡ºçµæœåˆ° CSVï¼ˆåŒ…å«åˆ†å‰²çš„æ®µè½æ¬„ä½å’Œå‹•æ…‹å¼•ç”¨ç¯€é»/åƒè€ƒæ–‡ä»¶æ¬„ä½ï¼‰"""
        selected_separators = self.get_selected_separators()
        output_data = []
        failed_rows = 0
        
        try:
            # å…ˆåˆ†ææ‰€æœ‰è¡Œï¼Œæ‰¾å‡ºæœ€å¤§æ®µè½æ•¸é‡
            max_segments = 1
            for row in results:
                try:
                    segments = self.split_segments_for_export(row.æ‡‰åƒè€ƒçš„æ–‡ä»¶æ®µè½, selected_separators)
                    max_segments = max(max_segments, len(segments))
                except Exception as e:
                    self.log_warning(f"åˆ†ææ®µè½å¤±æ•— [{row.ç·¨è™Ÿ}]: {str(e)}")
                    continue
            
            # åˆ†ææ‰€æœ‰è¡Œï¼Œæ‰¾å‡ºæœ€å¤§å¼•ç”¨ç¯€é»å’Œåƒè€ƒæ–‡ä»¶æ•¸é‡
            max_citation_nodes = 0
            max_citation_files = 0
            
            for row in results:
                try:
                    # è¨ˆç®—å¼•ç”¨ç¯€é»æ•¸é‡
                    citation_count = 0
                    for i in range(1, 20):  # å‡è¨­æœ€å¤šä¸æœƒè¶…é20å€‹
                        chinese_num = self.get_chinese_number(i)
                        field_name = f'å¼•ç”¨ç¯€é»{chinese_num}'
                        if hasattr(row, field_name):
                            citation_count = i
                        else:
                            break
                    max_citation_nodes = max(max_citation_nodes, citation_count)
                    
                    # è¨ˆç®—åƒè€ƒæ–‡ä»¶æ•¸é‡
                    file_count = 0
                    for i in range(1, 20):  # å‡è¨­æœ€å¤šä¸æœƒè¶…é20å€‹
                        chinese_num = self.get_chinese_number(i)
                        field_name = f'åƒè€ƒæ–‡ä»¶{chinese_num}'
                        if hasattr(row, field_name):
                            file_count = i
                        else:
                            break
                    max_citation_files = max(max_citation_files, file_count)
                except Exception as e:
                    self.log_warning(f"åˆ†æå¼•ç”¨ç¯€é»å¤±æ•— [{row.ç·¨è™Ÿ}]: {str(e)}")
                    continue
            
            self.log_info(f"æª¢æ¸¬åˆ°æœ€å¤§æ®µè½æ•¸é‡: {max_segments}ï¼Œå¼•ç”¨ç¯€é»æ•¸é‡: {max_citation_nodes}ï¼Œåƒè€ƒæ–‡ä»¶æ•¸é‡: {max_citation_files}")
            
            for row in results:
                try:
                    # æ¸…ç†å’Œå®‰å…¨åŒ–å­—ç¬¦ä¸²å…§å®¹
                    def safe_string(value):
                        if value is None:
                            return ''
                        str_value = str(value)
                        
                        # æŒ‰æ­£ç¢ºé †åºè½‰ç¾©ç‰¹æ®Šå­—ç¬¦ï¼Œé¿å…é‡è¤‡è½‰ç¾©
                        str_value = str_value.replace('&', '&amp;')  # é¦–å…ˆè™•ç† & å­—ç¬¦
                        str_value = str_value.replace('<', '&lt;')   # è½‰ç¾©å°æ–¼è™Ÿï¼ˆé˜²æ­¢ XML æ¨™ç±¤éŒ¯èª¤ï¼‰
                        str_value = str_value.replace('>', '&gt;')   # è½‰ç¾©å¤§æ–¼è™Ÿ
                        str_value = str_value.replace('"', '&quot;') # è½‰ç¾©é›™å¼•è™Ÿ
                        
                        # ç§»é™¤å¯èƒ½é€ æˆ CSV å•é¡Œçš„å­—ç¬¦
                        str_value = str_value.replace('\r\n', '\n').replace('\r', '\n')
                        
                        # é™åˆ¶è¶…é•·å…§å®¹
                        if len(str_value) > 32000:  # Excel å–®å…ƒæ ¼é™åˆ¶
                            str_value = str_value[:32000] + "...(å…§å®¹å·²æˆªæ–·)"
                        return str_value
                    
                    # åŸºæœ¬æ¬„ä½
                    row_data = {
                        'ç·¨è™Ÿ': safe_string(row.ç·¨è™Ÿ),
                        'æå•è€…': safe_string(row.æå•è€…),
                        'å•é¡Œæè¿°': safe_string(row.å•é¡Œæè¿°),
                        'æ˜¯å¦æª¢ç´¢KMæ¨è–¦': safe_string(row.æ˜¯å¦æª¢ç´¢KMæ¨è–¦),  # æ–°å¢æ¬„ä½
                        'AI åŠ©ç†å›è¦†': safe_string(row.AIåŠ©ç†å›è¦†),
                        'å»ºè­° or æ­£ç¢ºç­”æ¡ˆ (if have)': safe_string(row.å»ºè­°_or_æ­£ç¢ºç­”æ¡ˆ),
                        'æ‡‰åƒè€ƒçš„æ–‡ä»¶': safe_string(row.æ‡‰åƒè€ƒçš„æ–‡ä»¶),
                        'æ‡‰åƒè€ƒçš„æ–‡ä»¶æ®µè½(åŸå§‹)': safe_string(row.æ‡‰åƒè€ƒçš„æ–‡ä»¶æ®µè½),  # ä¿ç•™åŸå§‹å®Œæ•´å…§å®¹
                        'å¼•ç”¨ç¯€é»æ˜¯å¦å‘½ä¸­': safe_string(row.å¼•ç”¨ç¯€é»æ˜¯å¦å‘½ä¸­),
                        'åƒè€ƒæ–‡ä»¶æ˜¯å¦æ­£ç¢º': safe_string(row.åƒè€ƒæ–‡ä»¶æ˜¯å¦æ­£ç¢º),
                        'å›è¦†æ˜¯å¦æ»¿æ„': safe_string(row.å›è¦†æ˜¯å¦æ»¿æ„),
                        # åƒè€ƒæ–‡ä»¶è©³ç´°ä¿¡æ¯ï¼ˆä¸åŒ…å«å‘½ä¸­ç‡ï¼‰
                        'æœŸæœ›æ–‡ä»¶ç¸½æ•¸': str(row.æœŸæœ›æ–‡ä»¶ç¸½æ•¸),
                        'å‘½ä¸­æ–‡ä»¶æ•¸': str(row.å‘½ä¸­æ–‡ä»¶æ•¸),
                        'æœªå‘½ä¸­æ–‡ä»¶': safe_string(row.æœªå‘½ä¸­æ–‡ä»¶)
                    }
                    
                    # æ·»åŠ å‹•æ…‹å¼•ç”¨ç¯€é»æ¬„ä½
                    for i in range(1, max_citation_nodes + 1):
                        chinese_num = self.get_chinese_number(i)
                        field_name = f'å¼•ç”¨ç¯€é»{chinese_num}'
                        content = getattr(row, field_name, '') if hasattr(row, field_name) else ''
                        row_data[field_name] = safe_string(content)
                    
                    # æ·»åŠ å‹•æ…‹åƒè€ƒæ–‡ä»¶æ¬„ä½
                    for i in range(1, max_citation_files + 1):
                        chinese_num = self.get_chinese_number(i)
                        field_name = f'åƒè€ƒæ–‡ä»¶{chinese_num}'
                        content = getattr(row, field_name, '') if hasattr(row, field_name) else ''
                        row_data[field_name] = safe_string(content)
                    
                    # åˆ†å‰²æ®µè½ä¸¦æ·»åŠ åˆ°ç¨ç«‹æ¬„ä½
                    segments = self.split_segments_for_export(row.æ‡‰åƒè€ƒçš„æ–‡ä»¶æ®µè½, selected_separators)
                    
                    for i in range(max_segments):
                        chinese_num = self.get_chinese_number(i + 1)
                        column_name = f'æ‡‰åƒè€ƒçš„æ–‡ä»¶æ®µè½({chinese_num})'
                        
                        if i < len(segments):
                            row_data[column_name] = safe_string(segments[i])
                        else:
                            row_data[column_name] = ''  # ç©ºæ¬„ä½ç”¨æ–¼æ²’æœ‰é‚£éº¼å¤šæ®µè½çš„è¡Œ
                    
                    output_data.append(row_data)
                    
                except Exception as e:
                    failed_rows += 1
                    self.log_error(f"è™•ç†é©—è­‰çµæœå¤±æ•— [{getattr(row, 'ç·¨è™Ÿ', 'Unknown')}]: {str(e)}")
                    self.log_error(f"éŒ¯èª¤è©³æƒ…: {type(e).__name__}")
                    continue
            
            # ç¢ºä¿è¼¸å‡ºæ–‡ä»¶æ˜¯ CSV æ ¼å¼
            if not output_file.lower().endswith('.csv'):
                output_file = os.path.splitext(output_file)[0] + '.csv'
            
            # è¼¸å‡ºåˆ° CSV
            df = pd.DataFrame(output_data)
            df.to_csv(output_file, index=False, encoding='utf-8-sig')  # ä½¿ç”¨ BOM ç¢ºä¿ä¸­æ–‡æ­£ç¢ºé¡¯ç¤º
            self.output_file = output_file
            
            # è¨˜éŒ„åˆ†å‰²çµ±è¨ˆ
            self.log_info(f"å·²åŒ¯å‡º {len(output_data)} ç­†è¨˜éŒ„åˆ° CSV æª”æ¡ˆï¼Œæœ€å¤š {max_segments} å€‹æ®µè½")
            if failed_rows > 0:
                self.log_warning(f"è·³é {failed_rows} ç­†æœ‰å•é¡Œçš„è¨˜éŒ„")
            self.log_info(f"ä½¿ç”¨çš„åˆ†éš”ç¬¦: {', '.join(selected_separators)}")
            self.log_info(f"è¼¸å‡ºæª”æ¡ˆ: {output_file}")
            
        except Exception as e:
            self.log_error(f"åŒ¯å‡ºçµæœå¤±æ•—: {str(e)}")
            self.log_error(f"éŒ¯èª¤é¡å‹: {type(e).__name__}")
            raise
    
    def export_excel(self, results, stats):
        """è¼¸å‡ºçµæœåˆ° Excel æ ¼å¼"""
        try:
            if not hasattr(self, 'output_file') or not self.output_file:
                self.log_error("æ²’æœ‰å¯ç”¨çš„è¼¸å‡ºæª”æ¡ˆè·¯å¾‘")
                messagebox.showerror("éŒ¯èª¤", "æ²’æœ‰å¯ç”¨çš„è¼¸å‡ºæª”æ¡ˆè·¯å¾‘")
                return
            
            # ç”Ÿæˆ Excel æª”æ¡ˆè·¯å¾‘
            csv_file = self.output_file
            excel_file = os.path.splitext(csv_file)[0] + '.xlsx'
            
            self.log_info(f"é–‹å§‹è¼¸å‡º Excel æª”æ¡ˆ: {excel_file}")
            
            selected_separators = self.get_selected_separators()
            output_data = []
            failed_rows = 0
            
            # å…ˆåˆ†ææ‰€æœ‰è¡Œï¼Œæ‰¾å‡ºæœ€å¤§æ®µè½æ•¸é‡
            max_segments = 1
            for row in results:
                try:
                    segments = self.split_segments_for_export(row.æ‡‰åƒè€ƒçš„æ–‡ä»¶æ®µè½, selected_separators)
                    max_segments = max(max_segments, len(segments))
                except Exception as e:
                    self.log_warning(f"Excel è¼¸å‡º - åˆ†ææ®µè½å¤±æ•— [{row.ç·¨è™Ÿ}]: {str(e)}")
                    continue
            
            # åˆ†ææ‰€æœ‰è¡Œï¼Œæ‰¾å‡ºæœ€å¤§å¼•ç”¨ç¯€é»å’Œåƒè€ƒæ–‡ä»¶æ•¸é‡
            max_citation_nodes = 0
            max_citation_files = 0
            
            for row in results:
                try:
                    # è¨ˆç®—å¼•ç”¨ç¯€é»æ•¸é‡
                    citation_count = 0
                    for i in range(1, 20):
                        chinese_num = self.get_chinese_number(i)
                        field_name = f'å¼•ç”¨ç¯€é»{chinese_num}'
                        if hasattr(row, field_name):
                            citation_count = i
                        else:
                            break
                    max_citation_nodes = max(max_citation_nodes, citation_count)
                    
                    # è¨ˆç®—åƒè€ƒæ–‡ä»¶æ•¸é‡
                    file_count = 0
                    for i in range(1, 20):
                        chinese_num = self.get_chinese_number(i)
                        field_name = f'åƒè€ƒæ–‡ä»¶{chinese_num}'
                        if hasattr(row, field_name):
                            file_count = i
                        else:
                            break
                    max_citation_files = max(max_citation_files, file_count)
                except Exception as e:
                    self.log_warning(f"Excel è¼¸å‡º - åˆ†æå¼•ç”¨ç¯€é»å¤±æ•— [{row.ç·¨è™Ÿ}]: {str(e)}")
                    continue
            
            for row in results:
                try:
                    # Excel å®‰å…¨åŒ–å­—ç¬¦ä¸²å…§å®¹
                    def excel_safe_string(value):
                        if value is None:
                            return ''
                        str_value = str(value)
                        
                        # æŒ‰æ­£ç¢ºé †åºè½‰ç¾©ç‰¹æ®Šå­—ç¬¦ï¼Œé¿å…é‡è¤‡è½‰ç¾©
                        str_value = str_value.replace('&', '&amp;')  # é¦–å…ˆè™•ç† & å­—ç¬¦
                        str_value = str_value.replace('<', '&lt;')   # è½‰ç¾©å°æ–¼è™Ÿï¼ˆé˜²æ­¢ XML æ¨™ç±¤éŒ¯èª¤ï¼‰
                        str_value = str_value.replace('>', '&gt;')   # è½‰ç¾©å¤§æ–¼è™Ÿ
                        str_value = str_value.replace('"', '&quot;') # è½‰ç¾©é›™å¼•è™Ÿ
                        
                        # ç§»é™¤å¯èƒ½é€ æˆ Excel å•é¡Œçš„å­—ç¬¦
                        str_value = str_value.replace('\r\n', '\n').replace('\r', '\n')
                        
                        # Excel ç‰¹æ®Šå­—ç¬¦è™•ç†
                        if str_value.startswith('='):
                            str_value = "'" + str_value  # é˜²æ­¢è¢«è§£é‡‹ç‚ºå…¬å¼
                        if str_value.startswith('+') or str_value.startswith('-') or str_value.startswith('@'):
                            str_value = "'" + str_value  # é˜²æ­¢è¢«è§£é‡‹ç‚ºå…¬å¼æˆ–æŒ‡ä»¤
                        
                        # é™åˆ¶è¶…é•·å…§å®¹
                        if len(str_value) > 32000:  # Excel å–®å…ƒæ ¼é™åˆ¶
                            str_value = str_value[:32000] + "...(å…§å®¹å·²æˆªæ–·)"
                        return str_value
                    
                    # åŸºæœ¬æ¬„ä½
                    row_data = {
                        'ç·¨è™Ÿ': excel_safe_string(row.ç·¨è™Ÿ),
                        'æå•è€…': excel_safe_string(row.æå•è€…),
                        'å•é¡Œæè¿°': excel_safe_string(row.å•é¡Œæè¿°),
                        'æ˜¯å¦æª¢ç´¢KMæ¨è–¦': excel_safe_string(row.æ˜¯å¦æª¢ç´¢KMæ¨è–¦),  # æ–°å¢æ¬„ä½
                        'AI åŠ©ç†å›è¦†': excel_safe_string(row.AIåŠ©ç†å›è¦†),
                        'å»ºè­° or æ­£ç¢ºç­”æ¡ˆ (if have)': excel_safe_string(row.å»ºè­°_or_æ­£ç¢ºç­”æ¡ˆ),
                        'æ‡‰åƒè€ƒçš„æ–‡ä»¶': excel_safe_string(row.æ‡‰åƒè€ƒçš„æ–‡ä»¶),
                        'æ‡‰åƒè€ƒçš„æ–‡ä»¶æ®µè½(åŸå§‹)': excel_safe_string(row.æ‡‰åƒè€ƒçš„æ–‡ä»¶æ®µè½),
                        'å¼•ç”¨ç¯€é»æ˜¯å¦å‘½ä¸­': excel_safe_string(row.å¼•ç”¨ç¯€é»æ˜¯å¦å‘½ä¸­),
                        'åƒè€ƒæ–‡ä»¶æ˜¯å¦æ­£ç¢º': excel_safe_string(row.åƒè€ƒæ–‡ä»¶æ˜¯å¦æ­£ç¢º),
                        'å›è¦†æ˜¯å¦æ»¿æ„': excel_safe_string(row.å›è¦†æ˜¯å¦æ»¿æ„)
                    }
                    
                    # æ·»åŠ å‹•æ…‹å¼•ç”¨ç¯€é»æ¬„ä½
                    for i in range(1, max_citation_nodes + 1):
                        chinese_num = self.get_chinese_number(i)
                        field_name = f'å¼•ç”¨ç¯€é»{chinese_num}'
                        content = getattr(row, field_name, '') if hasattr(row, field_name) else ''
                        row_data[field_name] = excel_safe_string(content)
                    
                    # æ·»åŠ å‹•æ…‹åƒè€ƒæ–‡ä»¶æ¬„ä½
                    for i in range(1, max_citation_files + 1):
                        chinese_num = self.get_chinese_number(i)
                        field_name = f'åƒè€ƒæ–‡ä»¶{chinese_num}'
                        content = getattr(row, field_name, '') if hasattr(row, field_name) else ''
                        row_data[field_name] = excel_safe_string(content)
                    
                    # åˆ†å‰²æ®µè½ä¸¦æ·»åŠ åˆ°ç¨ç«‹æ¬„ä½
                    segments = self.split_segments_for_export(row.æ‡‰åƒè€ƒçš„æ–‡ä»¶æ®µè½, selected_separators)
                    
                    for i in range(max_segments):
                        chinese_num = self.get_chinese_number(i + 1)
                        column_name = f'æ‡‰åƒè€ƒçš„æ–‡ä»¶æ®µè½({chinese_num})'
                        
                        if i < len(segments):
                            row_data[column_name] = excel_safe_string(segments[i])
                        else:
                            row_data[column_name] = ''
                    
                    output_data.append(row_data)
                    
                except Exception as e:
                    failed_rows += 1
                    self.log_error(f"Excel è¼¸å‡º - è™•ç†é©—è­‰çµæœå¤±æ•— [{getattr(row, 'ç·¨è™Ÿ', 'Unknown')}]: {str(e)}")
                    continue
            
            # è¼¸å‡ºåˆ° Excel
            df = pd.DataFrame(output_data)
            df.to_excel(excel_file, index=False, engine='openpyxl')
            
            # è¨˜éŒ„çµ±è¨ˆ
            self.log_info(f"å·²è¼¸å‡º {len(output_data)} ç­†è¨˜éŒ„åˆ° Excel æª”æ¡ˆ")
            if failed_rows > 0:
                self.log_warning(f"Excel è¼¸å‡ºæ™‚è·³é {failed_rows} ç­†æœ‰å•é¡Œçš„è¨˜éŒ„")
            self.log_info(f"Excel æª”æ¡ˆ: {excel_file}")
            
            messagebox.showinfo("æˆåŠŸ", f"Excel æª”æ¡ˆå·²æˆåŠŸè¼¸å‡ºåˆ°ï¼š\n{excel_file}")
            
        except Exception as e:
            error_msg = f"Excel è¼¸å‡ºå¤±æ•—: {str(e)}"
            self.log_error(error_msg)
            self.log_error(f"éŒ¯èª¤é¡å‹: {type(e).__name__}")
            messagebox.showerror("Excel è¼¸å‡ºéŒ¯èª¤", error_msg)
    
    def export_to_excel(self):
        """è§¸ç™¼ Excel è¼¸å‡ºçš„æŒ‰éˆ•å›èª¿"""
        if not hasattr(self, 'latest_results') or not self.latest_results:
            messagebox.showwarning("è­¦å‘Š", "æ²’æœ‰å¯ç”¨çš„é©—è­‰çµæœæ•¸æ“šï¼Œè«‹å…ˆå®Œæˆé©—è­‰")
            return
        
        if not hasattr(self, 'latest_stats') or not self.latest_stats:
            messagebox.showwarning("è­¦å‘Š", "æ²’æœ‰å¯ç”¨çš„çµ±è¨ˆæ•¸æ“šï¼Œè«‹å…ˆå®Œæˆé©—è­‰")
            return
        
        try:
            self.export_excel(self.latest_results, self.latest_stats)
        except Exception as e:
            error_msg = f"Excel è¼¸å‡ºéç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}"
            self.log_error(error_msg)
            messagebox.showerror("Excel è¼¸å‡ºéŒ¯èª¤", error_msg)
        
    def show_results(self, results, stats, output_file):
        """é¡¯ç¤ºå¢å¼·çµæœ"""
        # ä¿å­˜æœ€æ–°çš„çµæœæ•¸æ“šï¼Œç”¨æ–¼ Excel è¼¸å‡º
        self.latest_results = results
        self.latest_stats = stats
        
        # åˆ‡æ›åˆ°çµæœé é¢
        notebook = self.root.nametowidget(self.root.winfo_children()[0])
        notebook.select(2)  # é¸æ“‡çµæœé é¢
        
        # æ›´æ–°çµ±è¨ˆ
        self.stats_text.config(state='normal')
        self.stats_text.delete(1.0, tk.END)
        
        if stats['rag_mode_enabled']:
            stats_str = f"""=== RAG å¢å¼·é©—è­‰çµ±è¨ˆçµæœ ===
ç¸½æŸ¥è©¢æ•¸: {stats['total_queries']}
å‚³çµ± TOP 10 Hit Rate: {stats['top_10_hit_rate']:.2f}%
æ®µè½ç´šå‘½ä¸­ç‡: {stats['segment_level_hit_rate']:.2f}%

=== RAG è©³ç´°æŒ‡æ¨™ ===
å¹³å‡ Precision: {stats['avg_precision']:.2f}%
å¹³å‡ Recall: {stats['avg_recall']:.2f}%
å¹³å‡ F1-Score: {stats['avg_f1_score']:.2f}%

=== æ®µè½ç´šçµ±è¨ˆ ===
ç¸½é æœŸæ®µè½æ•¸: {stats['total_expected_segments']}
å‘½ä¸­æ®µè½æ•¸: {stats['total_hit_segments']}
ç¸½æª¢ç´¢å¡Šæ•¸: {stats['total_retrieved_chunks']}

=== æ–‡ä»¶åŒ¹é…çµ±è¨ˆ ===
åƒè€ƒæ–‡ä»¶æ­£ç¢ºç‡: {stats['file_match_rate']:.2f}%
æ–‡ä»¶ç´šæ•´é«”å‘½ä¸­ç‡: {stats['file_level_hit_rate']:.2f}%
ç¸½æœŸæœ›æ–‡ä»¶æ•¸: {stats['total_expected_files']}
ç¸½å‘½ä¸­æ–‡ä»¶æ•¸: {stats['total_matched_files']}

=== é‡è©¦è™•ç†çµ±è¨ˆ ===
é‡è©¦æˆåŠŸå•é¡Œæ•¸: {stats['retry_success_count']}
é‡è©¦å¤±æ•—å•é¡Œæ•¸: {stats['retry_failed_count']}
åŸå§‹å¤±æ•—å•é¡Œæ•¸: {stats['original_failed_count']}

çµæœå·²è¼¸å‡ºåˆ°: {output_file}
"""
        else:
            stats_str = f"""=== æ¨™æº–é©—è­‰çµ±è¨ˆçµæœ ===
ç¸½æŸ¥è©¢æ•¸: {stats['total_queries']}
å¼•ç”¨ç¯€é»å‘½ä¸­ç‡: {stats['citation_hit_rate']:.2f}%
åƒè€ƒæ–‡ä»¶æ­£ç¢ºç‡: {stats['file_match_rate']:.2f}%
TOP 10 Hit Rate: {stats['top_10_hit_rate']:.2f}%

çµæœå·²è¼¸å‡ºåˆ°: {output_file}
"""
        
        self.stats_text.insert(1.0, stats_str)
        self.stats_text.config(state='disabled')
        
        # æ›´æ–°è©³ç´°çµæœ
        for item in self.results_tree.get_children():
            self.results_tree.delete(item)
            
        for row in results:
            self.results_tree.insert('', 'end', values=(
                row.ç·¨è™Ÿ,
                row.æå•è€…,
                row.å•é¡Œæè¿°[:50] + "..." if len(row.å•é¡Œæè¿°) > 50 else row.å•é¡Œæè¿°,
                row.AIåŠ©ç†å›è¦†[:50] + "..." if len(row.AIåŠ©ç†å›è¦†) > 50 else row.AIåŠ©ç†å›è¦†,
                row.å¼•ç”¨ç¯€é»æ˜¯å¦å‘½ä¸­,
                row.åƒè€ƒæ–‡ä»¶æ˜¯å¦æ­£ç¢º
            ))
        
        self.output_file = output_file
        
    def update_progress(self, current, total, message):
        """æ›´æ–°é€²åº¦"""
        self.progress_bar['value'] = current
        self.progress_label.config(text=f"{message} ({current}/{total})")
        
    def log_message(self, message, level='INFO', logger_name='GUI'):
        """è¶…å¼·åŒ–æ—¥èªŒè¨˜éŒ„æ–¹æ³•ï¼ˆå®Œå…¨å®‰å…¨ç‰ˆæœ¬ - æœ€å¤§åŒ–éæ­¸ä¿è­·ï¼‰"""
        
        # å®Œå…¨å®‰å…¨æ¨¡å¼ - åœ¨ä¸‹è¼‰æœŸé–“ç¦ç”¨æ‰€æœ‰æ—¥èªŒè™•ç†
        if getattr(self, '_download_in_progress', False):
            # åªä½¿ç”¨æœ€ç°¡å–®çš„æ§åˆ¶å°è¼¸å‡ºï¼Œé¿å…ä»»ä½•è¤‡é›œè™•ç†
            if level == 'ERROR':
                print(f"[SAFE-ERROR] {message}")
            return
        
        # ç·Šæ€¥ä¿è­· - å¦‚æœç¨‹åºä¸ç©©å®šï¼Œç«‹å³åœæ­¢æ—¥èªŒè™•ç†
        if getattr(self, '_emergency_throttle', False):
            return
        
        # ç·Šæ€¥é™æµ - å¦‚æœé€£çºŒéŒ¯èª¤éå¤šï¼Œç›´æ¥ç¦ç”¨æ—¥èªŒ
        if getattr(self, '_emergency_throttle', False):
            return
            
        # é˜²æ­¢éæ­¸èª¿ç”¨å’Œ GUI é—œé–‰å¾Œçš„èª¿ç”¨
        if not getattr(self, 'gui_running', True):
            return
            
        # æ·»åŠ éæ­¸ä¿è­·
        if getattr(self, '_in_log_message', False):
            # é€£çºŒéŒ¯èª¤è¨ˆæ•¸
            self._consecutive_errors = getattr(self, '_consecutive_errors', 0) + 1
            if self._consecutive_errors > 5:
                self._emergency_throttle = True
            return
            
        # æ¿€é€²çš„èª¿ç”¨æ£§æª¢æŸ¥
        try:
            import sys
            if len(sys._current_frames()) > 20:  # å¦‚æœæœ‰å¤ªå¤šæ´»èºç·šç¨‹
                return
        except:
            return
            
        # æ—¥èªŒé™æµæ©Ÿåˆ¶ - æ›´åš´æ ¼çš„æ§åˆ¶
        import time
        current_time = time.time()
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦é™æµï¼ˆæ›´åš´æ ¼ï¼‰
        if getattr(self, '_log_queue_size', 0) > getattr(self, '_max_concurrent_logs', 2):
            return  # è·³éæ­¤æ—¥èªŒï¼Œé˜²æ­¢éæ­¸
        
        # æª¢æŸ¥æ™‚é–“é–“éš”é™æµï¼ˆæ›´åš´æ ¼ï¼‰
        if current_time - getattr(self, '_last_log_time', 0) < 0.05:  # 50ms é–“éš”
            return  # è·³éæ­¤æ—¥èªŒ
        
        # å°APIæ—¥èªŒé€²è¡Œç‰¹æ®Šé™åˆ¶
        if logger_name == 'API' and getattr(self, '_log_queue_size', 0) > 1:
            return  # APIæ—¥èªŒåªå…è¨±1å€‹ä¸¦ç™¼
        
        try:
            self._in_log_message = True
            self._log_queue_size = getattr(self, '_log_queue_size', 0) + 1
            self._last_log_time = current_time
            
            # é‡ç½®é€£çºŒéŒ¯èª¤è¨ˆæ•¸
            self._consecutive_errors = 0
            
            # é¸æ“‡å°æ‡‰çš„æ—¥èªŒè¨˜éŒ„å™¨
            if logger_name == 'API':
                log_instance = self.api_logger
            elif logger_name == 'Validation':
                log_instance = self.validation_logger
            else:
                log_instance = self.gui_logger
            
            # æ ¹æ“šç´šåˆ¥è¨˜éŒ„åˆ°æ–‡ä»¶
            timestamp = pd.Timestamp.now().strftime('%H:%M:%S')
            formatted_message = f"[{timestamp}] {message}"
            
            if level.upper() == 'DEBUG':
                log_instance.debug(message)
            elif level.upper() == 'INFO':
                log_instance.info(message)
            elif level.upper() == 'WARNING':
                log_instance.warning(message)
            elif level.upper() == 'ERROR':
                log_instance.error(message)
            elif level.upper() == 'CRITICAL':
                log_instance.critical(message)
            
            # æ›´æ–° GUI é¡¯ç¤ºï¼ˆå„ªåŒ–ç‰ˆï¼‰
            def update_log():
                if not self.gui_running:
                    return
                    
                try:
                    if not hasattr(self, 'log_text') or not self.log_text.winfo_exists():
                        return
                    
                    # æª¢æŸ¥æ—¥èªŒç´šåˆ¥éæ¿¾
                    level_filter = getattr(self, 'log_level_var', None)
                    if level_filter and level_filter.get() != "ALL":
                        level_priority = {'DEBUG': 0, 'INFO': 1, 'WARNING': 2, 'ERROR': 3, 'CRITICAL': 4}
                        if level_priority.get(level.upper(), 1) < level_priority.get(level_filter.get(), 1):
                            return  # è·³éä½ç´šåˆ¥æ—¥èªŒ
                    
                    # æª¢æŸ¥æ—¥èªŒé¡å‹éæ¿¾
                    type_filter = getattr(self, 'log_type_var', None)
                    if type_filter and type_filter.get() != "ALL" and type_filter.get() != logger_name:
                        return  # è·³éä¸åŒ¹é…çš„é¡å‹
                        
                    self.log_text.config(state='normal')
                    
                    # å‰µå»ºå„ªåŒ–çš„æ—¥èªŒæ ¼å¼
                    level_icon = self.get_log_level_icon(level)
                    type_icon = self.get_log_type_icon(logger_name)
                    timestamp = pd.Timestamp.now().strftime('%H:%M:%S.%f')[:-3]  # åŒ…å«æ¯«ç§’
                    
                    # æ ¼å¼åŒ–æ¶ˆæ¯
                    formatted_line = f"[{timestamp}] {type_icon} {level_icon} {logger_name.upper():<10} | {message}\n"
                    
                    # æ’å…¥æ™‚é–“æˆ³ï¼ˆç°è‰²å°å­—ï¼‰
                    timestamp_start = self.log_text.index(tk.END + "-1c")
                    self.log_text.insert(tk.END, f"[{timestamp}] ")
                    timestamp_end = self.log_text.index(tk.END + "-1c")
                    self.log_text.tag_add('timestamp', timestamp_start, timestamp_end)
                    
                    # æ’å…¥é¡å‹åœ–æ¨™ï¼ˆå½©è‰²ï¼‰
                    type_start = self.log_text.index(tk.END + "-1c")
                    self.log_text.insert(tk.END, f"{type_icon} ")
                    type_end = self.log_text.index(tk.END + "-1c")
                    self.log_text.tag_add(f'{logger_name.lower()}_tag', type_start, type_end)
                    
                    # æ’å…¥ç´šåˆ¥åœ–æ¨™å’Œæ–‡å­—ï¼ˆæ ¹æ“šç´šåˆ¥è‘—è‰²ï¼‰
                    level_start = self.log_text.index(tk.END + "-1c")
                    self.log_text.insert(tk.END, f"{level_icon} {logger_name.upper():<10} | {message}")
                    level_end = self.log_text.index(tk.END + "-1c")
                    self.log_text.tag_add(level.lower(), level_start, level_end)
                    
                    # æª¢æŸ¥æœç´¢é«˜äº®
                    search_text = getattr(self, 'log_search_var', None)
                    if search_text and search_text.get():
                        search_term = search_text.get().lower()
                        if search_term in message.lower():
                            # é«˜äº®æœç´¢çµæœ
                            line_start = timestamp_start
                            self.log_text.tag_add('search_highlight', line_start, level_end)
                    
                    self.log_text.insert(tk.END, "\n")
                    
                    # æ›´æ–°çµ±è¨ˆ
                    if hasattr(self, 'log_stats'):
                        self.log_stats[level.upper()] = self.log_stats.get(level.upper(), 0) + 1
                        self.log_stats['total'] = self.log_stats.get('total', 0) + 1
                        self.update_log_stats()
                    
                    # é™åˆ¶æ—¥èªŒé¡¯ç¤ºè¡Œæ•¸ï¼ˆé¿å…éå¤šæ—¥èªŒå½±éŸ¿æ•ˆèƒ½ï¼‰
                    line_count = int(self.log_text.index('end-1c').split('.')[0])
                    if line_count > 1500:  # å¢åŠ é™åˆ¶åˆ°1500è¡Œ
                        self.log_text.delete('1.0', '750.0')  # åˆªé™¤å‰750è¡Œ
                    
                    # è‡ªå‹•æ»¾å‹•ï¼ˆå¯æ§åˆ¶ï¼‰
                    if getattr(self, 'auto_scroll_var', None) and self.auto_scroll_var.get():
                        self.log_text.see(tk.END)
                    
                    self.log_text.config(state='disabled')
                except Exception as e:
                    # é˜²æ­¢æ—¥èªŒè¨˜éŒ„æœ¬èº«å‡ºéŒ¯ï¼Œä½¿ç”¨éœé»˜å¤±æ•—
                    pass
            
            # å®‰å…¨åœ°æ›´æ–° GUI
            if self.gui_running:
                try:
                    self.root.after(0, update_log)
                except Exception:
                    # å¦‚æœ GUI æ›´æ–°å¤±æ•—ï¼Œéœé»˜å¿½ç•¥
                    pass
                    
        except Exception:
            # å®Œå…¨éœé»˜çš„éŒ¯èª¤è™•ç†ï¼Œé¿å…ä»»ä½•å¯èƒ½çš„éæ­¸èª¿ç”¨
            pass
        finally:
            self._in_log_message = False
            # æ¸›å°‘éšŠåˆ—å¤§å°
            self._log_queue_size = max(0, getattr(self, '_log_queue_size', 0) - 1)
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦é‡ç½®é™æµç‹€æ…‹
            if self._log_queue_size == 0:
                self._log_throttle_active = False
                # ç•¶æ²’æœ‰æ´»èºæ—¥èªŒæ™‚ï¼Œæª¢æŸ¥æ˜¯å¦å¯ä»¥é‡ç½®ç·Šæ€¥é™æµ
                if getattr(self, '_emergency_throttle', False):
                    # å»¶é²é‡ç½®ç·Šæ€¥é™æµï¼Œçµ¦ç³»çµ±æ™‚é–“å†·å»
                    import time
                    if time.time() - getattr(self, '_last_log_time', 0) > 5.0:  # 5ç§’å†·å»æœŸ
                        self._emergency_throttle = False
                        self._consecutive_errors = 0
    
    def log_info(self, message, logger_name='GUI'):
        """è¨˜éŒ„è³‡è¨Šç´šåˆ¥æ—¥èªŒ"""
        self.log_message(message, 'INFO', logger_name)
    
    def log_warning(self, message, logger_name='GUI'):
        """è¨˜éŒ„è­¦å‘Šç´šåˆ¥æ—¥èªŒ"""
        self.log_message(message, 'WARNING', logger_name)
    
    def log_error(self, message, logger_name='GUI'):
        """è¨˜éŒ„éŒ¯èª¤ç´šåˆ¥æ—¥èªŒ"""
        self.log_message(message, 'ERROR', logger_name)
    
    def log_debug(self, message, logger_name='GUI'):
        """è¨˜éŒ„é™¤éŒ¯ç´šåˆ¥æ—¥èªŒ"""
        self.log_message(message, 'DEBUG', logger_name)
    
    def log_api_request(self, url, method, payload=None):
        """è¨˜éŒ„ API è«‹æ±‚"""
        msg = f"APIè«‹æ±‚: {method} {url}"
        if payload:
            msg += f" | è¼‰è·å¤§å°: {len(str(payload))} å­—å…ƒ"
        self.log_debug(msg, 'API')
    
    def log_api_response(self, url, status_code, response_size=0, duration=None):
        """è¨˜éŒ„ API å›æ‡‰"""
        msg = f"APIå›æ‡‰: {url} | ç‹€æ…‹ç¢¼: {status_code} | å›æ‡‰å¤§å°: {response_size} å­—å…ƒ"
        if duration:
            msg += f" | è€—æ™‚: {duration:.2f}ç§’"
        
        if status_code >= 400:
            self.log_error(msg, 'API')
        else:
            self.log_info(msg, 'API')
    
    def log_validation_result(self, question_id, success, details=None):
        """è¨˜éŒ„é©—è­‰çµæœ"""
        status = "æˆåŠŸ" if success else "å¤±æ•—"
        msg = f"é©—è­‰ {question_id}: {status}"
        if details:
            msg += f" | {details}"
        
        if success:
            self.log_info(msg, 'Validation')
        else:
            self.log_warning(msg, 'Validation')
    
    def clear_log_display(self):
        """æ¸…ç©ºæ—¥èªŒé¡¯ç¤º"""
        self.log_text.config(state='normal')
        self.log_text.delete(1.0, tk.END)
        self.log_text.config(state='disabled')
        
        # é‡ç½®æ—¥èªŒçµ±è¨ˆ
        if hasattr(self, 'log_stats'):
            self.log_stats = {
                'DEBUG': 0,
                'INFO': 0,
                'WARNING': 0,
                'ERROR': 0,
                'total': 0
            }
            self.update_log_stats()
        
        self.log_info("ğŸ—‘ï¸ æ—¥èªŒé¡¯ç¤ºå·²æ¸…ç©º")
    
    def export_logs(self):
        """åŒ¯å‡ºç•¶å‰é¡¯ç¤ºçš„æ—¥èªŒ"""
        try:
            log_content = self.log_text.get(1.0, tk.END)
            timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
            filename = f"gui_logs_export_{timestamp}.txt"
            
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(f"=== MaiAgent é©—è­‰å·¥å…·æ—¥èªŒåŒ¯å‡º ===\n")
                f.write(f"åŒ¯å‡ºæ™‚é–“: {pd.Timestamp.now()}\n")
                f.write(f"{'='*50}\n\n")
                f.write(log_content)
            
            self.log_info(f"æ—¥èªŒå·²åŒ¯å‡ºåˆ°: {filename}")
            messagebox.showinfo("æˆåŠŸ", f"æ—¥èªŒå·²åŒ¯å‡ºåˆ°: {filename}")
            return filename
        except Exception as e:
            self.log_error(f"æ—¥èªŒåŒ¯å‡ºå¤±æ•—: {str(e)}")
            messagebox.showerror("éŒ¯èª¤", f"æ—¥èªŒåŒ¯å‡ºå¤±æ•—: {str(e)}")
            return None
    
    def open_log_folder(self):
        """é–‹å•Ÿæ—¥èªŒè³‡æ–™å¤¾"""
        try:
            log_dir = Path("logs")
            if log_dir.exists():
                self._open_file_or_folder(str(log_dir))
                self.log_info("å·²é–‹å•Ÿæ—¥èªŒè³‡æ–™å¤¾")
            else:
                self.log_warning("æ—¥èªŒè³‡æ–™å¤¾ä¸å­˜åœ¨")
                messagebox.showwarning("è­¦å‘Š", "æ—¥èªŒè³‡æ–™å¤¾ä¸å­˜åœ¨")
        except Exception as e:
            self.log_error(f"é–‹å•Ÿæ—¥èªŒè³‡æ–™å¤¾å¤±æ•—: {str(e)}")
            messagebox.showerror("éŒ¯èª¤", f"é–‹å•Ÿæ—¥èªŒè³‡æ–™å¤¾å¤±æ•—: {str(e)}")
    
    def on_log_level_changed(self, event=None):
        """è™•ç†æ—¥èªŒç´šåˆ¥è®Šæ›´"""
        level = self.log_level_var.get()
        self.log_info(f"æ—¥èªŒé¡¯ç¤ºç´šåˆ¥å·²è®Šæ›´ç‚º: {level}")
        
        # é€™è£¡å¯ä»¥å¯¦ç¾éæ¿¾åŠŸèƒ½ï¼ˆå¦‚æœéœ€è¦çš„è©±ï¼‰
        # ç›®å‰ä¿æŒæ‰€æœ‰æ—¥èªŒé¡¯ç¤ºï¼Œåªæ˜¯æ”¹è®Šè¨˜éŒ„ç´šåˆ¥
        
    def get_log_stats(self):
        """ç²å–æ—¥èªŒçµ±è¨ˆè³‡è¨Š"""
        try:
            log_dir = Path("logs")
            if not log_dir.exists():
                return "æ—¥èªŒè³‡æ–™å¤¾ä¸å­˜åœ¨"
            
            log_files = list(log_dir.glob("*.log"))
            total_size = sum(f.stat().st_size for f in log_files if f.exists())
            
            stats = f"æ—¥èªŒæª”æ¡ˆæ•¸é‡: {len(log_files)}\n"
            stats += f"ç¸½å¤§å°: {total_size / 1024:.2f} KB\n"
            stats += f"æ—¥èªŒè³‡æ–™å¤¾: {log_dir.absolute()}"
            
            return stats
        except Exception as e:
            return f"ç²å–æ—¥èªŒçµ±è¨ˆå¤±æ•—: {str(e)}"
    
    def show_log_stats(self):
        """é¡¯ç¤ºæ—¥èªŒçµ±è¨ˆè¦–çª—"""
        stats_window = tk.Toplevel(self.root)
        stats_window.title("æ—¥èªŒçµ±è¨ˆè³‡è¨Š")
        stats_window.geometry("600x400")
        stats_window.resizable(True, True)
        
        # å‰µå»ºæ–‡å­—å€åŸŸ
        stats_text = scrolledtext.ScrolledText(stats_window, wrap=tk.WORD)
        stats_text.pack(fill='both', expand=True, padx=10, pady=10)
        
        # ç²å–ä¸¦é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
        stats_info = self.get_log_stats()
        detailed_stats = f"""=== æ—¥èªŒç³»çµ±çµ±è¨ˆè³‡è¨Š ===

{stats_info}

=== æ—¥èªŒè¨˜éŒ„å™¨ç‹€æ…‹ ===
GUI Logger: {self.gui_logger.name} (Level: {self.gui_logger.level})
API Logger: {self.api_logger.name} (Level: {self.api_logger.level})
Validation Logger: {self.validation_logger.name} (Level: {self.validation_logger.level})

=== æ—¥èªŒè™•ç†å™¨è³‡è¨Š ===
"""
        
        # æ·»åŠ è™•ç†å™¨è³‡è¨Š
        root_logger = logging.getLogger()
        for i, handler in enumerate(root_logger.handlers):
            handler_type = type(handler).__name__
            if hasattr(handler, 'baseFilename'):
                handler_info = f"æª”æ¡ˆ: {handler.baseFilename}"
            else:
                handler_info = "æ§åˆ¶å°è¼¸å‡º"
            detailed_stats += f"è™•ç†å™¨ {i+1}: {handler_type} - {handler_info}\n"
        
        detailed_stats += f"\n=== ç•¶å‰é¡¯ç¤ºçš„æ—¥èªŒè¡Œæ•¸ ===\n"
        try:
            line_count = int(self.log_text.index('end-1c').split('.')[0]) - 1
            detailed_stats += f"GUI æ—¥èªŒé¡¯ç¤ºè¡Œæ•¸: {line_count}\n"
        except:
            detailed_stats += "ç„¡æ³•ç²å– GUI æ—¥èªŒè¡Œæ•¸\n"
        
        stats_text.insert(tk.END, detailed_stats)
        stats_text.config(state='disabled')
        
        # æ·»åŠ æŒ‰éˆ•
        button_frame = ttk.Frame(stats_window)
        button_frame.pack(fill='x', padx=10, pady=(0, 10))
        
        ttk.Button(button_frame, text="é‡æ–°æ•´ç†", 
                  command=lambda: self.refresh_log_stats(stats_text)).pack(side='left')
        ttk.Button(button_frame, text="é—œé–‰", 
                  command=stats_window.destroy).pack(side='right')
    
    def refresh_log_stats(self, stats_text):
        """é‡æ–°æ•´ç†æ—¥èªŒçµ±è¨ˆ"""
        stats_text.config(state='normal')
        stats_text.delete(1.0, tk.END)
        
        # é‡æ–°ç²å–çµ±è¨ˆè³‡è¨Š
        stats_info = self.get_log_stats()
        detailed_stats = f"""=== æ—¥èªŒç³»çµ±çµ±è¨ˆè³‡è¨Š ===

{stats_info}

=== æ—¥èªŒè¨˜éŒ„å™¨ç‹€æ…‹ ===
GUI Logger: {self.gui_logger.name} (Level: {self.gui_logger.level})
API Logger: {self.api_logger.name} (Level: {self.api_logger.level})
Validation Logger: {self.validation_logger.name} (Level: {self.validation_logger.level})

=== æ—¥èªŒè™•ç†å™¨è³‡è¨Š ===
"""
        
        # æ·»åŠ è™•ç†å™¨è³‡è¨Š
        root_logger = logging.getLogger()
        for i, handler in enumerate(root_logger.handlers):
            handler_type = type(handler).__name__
            if hasattr(handler, 'baseFilename'):
                handler_info = f"æª”æ¡ˆ: {handler.baseFilename}"
            else:
                handler_info = "æ§åˆ¶å°è¼¸å‡º"
            detailed_stats += f"è™•ç†å™¨ {i+1}: {handler_type} - {handler_info}\n"
        
        detailed_stats += f"\n=== ç•¶å‰é¡¯ç¤ºçš„æ—¥èªŒè¡Œæ•¸ ===\n"
        try:
            line_count = int(self.log_text.index('end-1c').split('.')[0]) - 1
            detailed_stats += f"GUI æ—¥èªŒé¡¯ç¤ºè¡Œæ•¸: {line_count}\n"
        except:
            detailed_stats += "ç„¡æ³•ç²å– GUI æ—¥èªŒè¡Œæ•¸\n"
            
        detailed_stats += f"\næ›´æ–°æ™‚é–“: {pd.Timestamp.now()}"
        
        stats_text.insert(tk.END, detailed_stats)
        stats_text.config(state='disabled')
    
    def show_about(self):
        """é¡¯ç¤ºé—œæ–¼ç¨‹å¼çš„å°è©±æ¡†"""
        about_window = tk.Toplevel(self.root)
        about_window.title("é—œæ–¼ç¨‹å¼")
        about_window.geometry("500x400")
        about_window.resizable(False, False)
        
        # è¨­å®šè¦–çª—å±…ä¸­
        about_window.transient(self.root)
        about_window.grab_set()
        
        main_frame = ttk.Frame(about_window, padding=20)
        main_frame.pack(fill='both', expand=True)
        
        # æ‡‰ç”¨ç¨‹å¼æ¨™é¡Œ
        title_label = ttk.Label(main_frame, text=__app_name__, 
                               font=('Arial', 16, 'bold'))
        title_label.pack(pady=(0, 5))
        
        # ç‰ˆæœ¬ä¿¡æ¯
        version_label = ttk.Label(main_frame, text=f"ç‰ˆæœ¬ {__version__}", 
                                 font=('Arial', 12))
        version_label.pack(pady=(0, 10))
        
        # æè¿°
        desc_label = ttk.Label(main_frame, text=__description__, 
                              font=('Arial', 10), 
                              wraplength=400, justify='center')
        desc_label.pack(pady=(0, 15))
        
        # è©³ç´°ä¿¡æ¯æ¡†
        info_frame = ttk.LabelFrame(main_frame, text="è©³ç´°ä¿¡æ¯", padding=10)
        info_frame.pack(fill='both', expand=True, pady=(0, 15))
        
        info_text = tk.Text(info_frame, height=12, wrap=tk.WORD, 
                           font=('Consolas', 9), state='normal')
        info_text.pack(fill='both', expand=True)
        
        # ç²å–ç³»çµ±ä¿¡æ¯
        import platform
        import sys
        
        system_info = f"""ç‰ˆæœ¬ä¿¡æ¯:
  æ‡‰ç”¨ç¨‹å¼åç¨±: {__app_name__}
  ç‰ˆæœ¬è™Ÿ: {__version__}
  å»ºç½®æ—¥æœŸ: {__build_date__}
  ä½œè€…: {__author__}

ç³»çµ±ç’°å¢ƒ:
  Python ç‰ˆæœ¬: {sys.version}
  ä½œæ¥­ç³»çµ±: {platform.system()} {platform.release()}
  æ¶æ§‹: {platform.machine()}
  è™•ç†å™¨: {platform.processor()}

æ ¸å¿ƒåŠŸèƒ½:
  â€¢ GUI åœ–å½¢åŒ–æ“ä½œç•Œé¢
  â€¢ RAG å¢å¼·çµ±è¨ˆåˆ†æ
  â€¢ å¤šç´šåˆ¥æ—¥èªŒè¨˜éŒ„ç³»çµ±
  â€¢ æ‰¹æ¬¡é©—è­‰è™•ç†
  â€¢ è©³ç´°çµ±è¨ˆå ±å‘Š
  â€¢ API è‡ªå‹•é‡è©¦æ©Ÿåˆ¶
  â€¢ å¤šç¨®è¼¸å‡ºæ ¼å¼æ”¯æ´

çµ„ç¹”ç®¡ç†åŠŸèƒ½:
  â€¢ çµ„ç¹”æˆå“¡åŒ¯å‡ºåŠŸèƒ½
  â€¢ å¸³è™Ÿæ‰¹é‡åŒ¯å…¥è‡ªå‹•åŒ–
  â€¢ ç¾¤çµ„æ¬Šé™é…ç½®ç®¡ç†
  â€¢ Excel/CSV æ ¼å¼æ•¸æ“šè™•ç†
  â€¢ å®Œæ•´çš„çµ„ç¹”æ¶æ§‹ç®¡ç†

çŸ¥è­˜åº«ç®¡ç†åŠŸèƒ½:
  â€¢ çŸ¥è­˜åº«æ–‡ä»¶åˆ—è¡¨ç®¡ç†
  â€¢ æ‰¹é‡æ–‡ä»¶ä¸‹è¼‰åŒ¯å‡º
  â€¢ æ–‡ä»¶é¸æ“‡èˆ‡ç¯©é¸
  â€¢ é€²åº¦è¿½è¹¤èˆ‡æ—¥èªŒè¨˜éŒ„
  â€¢ éˆæ´»çš„åŒ¯å‡ºç›®éŒ„é…ç½®

æŠ€è¡“æ”¯æ´:
  å¦‚æœ‰å•é¡Œæˆ–å»ºè­°ï¼Œè«‹è¯ç¹« MaiAgent Team
  
ç‰ˆæ¬Šè²æ˜:
  Copyright Â© 2025 MaiAgent Team
  ä¿ç•™æ‰€æœ‰æ¬Šåˆ©
"""
        
        info_text.insert(tk.END, system_info)
        info_text.config(state='disabled')
        
        # æŒ‰éˆ•æ¡†
        button_frame = ttk.Frame(main_frame)
        button_frame.pack(fill='x')
        
        # è¤‡è£½ä¿¡æ¯æŒ‰éˆ•
        def copy_info():
            try:
                about_window.clipboard_clear()
                about_window.update()  # å¼·åˆ¶æ›´æ–°å‰ªè²¼æ¿
                about_window.clipboard_append(system_info)
                about_window.update()  # å†æ¬¡å¼·åˆ¶æ›´æ–°
                self.log_info("ç³»çµ±ä¿¡æ¯å·²è¤‡è£½åˆ°å‰ªè²¼æ¿")
                messagebox.showinfo("æˆåŠŸ", "ç³»çµ±ä¿¡æ¯å·²è¤‡è£½åˆ°å‰ªè²¼æ¿")
            except Exception as e:
                self.log_error(f"è¤‡è£½æ“ä½œå¤±æ•—: {str(e)}")
                messagebox.showerror("éŒ¯èª¤", f"è¤‡è£½å¤±æ•—: {str(e)}")
        
        ttk.Button(button_frame, text="è¤‡è£½ä¿¡æ¯", command=copy_info).pack(side='left')
        ttk.Button(button_frame, text="é—œé–‰", command=about_window.destroy).pack(side='right')
    
    def get_selected_separators(self) -> List[str]:
        """ç²å–ç”¨æˆ¶é¸æ“‡çš„åˆ†éš”ç¬¦"""
        selected = []
        for sep_key, var in self.separator_vars.items():
            if var.get():
                selected.append(sep_key)
        
        # å¦‚æœæ²’æœ‰é¸æ“‡ä»»ä½•åˆ†éš”ç¬¦ï¼Œä½¿ç”¨é è¨­
        if not selected:
            selected = ['---', '|||', '\n\n']
            self.log_warning("æœªé¸æ“‡ä»»ä½•åˆ†éš”ç¬¦ï¼Œä½¿ç”¨é è¨­åˆ†éš”ç¬¦")
        
        return selected
    
    def test_separators(self):
        """æ¸¬è©¦åˆ†éš”ç¬¦åŠŸèƒ½"""
        selected_separators = self.get_selected_separators()
        
        # å‰µå»ºæ¸¬è©¦è¦–çª—
        test_window = tk.Toplevel(self.root)
        test_window.title("åˆ†éš”ç¬¦æ¸¬è©¦")
        test_window.geometry("600x500")
        test_window.resizable(True, True)
        
        main_frame = ttk.Frame(test_window, padding=10)
        main_frame.pack(fill='both', expand=True)
        
        # è¼¸å…¥å€åŸŸ
        input_frame = ttk.LabelFrame(main_frame, text="æ¸¬è©¦æ–‡æœ¬", padding=10)
        input_frame.pack(fill='both', expand=True, pady=(0, 10))
        
        ttk.Label(input_frame, text="è«‹è¼¸å…¥åŒ…å«åˆ†éš”ç¬¦çš„æ¸¬è©¦æ–‡æœ¬ï¼š").pack(anchor='w')
        
        input_text = scrolledtext.ScrolledText(input_frame, height=8, wrap=tk.WORD)
        input_text.pack(fill='both', expand=True, pady=(5, 0))
        
        # é è¨­æ¸¬è©¦æ–‡æœ¬
        sample_text = """ç¬¬ä¸€å€‹æ®µè½å…§å®¹---ç¬¬äºŒå€‹æ®µè½å…§å®¹|||ç¬¬ä¸‰å€‹æ®µè½å…§å®¹

ç¬¬å››å€‹æ®µè½ï¼ˆé›™æ›è¡Œåˆ†éš”ï¼‰

ç¬¬äº”å€‹æ®µè½###ç¬¬å…­å€‹æ®µè½===ç¬¬ä¸ƒå€‹æ®µè½...ç¬¬å…«å€‹æ®µè½"""
        input_text.insert(tk.END, sample_text)
        
        # çµæœå€åŸŸ
        result_frame = ttk.LabelFrame(main_frame, text="åˆ†å‰²çµæœ", padding=10)
        result_frame.pack(fill='both', expand=True)
        
        result_text = scrolledtext.ScrolledText(result_frame, height=8, wrap=tk.WORD, state='disabled')
        result_text.pack(fill='both', expand=True, pady=(5, 0))
        
        # æ§åˆ¶æŒ‰éˆ•
        button_frame = ttk.Frame(main_frame)
        button_frame.pack(fill='x', pady=(10, 0))
        
        def run_test():
            test_content = input_text.get(1.0, tk.END).strip()
            if not test_content:
                messagebox.showwarning("è­¦å‘Š", "è«‹è¼¸å…¥æ¸¬è©¦æ–‡æœ¬")
                return
            
            try:
                segments = self.text_matcher.parse_expected_segments(test_content, selected_separators)
                
                result_text.config(state='normal')
                result_text.delete(1.0, tk.END)
                
                result_content = f"ä½¿ç”¨çš„åˆ†éš”ç¬¦: {', '.join(selected_separators)}\n"
                result_content += f"åˆ†å‰²çµæœ (å…± {len(segments)} å€‹æ®µè½):\n"
                result_content += "=" * 50 + "\n\n"
                
                for i, segment in enumerate(segments, 1):
                    result_content += f"æ®µè½ {i}:\n{segment}\n\n"
                    result_content += "-" * 30 + "\n\n"
                
                result_text.insert(tk.END, result_content)
                result_text.config(state='disabled')
                
                self.log_info(f"åˆ†éš”ç¬¦æ¸¬è©¦å®Œæˆï¼Œå…±åˆ†å‰²å‡º {len(segments)} å€‹æ®µè½")
                
            except Exception as e:
                messagebox.showerror("éŒ¯èª¤", f"æ¸¬è©¦å¤±æ•—: {str(e)}")
                self.log_error(f"åˆ†éš”ç¬¦æ¸¬è©¦å¤±æ•—: {str(e)}")
        
        ttk.Button(button_frame, text="åŸ·è¡Œæ¸¬è©¦", command=run_test).pack(side='left')
        ttk.Button(button_frame, text="æ¸…ç©ºè¼¸å…¥", command=lambda: input_text.delete(1.0, tk.END)).pack(side='left', padx=(10, 0))
        ttk.Button(button_frame, text="é—œé–‰", command=test_window.destroy).pack(side='right')
        
        # ç«‹å³åŸ·è¡Œä¸€æ¬¡æ¸¬è©¦
        run_test()
    
    def reset_separators(self):
        """é‡è¨­åˆ†éš”ç¬¦ç‚ºé è¨­å€¼"""
        # é‡è¨­æ‰€æœ‰é¸é …
        for sep_key, var in self.separator_vars.items():
            if sep_key in ['---', '|||', '\n\n']:
                var.set(True)
            else:
                var.set(False)
        
        self.log_info("åˆ†éš”ç¬¦å·²é‡è¨­ç‚ºé è¨­å€¼")
        messagebox.showinfo("æˆåŠŸ", "åˆ†éš”ç¬¦å·²é‡è¨­ç‚ºé è¨­å€¼ (---, |||, \\n\\n)")
    
    def get_chinese_number(self, num: int) -> str:
        """å°‡æ•¸å­—è½‰æ›ç‚ºä¸­æ–‡æ•¸å­—"""
        chinese_nums = ['', 'ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'ä¸ƒ', 'å…«', 'ä¹', 'å',
                       'åä¸€', 'åäºŒ', 'åä¸‰', 'åå››', 'åäº”', 'åå…­', 'åä¸ƒ', 'åå…«', 'åä¹', 'äºŒå']
        if num < len(chinese_nums):
            return chinese_nums[num]
        else:
            return str(num)  # è¶…é20å€‹æ®µè½æ™‚ä½¿ç”¨é˜¿æ‹‰ä¼¯æ•¸å­—
    
    def split_segments_for_export(self, original_content: str, selected_separators: List[str]) -> List[str]:
        """ç‚ºåŒ¯å‡ºåŠŸèƒ½åˆ†å‰²æ®µè½"""
        if not original_content:
            return ['']
        
        segments = self.text_matcher.parse_expected_segments(original_content, selected_separators)
        return segments if segments else [original_content]
        
    def reset_validation_ui(self):
        """é‡è¨­é©—è­‰ UI ç‹€æ…‹"""
        self.start_button.config(state='normal')
        self.stop_button.config(state='disabled')
        self.progress_label.config(text="é©—è­‰å®Œæˆ")
        
    def open_results_file(self):
        """é–‹å•Ÿçµæœæ–‡ä»¶"""
        if hasattr(self, 'output_file') and os.path.exists(self.output_file):
            self._open_file_or_folder(self.output_file)
        else:
            messagebox.showwarning("è­¦å‘Š", "çµæœæ–‡ä»¶ä¸å­˜åœ¨")
            
    def open_results_folder(self):
        """é–‹å•Ÿçµæœè³‡æ–™å¤¾"""
        folder = os.path.dirname(os.path.abspath(self.output_file)) if hasattr(self, 'output_file') else os.getcwd()
        self._open_file_or_folder(folder)
    
    def _open_file_or_folder(self, path):
        """è·¨å¹³å°é–‹å•Ÿæª”æ¡ˆæˆ–è³‡æ–™å¤¾"""
        try:
            system = platform.system()
            if system == "Windows":
                os.startfile(path)
            elif system == "Darwin":  # macOS
                subprocess.call(["open", path])
            elif system == "Linux":
                subprocess.call(["xdg-open", path])
            else:
                self.log_warning(f"ä¸æ”¯æ´çš„ä½œæ¥­ç³»çµ±: {system}")
                messagebox.showwarning("è­¦å‘Š", f"ç„¡æ³•åœ¨ {system} ç³»çµ±ä¸Šè‡ªå‹•é–‹å•Ÿæª”æ¡ˆ")
        except Exception as e:
            self.log_error(f"é–‹å•Ÿæª”æ¡ˆå¤±æ•—: {str(e)}")
            messagebox.showerror("éŒ¯èª¤", f"é–‹å•Ÿæª”æ¡ˆå¤±æ•—: {str(e)}")
        
    def load_config(self):
        """è¼‰å…¥é…ç½®"""
        try:
            import configparser
            config = configparser.ConfigParser()
            config.read('config.ini', encoding='utf-8')
            
            if 'api' in config:
                self.api_base_url.set(config['api'].get('base_url', 'http://localhost:8000'))
                self.api_key.set(config['api'].get('api_key', ''))
            
            if 'validation' in config:
                self.similarity_threshold.set(config['validation'].getfloat('similarity_threshold', 0.3))
                # å…¼å®¹èˆŠçš„è¨­å®šæª”æ¡ˆ
                max_concurrent = 5  # é è¨­å€¼
                if 'max_concurrent_users' in config['validation']:
                    max_concurrent = config['validation'].getint('max_concurrent_users')
                elif 'max_concurrent_requests' in config['validation']:
                    max_concurrent = config['validation'].getint('max_concurrent_requests')
                self.max_concurrent.set(max_concurrent)
                # è¼‰å…¥ API å»¶é²è¨­å®š
                self.api_delay.set(config['validation'].getfloat('api_delay', 1.0))
                # è¼‰å…¥é‡è©¦æ¬¡æ•¸è¨­å®š
                self.max_retries.set(config['validation'].getint('max_retries', 3))
                # RAG æ¨¡å¼å›ºå®šå•Ÿç”¨ï¼Œä¸å¾é…ç½®æ–‡ä»¶è®€å–
                # top_k å‹•æ…‹èª¿æ•´ï¼Œä¸å¾é…ç½®æ–‡ä»¶è®€å–
            
            # è¼‰å…¥çµ„ç¹”åŒ¯å‡ºè¨­å®š
            if 'organization_export' in config:
                self.org_export_base_url.set(config['organization_export'].get('base_url', 'https://api.maiagent.ai/api/v1/'))
                self.org_export_api_key.set(config['organization_export'].get('api_key', ''))
            
            # è¼‰å…¥éƒ¨ç½²è¨­å®š
            if 'deployment' in config:
                self.deploy_base_url.set(config['deployment'].get('base_url', 'http://localhost:8000/api/v1/'))
                self.deploy_api_key.set(config['deployment'].get('api_key', ''))
                self.deploy_org_name.set(config['deployment'].get('organization_name', ''))
                self.deploy_create_users.set(config['deployment'].getboolean('create_users', False))
                self.deploy_referral_code.set(config['deployment'].get('referral_code', ''))
            
            # è¼‰å…¥çŸ¥è­˜åº«ç®¡ç†è¨­å®š
            if 'knowledge_base' in config:
                self.kb_base_url.set(config['knowledge_base'].get('base_url', 'http://localhost:8000/api/v1/'))
                self.kb_api_key.set(config['knowledge_base'].get('api_key', ''))
                self.kb_export_dir.set(config['knowledge_base'].get('export_dir', ''))
                self.concurrent_downloads.set(config['knowledge_base'].getint('concurrent_downloads', 1))
                # è¼‰å…¥è¼‰å…¥æ¨¡å¼è¨­ç½®
                if hasattr(self, 'load_all_at_once'):
                    load_all = config['knowledge_base'].getboolean('load_all_at_once', True)
                    self.load_all_at_once.set(load_all)
            
            # è¼‰å…¥ query_metadata è¨­å®š
            if 'query_metadata' in config:
                self.enable_query_metadata.set(config['query_metadata'].getboolean('enable', False))
                self.knowledge_base_id.set(config['query_metadata'].get('knowledge_base_id', ''))
                self.label_id.set(config['query_metadata'].get('label_id', ''))
                # æ›´æ–° UI ç‹€æ…‹
                self.on_query_metadata_toggle()
            
            # è¼‰å…¥ä¸Šä¸‹æ–‡çµ„åˆè¨­å®š
            if 'context' in config:
                self.enable_context_combination.set(config['context'].getboolean('enable_combination', True))
            
            # è¼‰å…¥åˆ†éš”ç¬¦è¨­å®š
            if 'separators' in config:
                # å»ºç«‹åˆ†éš”ç¬¦åˆ¥åæ˜ å°„ï¼ˆèˆ‡ä¿å­˜æ™‚ç›¸åŒï¼‰
                separator_aliases = {
                    '---': 'hyphen_triple',
                    '|||': 'pipe_triple', 
                    '\n\n': 'newline_double',
                    '###': 'hash_triple',
                    '===': 'equal_triple',
                    '...': 'dot_triple'
                }
                
                separator_section = config['separators']
                for sep_key in self.separator_vars:
                    alias = separator_aliases.get(sep_key, sep_key)
                    # å¾é…ç½®æ–‡ä»¶è®€å–ï¼Œå¦‚æœä¸å­˜åœ¨å‰‡ä½¿ç”¨ç•¶å‰å€¼
                    saved_value = separator_section.getboolean(alias, self.separator_vars[sep_key].get())
                    self.separator_vars[sep_key].set(saved_value)
                
                self.log_info(f"åˆ†éš”ç¬¦è¨­å®šå·²è¼‰å…¥: {self.get_selected_separators()}")
            
            # æ›´æ–°æ¨è–¦ç¢¼è¼¸å…¥æ¡†ç‹€æ…‹
            self.on_create_users_changed()
                
            messagebox.showinfo("æˆåŠŸ", "é…ç½®è¼‰å…¥æˆåŠŸ")
            
        except Exception as e:
            messagebox.showerror("éŒ¯èª¤", f"è¼‰å…¥é…ç½®å¤±æ•—: {str(e)}")
            
    def save_config(self):
        """å„²å­˜é…ç½®"""
        try:
            import configparser
            config = configparser.ConfigParser()
            
            config['api'] = {
                'base_url': self.api_base_url.get(),
                'api_key': self.api_key.get()
            }
            
            config['validation'] = {
                'similarity_threshold': str(self.similarity_threshold.get()),
                'max_concurrent_users': str(self.max_concurrent.get()),
                'api_delay': str(self.api_delay.get()),  # API å‘¼å«å»¶é²æ™‚é–“
                'max_retries': str(self.max_retries.get()),  # API è«‹æ±‚é‡è©¦æ¬¡æ•¸
                'enable_rag_mode': 'True',  # å›ºå®šå•Ÿç”¨ RAG æ¨¡å¼
                'top_k': 'dynamic'  # å‹•æ…‹èª¿æ•´
            }
            
            # çµ„ç¹”åŒ¯å‡ºè¨­å®š
            config['organization_export'] = {
                'base_url': self.org_export_base_url.get(),
                'api_key': self.org_export_api_key.get()
            }
            
            # éƒ¨ç½²è¨­å®š
            config['deployment'] = {
                'base_url': self.deploy_base_url.get(),
                'api_key': self.deploy_api_key.get(),
                'organization_name': self.deploy_org_name.get(),
                'create_users': str(self.deploy_create_users.get()),
                'referral_code': self.deploy_referral_code.get()
            }
            
            # çŸ¥è­˜åº«ç®¡ç†è¨­å®š
            config['knowledge_base'] = {
                'base_url': self.kb_base_url.get(),
                'api_key': self.kb_api_key.get(),
                'export_dir': self.kb_export_dir.get(),
                'concurrent_downloads': str(self.concurrent_downloads.get()),
                'load_all_at_once': str(getattr(self, 'load_all_at_once', tk.BooleanVar(value=True)).get())
            }
            
            # ä¿å­˜ query_metadata è¨­å®š
            config['query_metadata'] = {
                'enable': str(self.enable_query_metadata.get()),
                'knowledge_base_id': self.knowledge_base_id.get(),
                'label_id': self.label_id.get()
            }
            
            # ä¿å­˜ä¸Šä¸‹æ–‡çµ„åˆè¨­å®š
            config['context'] = {
                'enable_combination': str(self.enable_context_combination.get())
            }
            
            # ä¿å­˜åˆ†éš”ç¬¦è¨­å®š
            # å»ºç«‹åˆ†éš”ç¬¦åˆ¥åæ˜ å°„
            separator_aliases = {
                '---': 'hyphen_triple',
                '|||': 'pipe_triple', 
                '\n\n': 'newline_double',
                '###': 'hash_triple',
                '===': 'equal_triple',
                '...': 'dot_triple'
            }
            
            config['separators'] = {}
            for sep_key, var in self.separator_vars.items():
                alias = separator_aliases.get(sep_key, sep_key)
                config['separators'][alias] = str(var.get())
            
            with open('config.ini', 'w', encoding='utf-8') as f:
                config.write(f)
                
            self.log_info(f"åˆ†éš”ç¬¦è¨­å®šå·²ä¿å­˜: {self.get_selected_separators()}")
            messagebox.showinfo("æˆåŠŸ", "é…ç½®å„²å­˜æˆåŠŸ")
            
        except Exception as e:
            messagebox.showerror("éŒ¯èª¤", f"å„²å­˜é…ç½®å¤±æ•—: {str(e)}")
    
    def create_organization_tab(self, notebook):
        """å‰µå»ºçµ„ç¹”ç®¡ç†æ¨™ç±¤é """
        org_frame = ttk.Frame(notebook)
        notebook.add(org_frame, text="çµ„ç¹”ç®¡ç†")
        
        # å‰µå»ºå­ç­†è¨˜æœ¬
        org_notebook = ttk.Notebook(org_frame)
        org_notebook.pack(fill='both', expand=True, padx=10, pady=10)
        
        # çµ„ç¹”åŒ¯å‡ºå­é é¢
        self.create_export_tab(org_notebook)
        
        # å¸³è™Ÿæ‰¹é‡åŒ¯å…¥å­é é¢
        self.create_deployment_tab(org_notebook)
        
        # çŸ¥è­˜åº«ç®¡ç†å­é é¢
        self.create_knowledge_base_tab(org_notebook)
    
    def create_export_tab(self, notebook):
        """å‰µå»ºçµ„ç¹”åŒ¯å‡ºæ¨™ç±¤é """
        export_frame = ttk.Frame(notebook)
        notebook.add(export_frame, text="çµ„ç¹”åŒ¯å‡º")
        
        main_frame = ttk.Frame(export_frame)
        main_frame.pack(fill='both', expand=True, padx=20, pady=20)
        
        # API è¨­å®š
        api_frame = ttk.LabelFrame(main_frame, text="API è¨­å®š", padding=10)
        api_frame.pack(fill='x', pady=(0, 10))
        
        ttk.Label(api_frame, text="API åŸºç¤ URLï¼š").pack(anchor='w')
        ttk.Entry(api_frame, textvariable=self.org_export_base_url, width=60).pack(fill='x', pady=(5, 10))
        
        ttk.Label(api_frame, text="API é‡‘é‘°ï¼š").pack(anchor='w')
        ttk.Entry(api_frame, textvariable=self.org_export_api_key, width=60, show="*").pack(fill='x', pady=(5, 0))
        
        # çµ„ç¹”é¸æ“‡
        org_frame = ttk.LabelFrame(main_frame, text="çµ„ç¹”é¸æ“‡", padding=10)
        org_frame.pack(fill='x', pady=(0, 10))
        
        self.export_org_listbox = tk.Listbox(org_frame, height=5)
        self.export_org_listbox.pack(fill='x', pady=(0, 10))
        
        org_button_frame = ttk.Frame(org_frame)
        org_button_frame.pack(fill='x')
        
        ttk.Button(org_button_frame, text="è¼‰å…¥çµ„ç¹”åˆ—è¡¨", command=self.load_export_organizations).pack(side='left')
        ttk.Button(org_button_frame, text="æ¸¬è©¦é€£æ¥", command=self.test_export_connection).pack(side='left', padx=(10, 0))
        
        # åŒ¯å‡ºæ§åˆ¶
        export_control_frame = ttk.LabelFrame(main_frame, text="åŒ¯å‡ºæ§åˆ¶", padding=10)
        export_control_frame.pack(fill='x', pady=(0, 10))
        
        self.export_button = ttk.Button(export_control_frame, text="é–‹å§‹åŒ¯å‡º", command=self.start_export)
        self.export_button.pack(side='left')
        
        # åŒ¯å‡ºæ—¥èªŒ
        export_log_frame = ttk.LabelFrame(main_frame, text="åŒ¯å‡ºæ—¥èªŒ", padding=10)
        export_log_frame.pack(fill='both', expand=True)
        
        self.export_log_text = scrolledtext.ScrolledText(export_log_frame, height=10, state='disabled')
        self.export_log_text.pack(fill='both', expand=True)
    
    def create_deployment_tab(self, notebook):
        """å‰µå»ºå¸³è™Ÿæ‰¹é‡åŒ¯å…¥æ¨™ç±¤é """
        deploy_frame = ttk.Frame(notebook)
        notebook.add(deploy_frame, text="å¸³è™Ÿæ‰¹é‡åŒ¯å…¥")
        
        main_frame = ttk.Frame(deploy_frame)
        main_frame.pack(fill='both', expand=True, padx=20, pady=20)
        
        # CSV æ–‡ä»¶é¸æ“‡
        csv_frame = ttk.LabelFrame(main_frame, text="CSV æ–‡ä»¶", padding=10)
        csv_frame.pack(fill='x', pady=(0, 10))
        
        ttk.Label(csv_frame, text="é¸æ“‡ CSV æ–‡ä»¶ï¼š").pack(anchor='w')
        csv_path_frame = ttk.Frame(csv_frame)
        csv_path_frame.pack(fill='x', pady=(5, 0))
        
        ttk.Entry(csv_path_frame, textvariable=self.deploy_csv_file, width=60).pack(side='left', fill='x', expand=True)
        ttk.Button(csv_path_frame, text="ç€è¦½", command=self.browse_deploy_csv).pack(side='right', padx=(5, 0))
        
        # API è¨­å®š
        deploy_api_frame = ttk.LabelFrame(main_frame, text="ç›®æ¨™ç’°å¢ƒ API è¨­å®š", padding=10)
        deploy_api_frame.pack(fill='x', pady=(0, 10))
        
        ttk.Label(deploy_api_frame, text="API åŸºç¤ URLï¼š").pack(anchor='w')
        ttk.Entry(deploy_api_frame, textvariable=self.deploy_base_url, width=60).pack(fill='x', pady=(5, 10))
        
        ttk.Label(deploy_api_frame, text="API é‡‘é‘°ï¼š").pack(anchor='w')
        ttk.Entry(deploy_api_frame, textvariable=self.deploy_api_key, width=60, show="*").pack(fill='x', pady=(5, 0))
        
        # åŒ¯å…¥é¸é …
        deploy_options_frame = ttk.LabelFrame(main_frame, text="åŒ¯å…¥é¸é …", padding=10)
        deploy_options_frame.pack(fill='x', pady=(0, 10))
        
        ttk.Label(deploy_options_frame, text="çµ„ç¹”åç¨±ï¼ˆé¸å¡«ï¼‰ï¼š").pack(anchor='w')
        ttk.Entry(deploy_options_frame, textvariable=self.deploy_org_name, width=60).pack(fill='x', pady=(5, 10))
        
        user_frame = ttk.Frame(deploy_options_frame)
        user_frame.pack(fill='x', pady=(0, 10))
        
        ttk.Checkbutton(user_frame, text="å‰µå»ºç”¨æˆ¶å¸³è™Ÿ", variable=self.deploy_create_users, 
                       command=self.on_create_users_changed).pack(side='left')
        
        ttk.Label(deploy_options_frame, text="æ¨è–¦ç¢¼ï¼ˆå‰µå»ºç”¨æˆ¶æ™‚éœ€è¦ï¼‰ï¼š").pack(anchor='w')
        self.deploy_referral_entry = ttk.Entry(deploy_options_frame, textvariable=self.deploy_referral_code, 
                                              width=60, state='disabled')
        self.deploy_referral_entry.pack(fill='x', pady=(5, 0))
        
        # åŒ¯å…¥æ§åˆ¶
        deploy_control_frame = ttk.LabelFrame(main_frame, text="åŒ¯å…¥æ§åˆ¶", padding=10)
        deploy_control_frame.pack(fill='x', pady=(0, 10))
        
        self.deploy_button = ttk.Button(deploy_control_frame, text="é–‹å§‹åŒ¯å…¥", command=self.start_deployment)
        self.deploy_button.pack(side='left')
        
        # åŒ¯å…¥æ—¥èªŒ
        deploy_log_frame = ttk.LabelFrame(main_frame, text="åŒ¯å…¥æ—¥èªŒ", padding=10)
        deploy_log_frame.pack(fill='both', expand=True)
        
        self.deploy_log_text = scrolledtext.ScrolledText(deploy_log_frame, height=10, state='disabled')
        self.deploy_log_text.pack(fill='both', expand=True)
    
    def create_knowledge_base_tab(self, notebook):
        """å‰µå»ºçŸ¥è­˜åº«ç®¡ç†æ¨™ç±¤é """
        kb_frame = ttk.Frame(notebook)
        notebook.add(kb_frame, text="ğŸ—ƒï¸ çŸ¥è­˜åº«ç®¡ç†")
        
        # åˆ†å‰²ç‚ºå·¦å³å…©å€‹å€åŸŸ
        paned_window = ttk.PanedWindow(kb_frame, orient=tk.HORIZONTAL)
        paned_window.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # å·¦å´é¢æ¿ï¼šé…ç½®å’Œæ“ä½œ
        left_frame = ttk.Frame(paned_window)
        paned_window.add(left_frame, weight=1)
        
        # çŸ¥è­˜åº«é€£æ¥é…ç½®
        config_frame = ttk.LabelFrame(left_frame, text="ğŸ”— çŸ¥è­˜åº«é€£æ¥é…ç½®", padding=10)
        config_frame.pack(fill=tk.X, pady=(0, 10))
        
        # API é…ç½®
        ttk.Label(config_frame, text="API åŸºç¤ URL:").grid(row=0, column=0, sticky=tk.W, padx=(0, 5))
        kb_base_url_entry = ttk.Entry(config_frame, textvariable=self.kb_base_url, width=40)
        kb_base_url_entry.grid(row=0, column=1, sticky=tk.W+tk.E, padx=(0, 5))
        
        # æ·»åŠ URLæ ¼å¼èªªæ˜
        url_help = ttk.Label(config_frame, text="æ ¼å¼: https://api.maiagent.ai/api æˆ– http://localhost:8000/api", 
                            font=('TkDefaultFont', 8), foreground='gray')
        url_help.grid(row=0, column=2, sticky=tk.W, padx=(5, 0))
        
        ttk.Label(config_frame, text="API é‡‘é‘°:").grid(row=1, column=0, sticky=tk.W, padx=(0, 5), pady=(5, 0))
        kb_api_key_entry = ttk.Entry(config_frame, textvariable=self.kb_api_key, width=40, show="*")
        kb_api_key_entry.grid(row=1, column=1, sticky=tk.W+tk.E, padx=(0, 5), pady=(5, 0))
        
        config_frame.columnconfigure(1, weight=1)
        config_frame.columnconfigure(2, weight=0)  # URLèªªæ˜æ¬„ä½ä¸éœ€è¦æ“´å±•
        
        # é€£æ¥æ¸¬è©¦å’ŒçŸ¥è­˜åº«è¼‰å…¥
        action_frame = ttk.Frame(config_frame)
        action_frame.grid(row=2, column=0, columnspan=2, pady=(10, 0), sticky=tk.W+tk.E)
        
        self.kb_test_button = ttk.Button(action_frame, text="ğŸ§ª æ¸¬è©¦é€£æ¥", command=self.test_kb_connection)
        self.kb_test_button.pack(side=tk.LEFT, padx=(0, 5))
        
        self.kb_load_button = ttk.Button(action_frame, text="ğŸ“‹ è¼‰å…¥çŸ¥è­˜åº«", command=self.load_knowledge_bases)
        self.kb_load_button.pack(side=tk.LEFT, padx=(0, 5))
        
        # çŸ¥è­˜åº«é¸æ“‡
        kb_select_frame = ttk.LabelFrame(left_frame, text="ğŸ“š é¸æ“‡çŸ¥è­˜åº«", padding=10)
        kb_select_frame.pack(fill=tk.X, pady=(0, 10))
        
        # å‰µå»ºå®¹å™¨ä¾†æ­£ç¢ºä½ˆå±€listboxå’Œæ»‘å‹•æ¢
        kb_container = ttk.Frame(kb_select_frame)
        kb_container.pack(fill=tk.BOTH, expand=True)
        
        # å…ˆå‰µå»ºæ»‘å‹•æ¢ï¼ˆå³å´ï¼‰
        kb_scroll = ttk.Scrollbar(kb_container, orient=tk.VERTICAL)
        kb_scroll.pack(side=tk.RIGHT, fill=tk.Y)
        
        # å†å‰µå»ºlistboxï¼ˆå¡«æ»¿å‰©é¤˜ç©ºé–“ï¼‰
        self.kb_listbox = tk.Listbox(kb_container, height=6, yscrollcommand=kb_scroll.set)
        self.kb_listbox.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        self.kb_listbox.bind('<<ListboxSelect>>', self.on_kb_selection_changed)
        
        # é…ç½®æ»‘å‹•æ¢å‘½ä»¤
        kb_scroll.config(command=self.kb_listbox.yview)
        
        # æª”æ¡ˆè¼‰å…¥é€²åº¦æ¢
        kb_progress_frame = ttk.Frame(kb_select_frame)
        kb_progress_frame.pack(fill=tk.X, pady=(5, 0))
        
        ttk.Label(kb_progress_frame, text="æª”æ¡ˆè¼‰å…¥é€²åº¦:").pack(side=tk.LEFT, padx=(0, 5))
        self.kb_files_progress = ttk.Progressbar(kb_progress_frame, mode='determinate', maximum=100)
        self.kb_files_progress.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(0, 5))
        
        # é€²åº¦æ¨™ç±¤
        self.kb_progress_label = ttk.Label(kb_progress_frame, text="0/0", width=10)
        self.kb_progress_label.pack(side=tk.RIGHT)
        
        # æª”æ¡ˆä¸Šå‚³å€åŸŸ
        upload_frame = ttk.LabelFrame(left_frame, text="ğŸ“ æª”æ¡ˆä¸Šå‚³", padding=10)
        upload_frame.pack(fill=tk.X, pady=(0, 10))
        
        # æª”æ¡ˆé¸æ“‡
        file_select_frame = ttk.Frame(upload_frame)
        file_select_frame.pack(fill=tk.X, pady=(0, 5))
        
        ttk.Label(file_select_frame, text="é¸æ“‡æª”æ¡ˆ:").pack(side=tk.LEFT, padx=(0, 5))
        self.upload_file_var = tk.StringVar()
        upload_file_entry = ttk.Entry(file_select_frame, textvariable=self.upload_file_var, state="readonly")
        upload_file_entry.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(0, 5))
        
        browse_file_button = ttk.Button(file_select_frame, text="ç€è¦½...", command=self.browse_upload_file)
        browse_file_button.pack(side=tk.RIGHT)
        
        # ä¸Šå‚³æŒ‰éˆ•
        upload_button_frame = ttk.Frame(upload_frame)
        upload_button_frame.pack(fill=tk.X, pady=(5, 0))
        
        self.upload_start_button = ttk.Button(upload_button_frame, text="ğŸ“¤ é–‹å§‹ä¸Šå‚³", 
                                            command=self.start_file_upload, state=tk.DISABLED)
        self.upload_start_button.pack(side=tk.LEFT, padx=(0, 5))
        
        # ä¸Šå‚³é€²åº¦
        self.upload_progress = ttk.Progressbar(upload_button_frame, mode='indeterminate')
        self.upload_progress.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(5, 0))
        
        # æª”æ¡ˆåŒ¯å‡º
        export_frame = ttk.LabelFrame(left_frame, text="ğŸ’¾ æª”æ¡ˆåŒ¯å‡º", padding=10)
        export_frame.pack(fill=tk.BOTH, expand=True)
        
        # åŒ¯å‡ºç›®éŒ„
        export_dir_frame = ttk.Frame(export_frame)
        export_dir_frame.pack(fill=tk.X, pady=(0, 5))
        
        ttk.Label(export_dir_frame, text="åŒ¯å‡ºç›®éŒ„:").pack(side=tk.LEFT, padx=(0, 5))
        # å¦‚æœæ²’æœ‰è¨­å®šåŒ¯å‡ºç›®éŒ„ï¼Œä½¿ç”¨é è¨­å€¼
        if not self.kb_export_dir.get():
            self.kb_export_dir.set(os.path.join(os.getcwd(), "exports"))
        export_dir_entry = ttk.Entry(export_dir_frame, textvariable=self.kb_export_dir, state="readonly")
        export_dir_entry.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(0, 5))
        
        browse_dir_button = ttk.Button(export_dir_frame, text="ç€è¦½...", command=self.browse_export_directory)
        browse_dir_button.pack(side=tk.RIGHT)
        
        # åŒ¯å‡ºæ§åˆ¶
        export_control_frame = ttk.Frame(export_frame)
        export_control_frame.pack(fill=tk.X, pady=(5, 0))
        
        self.select_all_button = ttk.Button(export_control_frame, text="âœ… å…¨é¸", 
                                          command=self.select_all_files, state=tk.DISABLED)
        self.select_all_button.pack(side=tk.LEFT, padx=(0, 5))
        
        self.deselect_all_button = ttk.Button(export_control_frame, text="âŒ å–æ¶ˆå…¨é¸", 
                                            command=self.deselect_all_files, state=tk.DISABLED)
        self.deselect_all_button.pack(side=tk.LEFT, padx=(0, 5))
        
        self.kb_export_button = ttk.Button(export_control_frame, text="ğŸ“‚ åŒ¯å‡ºé¸ä¸­æª”æ¡ˆ", 
                                         command=self.start_kb_export, state=tk.DISABLED)
        self.kb_export_button.pack(side=tk.RIGHT)
        
        # ä¸¦ç™¼ä¸‹è¼‰é…ç½®
        concurrent_frame = ttk.Frame(export_frame)
        concurrent_frame.pack(fill=tk.X, pady=(5, 0))
        
        ttk.Label(concurrent_frame, text="ä¸¦ç™¼ä¸‹è¼‰æ•¸:").pack(side=tk.LEFT, padx=(0, 5))
        self.concurrent_downloads = tk.IntVar(value=1)  # å›ºå®šç‚º 1ï¼Œå®Œå…¨é¿å…ä¸¦ç™¼
        concurrent_spinbox = ttk.Spinbox(concurrent_frame, from_=1, to=10, width=5, 
                                       textvariable=self.concurrent_downloads)
        concurrent_spinbox.pack(side=tk.LEFT, padx=(0, 10))
        
        # æ·»åŠ èªªæ˜
        ttk.Label(concurrent_frame, text="(1-10ï¼Œæ•¸å€¼è¶Šé«˜ä¸‹è¼‰è¶Šå¿«ä½†å¯èƒ½å¢åŠ æœå‹™å™¨è² æ“”)", 
                 font=('TkDefaultFont', 8), foreground='gray').pack(side=tk.LEFT)
        
        # è¼‰å…¥æ–¹å¼é¸æ“‡
        load_mode_frame = ttk.Frame(export_frame)
        load_mode_frame.pack(fill=tk.X, pady=(5, 0))
        
        self.load_all_at_once = tk.BooleanVar(value=True)
        ttk.Checkbutton(load_mode_frame, text="ğŸ“¦ ä¸€æ¬¡æ€§è¼‰å…¥æ‰€æœ‰æ–‡ä»¶ï¼ˆæ¸›å°‘APIèª¿ç”¨ï¼Œæ¨è–¦ï¼‰", 
                       variable=self.load_all_at_once,
                       command=self.on_load_mode_changed).pack(side=tk.LEFT)
        
        # æª”æ¡ˆåŒ¯å‡ºé€²åº¦æ¢
        export_progress_frame = ttk.Frame(export_frame)
        export_progress_frame.pack(fill=tk.X, pady=(5, 0))
        
        ttk.Label(export_progress_frame, text="æª”æ¡ˆåŒ¯å‡ºé€²åº¦:").pack(side=tk.LEFT, padx=(0, 5))
        self.kb_export_progress = ttk.Progressbar(export_progress_frame, mode='determinate', maximum=100)
        self.kb_export_progress.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(0, 5))
        
        # åŒ¯å‡ºé€²åº¦æ¨™ç±¤
        self.kb_export_progress_label = ttk.Label(export_progress_frame, text="0/0", width=10)
        self.kb_export_progress_label.pack(side=tk.RIGHT)
        
        # å³å´é¢æ¿ï¼šæª”æ¡ˆåˆ—è¡¨å’Œæ—¥èªŒ
        right_frame = ttk.Frame(paned_window)
        paned_window.add(right_frame, weight=2)
        
        # åˆ†å‰²ç‚ºä¸Šä¸‹å…©å€‹å€åŸŸ
        right_paned = ttk.PanedWindow(right_frame, orient=tk.VERTICAL)
        right_paned.pack(fill=tk.BOTH, expand=True)
        
        # æª”æ¡ˆåˆ—è¡¨
        files_frame = ttk.LabelFrame(right_paned, text="ğŸ“„ çŸ¥è­˜åº«æª”æ¡ˆ", padding=5)
        right_paned.add(files_frame, weight=2)
        
        # æª”æ¡ˆåˆ—è¡¨å®¹å™¨
        files_container = ttk.Frame(files_frame)
        files_container.pack(fill=tk.BOTH, expand=True)
        
        # å‰µå»ºTreeviewé¡¯ç¤ºæª”æ¡ˆ
        columns = ("æª”æ¡ˆåç¨±", "å¤§å°", "ç‹€æ…‹", "å‰µå»ºæ™‚é–“")
        self.files_tree = ttk.Treeview(files_container, columns=columns, show="tree headings", height=15)
        
        # è¨­å®šæ¬„ä½
        self.files_tree.heading("#0", text="â˜‘", anchor=tk.W)
        self.files_tree.column("#0", width=30, minwidth=30)
        
        for col in columns:
            self.files_tree.heading(col, text=col, anchor=tk.W)
            if col == "æª”æ¡ˆåç¨±":
                self.files_tree.column(col, width=200, minwidth=150)
            elif col == "å¤§å°":
                self.files_tree.column(col, width=80, minwidth=60)
            elif col == "ç‹€æ…‹":
                self.files_tree.column(col, width=80, minwidth=60)
            else:  # å‰µå»ºæ™‚é–“
                self.files_tree.column(col, width=150, minwidth=120)
        
        self.files_tree.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        
        # æª”æ¡ˆåˆ—è¡¨æ»¾å‹•æ¢
        files_scrollbar = ttk.Scrollbar(files_container, orient=tk.VERTICAL, command=self.files_tree.yview)
        files_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        self.files_tree.config(yscrollcommand=files_scrollbar.set)
        
        # ç¶å®šé›™æ“Šäº‹ä»¶
        self.files_tree.bind("<Double-1>", self.toggle_file_selection)
        
        # æ—¥èªŒå€åŸŸ
        log_frame = ttk.LabelFrame(right_paned, text="ğŸ“‹ æ“ä½œæ—¥èªŒ", padding=5)
        right_paned.add(log_frame, weight=1)
        
        # æ—¥èªŒæ–‡æœ¬æ¡†
        log_container = ttk.Frame(log_frame)
        log_container.pack(fill=tk.BOTH, expand=True)
        
        self.kb_log_text = tk.Text(log_container, height=8, wrap=tk.WORD)
        self.kb_log_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        
        kb_log_scrollbar = ttk.Scrollbar(log_container, orient=tk.VERTICAL, command=self.kb_log_text.yview)
        kb_log_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        self.kb_log_text.config(yscrollcommand=kb_log_scrollbar.set)
        
        # åˆå§‹åŒ–è®Šé‡
        self.current_kb_id = None
        self.kb_files_data = []
        self.upload_thread = None
        self.selected_files = set()
        self.file_info_map = {}
        self.knowledge_bases = []
    
    # === çµ„ç¹”ç®¡ç†åŠŸèƒ½æ–¹æ³• ===
    
    def browse_deploy_csv(self):
        """ç€è¦½é¸æ“‡éƒ¨ç½²ç”¨ CSV æ–‡ä»¶"""
        file_path = filedialog.askopenfilename(
            title="é¸æ“‡çµ„ç¹”æˆå“¡ CSV æ–‡ä»¶",
            filetypes=[("CSV files", "*.csv"), ("All files", "*.*")]
        )
        if file_path:
            self.deploy_csv_file.set(file_path)
    
    def on_create_users_changed(self):
        """ç”¨æˆ¶å‰µå»ºé¸é …è®Šæ›´è™•ç†"""
        if self.deploy_create_users.get():
            self.deploy_referral_entry.config(state='normal')
        else:
            self.deploy_referral_entry.config(state='disabled')
    
    def test_export_connection(self):
        """æ¸¬è©¦çµ„ç¹”åŒ¯å‡º API é€£æ¥"""
        if not self.org_export_api_key.get():
            messagebox.showerror("éŒ¯èª¤", "è«‹è¼¸å…¥ API é‡‘é‘°")
            return
            
        def test_async():
            try:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                async def test():
                    async with MaiAgentApiClient(self.org_export_base_url.get(), 
                                               self.org_export_api_key.get(), 
                                               None) as client:
                        organizations = await client.get_organizations()
                        return len(organizations)
                
                count = loop.run_until_complete(test())
                loop.close()
                
                self.root.after(0, lambda: messagebox.showinfo("æˆåŠŸ", f"é€£æ¥æˆåŠŸï¼æ‰¾åˆ° {count} å€‹çµ„ç¹”"))
                
            except Exception as e:
                error_msg = str(e)
                self.root.after(0, lambda: messagebox.showerror("éŒ¯èª¤", f"é€£æ¥å¤±æ•—ï¼š{error_msg}"))
        
        threading.Thread(target=test_async, daemon=True).start()
    
    def load_export_organizations(self):
        """è¼‰å…¥çµ„ç¹”åˆ—è¡¨"""
        if not self.org_export_api_key.get():
            messagebox.showerror("éŒ¯èª¤", "è«‹å…ˆè¼¸å…¥ API é‡‘é‘°")
            return
        
        def load_async():
            try:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                async def fetch():
                    async with MaiAgentApiClient(self.org_export_base_url.get(), 
                                               self.org_export_api_key.get(), 
                                               None) as client:
                        return await client.get_organizations()
                
                orgs = loop.run_until_complete(fetch())
                loop.close()
                
                self.root.after(0, lambda: self.update_export_organization_list(orgs))
                
            except Exception as e:
                error_msg = str(e)
                self.root.after(0, lambda: messagebox.showerror("éŒ¯èª¤", f"è¼‰å…¥å¤±æ•—ï¼š{error_msg}"))
        
        threading.Thread(target=load_async, daemon=True).start()
    
    def update_export_organization_list(self, organizations):
        """æ›´æ–°åŒ¯å‡ºçµ„ç¹”åˆ—è¡¨"""
        self.export_org_listbox.delete(0, tk.END)
        self.export_organizations = organizations
        
        for org in organizations:
            if isinstance(org, dict):
                name = org.get('name', 'Unknown')
                org_id = org.get('id', 'Unknown')
                self.export_org_listbox.insert(tk.END, f"{name} (ID: {org_id})")
        
        self.log_info(f"è¼‰å…¥äº† {len(organizations)} å€‹çµ„ç¹”")
    
    def start_export(self):
        """é–‹å§‹çµ„ç¹”åŒ¯å‡º"""
        selection = self.export_org_listbox.curselection()
        if not selection:
            messagebox.showerror("éŒ¯èª¤", "è«‹é¸æ“‡è¦åŒ¯å‡ºçš„çµ„ç¹”")
            return
        
        if not self.org_export_api_key.get():
            messagebox.showerror("éŒ¯èª¤", "è«‹è¼¸å…¥ API é‡‘é‘°")
            return
        
        selected_org = self.export_organizations[selection[0]]
        self.selected_export_org_id = selected_org['id']
        
        self.export_button.config(state='disabled')
        
        threading.Thread(target=self.run_export, daemon=True).start()
    
    def run_export(self):
        """åŸ·è¡Œçµ„ç¹”åŒ¯å‡ºï¼ˆåœ¨èƒŒæ™¯åŸ·è¡Œç·’ä¸­ï¼‰"""
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            success = loop.run_until_complete(self.export_organization_data())
            loop.close()
            
            if success:
                self.root.after(0, self.export_completed)
            else:
                self.root.after(0, lambda: self.export_failed("åŒ¯å‡ºéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤"))
                
        except Exception as e:
            error_msg = str(e)
            self.root.after(0, lambda: self.export_failed(error_msg))
    
    async def export_organization_data(self):
        """åŒ¯å‡ºçµ„ç¹”æ•¸æ“š"""
        try:
            async with MaiAgentApiClient(self.org_export_base_url.get(), 
                                       self.org_export_api_key.get(), 
                                       None) as client:
                
                # ç²å–æ¬Šé™åˆ—è¡¨
                self.log_export("ğŸ” æ­£åœ¨ç²å–æ¬Šé™åˆ—è¡¨...")
                permissions = await client.get_permissions()
                self.log_export(f"âœ… æ‰¾åˆ° {len(permissions)} å€‹æ¬Šé™é…ç½®")
                
                # å‰µå»ºæ¬Šé™æ˜ å°„
                permission_id_to_name = {}
                for perm in permissions:
                    if isinstance(perm, dict) and 'id' in perm and 'name' in perm:
                        permission_id_to_name[str(perm['id'])] = perm['name']
                
                # ç²å–çµ„ç¹”æˆå“¡
                self.log_export("ğŸ‘¥ æ­£åœ¨ç²å–çµ„ç¹”æˆå“¡...")
                members = await client.get_organization_members(self.selected_export_org_id)
                self.log_export(f"âœ… æ‰¾åˆ° {len(members)} å€‹æˆå“¡")
                
                # ç²å–çµ„ç¹”ç¾¤çµ„
                self.log_export("ğŸ¢ æ­£åœ¨ç²å–çµ„ç¹”ç¾¤çµ„...")
                groups = await client.get_organization_groups(self.selected_export_org_id)
                self.log_export(f"âœ… æ‰¾åˆ° {len(groups)} å€‹ç¾¤çµ„")
                
                # ç²å–ç¾¤çµ„æˆå“¡ä¿¡æ¯
                group_members_map = {}
                for group in groups:
                    if isinstance(group, dict) and 'id' in group:
                        group_id = group['id']
                        if isinstance(group_id, (str, int)):
                            group_id_str = str(group_id)
                            group_name = group.get('name', 'Unknown')

                            try:
                                self.log_export(f"ğŸ“‹ æ­£åœ¨ç²å–ç¾¤çµ„ {group_name} çš„æˆå“¡åˆ—è¡¨...")
                                group_members = await client.get_group_members(self.selected_export_org_id, group_id_str)
                                group_members_map[group_id_str] = group_members
                                self.log_export(f"ğŸ” ç¾¤çµ„ {group_name} (ID: {group_id}) æœ‰ {len(group_members)} å€‹æˆå“¡")
                            except Exception as e:
                                self.log_export(f"âš ï¸ ç²å–ç¾¤çµ„ {group_name} æˆå“¡å¤±æ•—: {str(e)}")
                                group_members_map[group_id_str] = []
                
                # è™•ç†ç¾¤çµ„æ¬Šé™
                group_permissions_map = {}
                for group in groups:
                    if isinstance(group, dict) and 'id' in group and 'permissions' in group:
                        group_id_str = str(group['id'])
                        group_name = group.get('name', 'Unknown')
                        group_permissions = group.get('permissions', [])
                        
                        permission_names = []
                        for perm in group_permissions:
                            if isinstance(perm, dict) and 'id' in perm:
                                perm_id = str(perm['id'])
                                if perm_id in permission_id_to_name:
                                    permission_names.append(permission_id_to_name[perm_id])
                                    self.log_export(f"âœ… ç¾¤çµ„ {group_name} æ¬Šé™: {permission_id_to_name[perm_id]}")
                            elif isinstance(perm, (str, int)):
                                perm_id = str(perm)
                                if perm_id in permission_id_to_name:
                                    permission_names.append(permission_id_to_name[perm_id])
                                    self.log_export(f"âœ… ç¾¤çµ„ {group_name} æ¬Šé™: {permission_id_to_name[perm_id]}")
                        
                        group_permissions_map[group_id_str] = permission_names
                
                # ç”Ÿæˆ Excel
                org_name = None
                for org in self.export_organizations:
                    if org['id'] == self.selected_export_org_id:
                        org_name = org['name']
                        break
                
                if not org_name:
                    org_name = "Unknown"
                
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                excel_filename = f"organization_members_{org_name}_{timestamp}.xlsx"
                
                self.log_export(f"ğŸ“„ æ­£åœ¨ç”Ÿæˆ Excel æ–‡ä»¶: {excel_filename}")
                
                # æ”¶é›†æ‰€æœ‰æˆå“¡æ•¸æ“š
                member_data_list = []
                
                for member in members:
                        if not isinstance(member, dict):
                            continue
                        
                        member_id = member.get('id')
                        member_name = member.get('name', 'Unknown')
                        member_email = member.get('email', '')
                        is_owner = member.get('is_owner', False)
                        created_at = member.get('created_at', '')
                        
                        if not isinstance(member_id, (str, int)):
                            continue
                        
                        member_id_str = str(member_id)
                        
                        # æŸ¥æ‰¾æˆå“¡æ‰€å±¬ç¾¤çµ„
                        member_groups = []
                        member_group_permissions = []
                        
                        for group_id, group_members in group_members_map.items():
                            if not isinstance(group_members, list):
                                continue
                            
                            for gm in group_members:
                                if isinstance(gm, dict):
                                    if 'member' in gm:
                                        member_data = gm['member']
                                        gm_id = member_data.get('id')
                                    elif 'id' in gm:
                                        gm_id = gm['id']
                                    else:
                                        continue
                                    
                                    if isinstance(gm_id, (str, int)) and str(gm_id) == member_id_str:
                                        # æ‰¾åˆ°å°æ‡‰ç¾¤çµ„
                                        for group in groups:
                                            if isinstance(group, dict) and str(group['id']) == group_id:
                                                group_name = group.get('name', 'Unknown')
                                                member_groups.append(group_name)
                                                
                                                # æ·»åŠ ç¾¤çµ„æ¬Šé™
                                                if group_id in group_permissions_map:
                                                    permissions = group_permissions_map[group_id]
                                                    if permissions:
                                                        perm_str = f"{group_name}({', '.join(permissions)})"
                                                    else:
                                                        perm_str = f"{group_name}(ç„¡æ¬Šé™)"
                                                    member_group_permissions.append(perm_str)
                                                break
                                        break
                        
                        # æ”¶é›†æˆå“¡æ•¸æ“š
                        member_data_list.append({
                            'æˆå“¡ ID': member_id_str,
                            'å§“å': member_name,
                            'é›»å­éƒµä»¶': member_email,
                            'æ˜¯å¦ç‚ºæ“æœ‰è€…': 'æ˜¯' if is_owner else 'å¦',
                            'å»ºç«‹æ™‚é–“': created_at,
                            'æ‰€å±¬ç¾¤çµ„': '; '.join(member_groups),
                            'ç¾¤çµ„æ¬Šé™é…ç½®': '; '.join(member_group_permissions)
                        })
                
                # ç”Ÿæˆ Excel æ–‡ä»¶
                if member_data_list:
                    df = pd.DataFrame(member_data_list)
                    df.to_excel(excel_filename, index=False, engine='openpyxl')
                    self.log_export(f"âœ… Excel æ–‡ä»¶ç”Ÿæˆå®Œæˆ: {excel_filename}")
                else:
                    self.log_export("âš ï¸ ç„¡æˆå“¡æ•¸æ“šå¯åŒ¯å‡º")
                
                return True
                
        except Exception as e:
            self.log_export(f"âŒ åŒ¯å‡ºå¤±æ•—: {str(e)}")
            return False
    
    def export_completed(self):
        """åŒ¯å‡ºå®Œæˆ"""
        self.export_button.config(state='normal')
        messagebox.showinfo("åŒ¯å‡ºå®Œæˆ", "çµ„ç¹”æˆå“¡åŒ¯å‡ºå·²æˆåŠŸå®Œæˆï¼")
        self.log_info("çµ„ç¹”åŒ¯å‡ºå®Œæˆ", 'Organization')
    
    def export_failed(self, error_message):
        """åŒ¯å‡ºå¤±æ•—"""
        self.export_button.config(state='normal')
        messagebox.showerror("åŒ¯å‡ºå¤±æ•—", f"åŒ¯å‡ºéç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{error_message}")
        self.log_error(f"çµ„ç¹”åŒ¯å‡ºå¤±æ•—: {error_message}", 'Organization')
    
    def log_export(self, message):
        """è¨˜éŒ„åŒ¯å‡ºæ—¥èªŒ"""
        self.root.after(0, lambda: self._update_export_log(message))
    
    def _update_export_log(self, message):
        """æ›´æ–°åŒ¯å‡ºæ—¥èªŒé¡¯ç¤º"""
        self.export_log_text.config(state='normal')
        self.export_log_text.insert(tk.END, f"{message}\n")
        self.export_log_text.see(tk.END)
        self.export_log_text.config(state='disabled')
    
    # === å¸³è™Ÿæ‰¹é‡åŒ¯å…¥åŠŸèƒ½ ===
    
    def start_deployment(self):
        """é–‹å§‹å¸³è™Ÿæ‰¹é‡åŒ¯å…¥"""
        # æª¢æŸ¥è¨­å®š
        if not self.deploy_csv_file.get():
            messagebox.showerror("éŒ¯èª¤", "è«‹é¸æ“‡éƒ¨ç½²æ–‡ä»¶ (CSV)")
            return
            
        if not self.deploy_api_key.get():
            messagebox.showerror("éŒ¯èª¤", "è«‹è¼¸å…¥ API é‡‘é‘°")
            return
        
        self.deploy_button.config(state='disabled')
        
        threading.Thread(target=self.run_deployment, daemon=True).start()
    
    def run_deployment(self):
        """åŸ·è¡Œæ‰¹é‡åŒ¯å…¥ï¼ˆåœ¨èƒŒæ™¯åŸ·è¡Œç·’ä¸­ï¼‰"""
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            success = loop.run_until_complete(self.execute_batch_import())
            loop.close()
            
            if success:
                self.root.after(0, self.deployment_completed)
            else:
                self.root.after(0, lambda: self.deployment_failed("åŒ¯å…¥éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤"))
                
        except Exception as e:
            error_msg = str(e)
            self.root.after(0, lambda: self.deployment_failed(error_msg))
    
    async def execute_batch_import(self):
        """åŸ·è¡Œæ‰¹é‡åŒ¯å…¥é‚è¼¯"""
        try:
            async with MaiAgentApiClient(self.deploy_base_url.get(), 
                                       self.deploy_api_key.get(), 
                                       None) as client:
                
                referral_code = self.deploy_referral_code.get() if self.deploy_create_users.get() else None
                processor = BatchImportProcessor(client, self.deploy_csv_file.get(), referral_code)
                
                return await processor.execute_import(
                    organization_name=self.deploy_org_name.get() or None,
                    create_users=self.deploy_create_users.get(),
                    log_callback=self.log_deploy
                )
                
        except Exception as e:
            self.log_deploy(f"âŒ æ‰¹é‡åŒ¯å…¥åŸ·è¡Œå¤±æ•—: {str(e)}")
            return False
    
    def deployment_completed(self):
        """åŒ¯å…¥å®Œæˆ"""
        self.deploy_button.config(state='normal')
        messagebox.showinfo("åŒ¯å…¥å®Œæˆ", "å¸³è™Ÿæ‰¹é‡åŒ¯å…¥å·²æˆåŠŸå®Œæˆï¼")
        self.log_info("å¸³è™Ÿæ‰¹é‡åŒ¯å…¥å®Œæˆ", 'Deployment')
    
    def deployment_failed(self, error_message):
        """åŒ¯å…¥å¤±æ•—"""
        self.deploy_button.config(state='normal')
        messagebox.showerror("åŒ¯å…¥å¤±æ•—", f"åŒ¯å…¥éç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{error_message}")
        self.log_error(f"å¸³è™Ÿæ‰¹é‡åŒ¯å…¥å¤±æ•—: {error_message}", 'Deployment')
    
    def log_deploy(self, message):
        """è¨˜éŒ„åŒ¯å…¥æ—¥èªŒ"""
        self.root.after(0, lambda: self._update_deploy_log(message))
    
    def _update_deploy_log(self, message):
        """æ›´æ–°åŒ¯å…¥æ—¥èªŒé¡¯ç¤º"""
        self.deploy_log_text.config(state='normal')
        self.deploy_log_text.insert(tk.END, f"{message}\n")
        self.deploy_log_text.see(tk.END)
        self.deploy_log_text.config(state='disabled')
    
    # === çŸ¥è­˜åº«ç®¡ç†åŠŸèƒ½ ===
    
    def browse_export_directory(self):
        """ç€è¦½é¸æ“‡åŒ¯å‡ºç›®éŒ„"""
        directory = filedialog.askdirectory(title="é¸æ“‡åŒ¯å‡ºç›®éŒ„")
        if directory:
            self.kb_export_dir.set(directory)
    
    def test_kb_connection(self):
        """æ¸¬è©¦çŸ¥è­˜åº« API é€£æ¥"""
        # ç²å–APIé…ç½®
        base_url = self.kb_base_url.get().strip()
        api_key = self.kb_api_key.get().strip()
        
        # è©³ç´°çš„èª¿è©¦ä¿¡æ¯
        self.log_kb(f"ğŸ” æ¸¬è©¦é€£æ¥ - åŸºç¤URL: {base_url}")
        self.log_kb(f"ğŸ” æ¸¬è©¦é€£æ¥ - APIé‡‘é‘°é•·åº¦: {len(api_key)} å­—ç¬¦")
        self.log_kb(f"ğŸ” æ¸¬è©¦é€£æ¥ - APIé‡‘é‘°å‰ç¶´: {api_key[:10]}..." if len(api_key) > 10 else f"ğŸ” æ¸¬è©¦é€£æ¥ - APIé‡‘é‘°: {api_key}")
        
        if not base_url:
            messagebox.showerror("éŒ¯èª¤", "è«‹è¼¸å…¥ API åŸºç¤ URL")
            self.log_kb("âŒ æ¸¬è©¦å¤±æ•— - æœªè¼¸å…¥åŸºç¤URL")
            return
            
        if not api_key:
            messagebox.showerror("éŒ¯èª¤", "è«‹è¼¸å…¥ API é‡‘é‘°")
            self.log_kb("âŒ æ¸¬è©¦å¤±æ•— - æœªè¼¸å…¥APIé‡‘é‘°")
            return
            
        def test_async():
            try:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                self.root.after(0, lambda: self.log_kb("ğŸš€ é–‹å§‹æ¸¬è©¦APIé€£æ¥..."))
                
                async def test():
                    async with MaiAgentApiClient(base_url, api_key, None) as client:
                        self.root.after(0, lambda: self.log_kb("ğŸ“¡ æ­£åœ¨å‘¼å« get_knowledge_bases API..."))
                        knowledge_bases = await client.get_knowledge_bases()
                        self.root.after(0, lambda: self.log_kb(f"ğŸ“‹ APIå›æ‡‰: æ‰¾åˆ° {len(knowledge_bases)} å€‹çŸ¥è­˜åº«"))
                        return len(knowledge_bases)
                
                count = loop.run_until_complete(test())
                loop.close()
                
                self.root.after(0, lambda: self.log_kb(f"âœ… é€£æ¥æ¸¬è©¦æˆåŠŸï¼å…± {count} å€‹çŸ¥è­˜åº«"))
                self.root.after(0, lambda: messagebox.showinfo("æˆåŠŸ", f"é€£æ¥æˆåŠŸï¼æ‰¾åˆ° {count} å€‹çŸ¥è­˜åº«"))
                
            except Exception as e:
                error_msg = str(e)
                self.root.after(0, lambda: self.log_kb(f"âŒ é€£æ¥æ¸¬è©¦å¤±æ•—: {error_msg}"))
                self.root.after(0, lambda: messagebox.showerror("éŒ¯èª¤", f"é€£æ¥å¤±æ•—ï¼š{error_msg}"))
        
        threading.Thread(target=test_async, daemon=True).start()
    
    def load_knowledge_bases(self):
        """è¼‰å…¥çŸ¥è­˜åº«åˆ—è¡¨"""
        # ç²å–APIé…ç½®
        base_url = self.kb_base_url.get().strip()
        api_key = self.kb_api_key.get().strip()
        
        if not base_url:
            messagebox.showerror("éŒ¯èª¤", "è«‹å…ˆè¼¸å…¥ API åŸºç¤ URL")
            self.log_kb("âŒ è¼‰å…¥å¤±æ•— - æœªè¼¸å…¥åŸºç¤URL")
            return
            
        if not api_key:
            messagebox.showerror("éŒ¯èª¤", "è«‹å…ˆè¼¸å…¥ API é‡‘é‘°")
            self.log_kb("âŒ è¼‰å…¥å¤±æ•— - æœªè¼¸å…¥APIé‡‘é‘°")
            return
        
        def load_async():
            try:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                self.root.after(0, lambda: self.log_kb("ğŸ”„ æ­£åœ¨è¼‰å…¥çŸ¥è­˜åº«åˆ—è¡¨..."))
                
                async def fetch():
                    async with MaiAgentApiClient(base_url, api_key, None) as client:
                        knowledge_bases = await client.get_knowledge_bases()
                        self.root.after(0, lambda: self.log_kb(f"ğŸ“‹ æˆåŠŸç²å– {len(knowledge_bases)} å€‹çŸ¥è­˜åº«"))
                        return knowledge_bases
                
                knowledge_bases = loop.run_until_complete(fetch())
                loop.close()
                
                self.root.after(0, lambda: self.update_knowledge_base_list(knowledge_bases))
                
            except Exception as e:
                error_msg = str(e)
                self.root.after(0, lambda: self.log_kb(f"âŒ è¼‰å…¥çŸ¥è­˜åº«å¤±æ•—: {error_msg}"))
                self.root.after(0, lambda: messagebox.showerror("éŒ¯èª¤", f"è¼‰å…¥çŸ¥è­˜åº«å¤±æ•—ï¼š{error_msg}"))
        
        threading.Thread(target=load_async, daemon=True).start()
    
    def update_knowledge_base_list(self, knowledge_bases):
        """æ›´æ–°çŸ¥è­˜åº«åˆ—è¡¨"""
        self.kb_listbox.delete(0, tk.END)
        self.knowledge_bases = knowledge_bases
        
        for kb in knowledge_bases:
            if isinstance(kb, dict):
                name = kb.get('name', 'Unknown')
                kb_id = kb.get('id', 'Unknown')
                self.kb_listbox.insert(tk.END, f"{name} (ID: {kb_id})")
        
        self.log_kb(f"è¼‰å…¥äº† {len(knowledge_bases)} å€‹çŸ¥è­˜åº«")
    
    def update_files_list(self, files):
        """æ›´æ–°æª”æ¡ˆåˆ—è¡¨"""
        # æ¸…ç©ºç¾æœ‰åˆ—è¡¨
        for item in self.files_tree.get_children():
            self.files_tree.delete(item)
        
        self.kb_files_data = files
        self.selected_files.clear()
        
        for i, file_info in enumerate(files):
            if isinstance(file_info, dict):
                file_id = file_info.get('id', 'Unknown')
                file_name = file_info.get('filename', file_info.get('name', 'Unknown'))
                file_size = file_info.get('file_size', file_info.get('size', 0))
                status = file_info.get('status', 'Unknown')
                created_at = file_info.get('created_at', file_info.get('updated_at', 'Unknown'))
                
                # æ ¼å¼åŒ–æª”æ¡ˆå¤§å°
                if isinstance(file_size, (int, float)) and file_size > 0:
                    if file_size > 1024 * 1024:
                        size_str = f"{file_size / (1024 * 1024):.1f} MB"
                    elif file_size > 1024:
                        size_str = f"{file_size / 1024:.1f} KB"
                    else:
                        size_str = f"{file_size} B"
                else:
                    size_str = "-"
                
                # æ ¼å¼åŒ–ç‹€æ…‹
                status_map = {
                    'pending': 'å¾…è™•ç†',
                    'processing': 'è™•ç†ä¸­',
                    'completed': 'å·²å®Œæˆ',
                    'failed': 'å¤±æ•—',
                    'deleting': 'åˆªé™¤ä¸­'
                }
                status_display = status_map.get(status, status)
                
                # æ ¼å¼åŒ–å‰µå»ºæ™‚é–“
                if created_at and created_at != 'Unknown':
                    try:
                        # å˜—è©¦è§£æä¸¦æ ¼å¼åŒ–æ™‚é–“
                        if 'T' in created_at:
                            date_part = created_at.split('T')[0]
                            time_part = created_at.split('T')[1].split('.')[0] if '.' in created_at else created_at.split('T')[1]
                            created_at = f"{date_part} {time_part[:8]}"
                    except:
                        pass
                
                # æ·»åŠ åˆ°æ¨¹å½¢è¦–åœ–
                item_id = self.files_tree.insert('', 'end', text='â˜', values=(
                    file_name,      # æª”æ¡ˆåç¨±
                    size_str,       # å¤§å°
                    status_display, # ç‹€æ…‹
                    created_at      # å‰µå»ºæ™‚é–“
                ))
                
                # ç‚ºæ¯å€‹itemä¿å­˜æª”æ¡ˆè³‡è¨Šï¼Œä»¥ä¾¿å¾ŒçºŒä½¿ç”¨
                self.file_info_map[item_id] = file_info
        
        # æ›´æ–°æŒ‰éˆ•ç‹€æ…‹
        if len(files) > 0:
            self.select_all_button.config(state=tk.NORMAL)
            self.deselect_all_button.config(state=tk.NORMAL)
            self.kb_export_button.config(state=tk.NORMAL)
        else:
            self.select_all_button.config(state=tk.DISABLED)
            self.deselect_all_button.config(state=tk.DISABLED)
            self.kb_export_button.config(state=tk.DISABLED)
        
        self.log_kb(f"è¼‰å…¥äº† {len(files)} å€‹æª”æ¡ˆ")
    
    def toggle_file_selection(self, event):
        """åˆ‡æ›æª”æ¡ˆé¸æ“‡ç‹€æ…‹"""
        item = self.files_tree.selection()[0] if self.files_tree.selection() else None
        if item:
            current_text = self.files_tree.item(item, 'text')
            if current_text == 'â˜':
                # é¸ä¸­
                self.files_tree.item(item, text='â˜‘')
                self.selected_files.add(item)
            else:
                # å–æ¶ˆé¸ä¸­
                self.files_tree.item(item, text='â˜') 
                self.selected_files.discard(item)
    
    def select_all_files(self):
        """é¸æ“‡æ‰€æœ‰æª”æ¡ˆ"""
        for item_id in self.files_tree.get_children():
            self.files_tree.item(item_id, text='â˜‘')
            self.selected_files.add(item_id)
        
        self.log_kb("å·²é¸æ“‡æ‰€æœ‰æª”æ¡ˆ")
    
    def deselect_all_files(self):
        """å–æ¶ˆé¸æ“‡æ‰€æœ‰æª”æ¡ˆ"""
        for item_id in self.files_tree.get_children():
            self.files_tree.item(item_id, text='â˜')
        self.selected_files.clear()
        
        self.log_kb("å·²å–æ¶ˆé¸æ“‡æ‰€æœ‰æª”æ¡ˆ")
    
    def start_kb_export(self):
        """é–‹å§‹çŸ¥è­˜åº«æ–‡ä»¶åŒ¯å‡º"""
        # æª¢æŸ¥è¨­å®š
        if not self.selected_kb_id:
            messagebox.showerror("éŒ¯èª¤", "è«‹å…ˆé¸æ“‡çŸ¥è­˜åº«")
            return
        
        if not self.kb_api_key.get():
            messagebox.showerror("éŒ¯èª¤", "è«‹è¼¸å…¥ API é‡‘é‘°")
            return
        
        if not self.kb_export_dir.get():
            messagebox.showerror("éŒ¯èª¤", "è«‹é¸æ“‡åŒ¯å‡ºç›®éŒ„")
            return
        
        # æª¢æŸ¥é¸ä¸­çš„æ–‡ä»¶
        selected_files = [
            self.file_info_map[item_id] for item_id in self.selected_files
            if item_id in self.file_info_map
        ]
        
        if not selected_files:
            messagebox.showerror("éŒ¯èª¤", "è«‹è‡³å°‘é¸æ“‡ä¸€å€‹æ–‡ä»¶")
            return
        
        self.kb_export_button.config(state='disabled')
        # é‡ç½®æª”æ¡ˆåŒ¯å‡ºé€²åº¦æ¢
        self.kb_export_progress.configure(value=0)
        self.kb_export_progress_label.config(text=f"0/{len(selected_files)}")
        
        threading.Thread(target=self.run_kb_export, args=(selected_files,), daemon=True).start()
    
    async def _download_single_file_concurrent(self, client, file_info, kb_export_path, download_stats, semaphore, file_index):
        """ä¸¦è¡Œä¸‹è¼‰å–®å€‹æ–‡ä»¶"""
        async with semaphore:  # æ§åˆ¶ä¸¦ç™¼æ•¸é‡
            file_id = file_info.get('id')
            file_name = file_info.get('filename', file_info.get('name', f'file_{file_id}'))
            file_status = file_info.get('status', 'unknown')
            
            try:
                # æª¢æŸ¥æ–‡ä»¶ç‹€æ…‹
                if file_status in ['deleting', 'failed']:
                    self.log_kb(f"âš ï¸ è·³éæ–‡ä»¶ {file_name}ï¼šç‹€æ…‹ç‚º {file_status}")
                    async with download_stats['lock']:
                        download_stats['failed'] += 1
                        download_stats['completed'] += 1
                        self._update_concurrent_progress(download_stats)
                    return
                
                self.log_kb(f"ğŸ“¥ é–‹å§‹ä¸‹è¼‰æ–‡ä»¶: {file_name}")
                
                # ä¸‹è¼‰æ–‡ä»¶ï¼ˆä½¿ç”¨é‡è©¦æ©Ÿåˆ¶ï¼‰
                file_data = await client.download_knowledge_base_file(self.selected_kb_id, file_id, max_retries=3)
                
                # ä¿å­˜æ–‡ä»¶
                file_path = kb_export_path / file_name
                with open(file_path, 'wb') as f:
                    f.write(file_data)
                
                self.log_kb(f"âœ… æ–‡ä»¶ä¸‹è¼‰æˆåŠŸ: {file_name} ({len(file_data)} bytes)")
                
                # æ›´æ–°çµ±è¨ˆ
                async with download_stats['lock']:
                    download_stats['successful'] += 1
                    download_stats['completed'] += 1
                    self._update_concurrent_progress(download_stats)
                    
            except Exception as e:
                error_msg = str(e)
                self.log_kb(f"âŒ æ–‡ä»¶ä¸‹è¼‰å¤±æ•—: {file_name} (ID: {file_id})")
                self.log_kb(f"   éŒ¯èª¤è©³æƒ…: {error_msg}")
                
                # æ ¹æ“šéŒ¯èª¤é¡å‹æä¾›æ›´å…·é«”çš„èªªæ˜
                if "502" in error_msg or "503" in error_msg or "504" in error_msg:
                    self.log_kb(f"   å¯èƒ½åŸå› : æœå‹™å™¨æš«æ™‚ä¸å¯ç”¨ï¼Œå·²å˜—è©¦é‡è©¦")
                elif "404" in error_msg:
                    self.log_kb(f"   å¯èƒ½åŸå› : æ–‡ä»¶ä¸å­˜åœ¨æˆ–ç„¡ä¸‹è¼‰æ¬Šé™")
                elif "è¶…æ™‚" in error_msg:
                    self.log_kb(f"   å¯èƒ½åŸå› : ç¶²è·¯é€£æ¥è¶…æ™‚")
                
                # æ›´æ–°çµ±è¨ˆ
                async with download_stats['lock']:
                    download_stats['failed'] += 1
                    download_stats['completed'] += 1
                    self._update_concurrent_progress(download_stats)
    
    def _update_concurrent_progress(self, download_stats):
        """æ›´æ–°ä¸¦è¡Œä¸‹è¼‰é€²åº¦ï¼ˆç·šç¨‹å®‰å…¨ï¼‰"""
        if not self.gui_running:
            return
            
        completed = download_stats['completed']
        total = download_stats['total']
        successful = download_stats['successful']
        failed = download_stats['failed']
        
        # æ›´æ–°é€²åº¦æ¢ï¼ˆç·šç¨‹å®‰å…¨ï¼‰
        progress = (completed / total) * 100 if total > 0 else 0
        try:
            self.root.after(0, lambda p=progress: self._safe_update_progress_bar(p))
            self.root.after(0, lambda c=completed, t=total, s=successful, f=failed: 
                           self._safe_update_progress_label(c, t, s, f))
        except Exception as e:
            # å¦‚æœ GUI æ›´æ–°å¤±æ•—ï¼Œè¨˜éŒ„ä½†ä¸æ‹‹å‡ºç•°å¸¸
            print(f"GUI æ›´æ–°å¤±æ•—: {e}")
    
    def _safe_update_progress_bar(self, progress_value):
        """å®‰å…¨æ›´æ–°é€²åº¦æ¢"""
        try:
            if self.gui_running and hasattr(self, 'kb_export_progress'):
                self.kb_export_progress.configure(value=progress_value)
        except Exception:
            pass
            
    def _safe_update_progress_label(self, completed, total, successful, failed):
        """å®‰å…¨æ›´æ–°é€²åº¦æ¨™ç±¤"""
        try:
            if self.gui_running and hasattr(self, 'kb_export_progress_label'):
                self.kb_export_progress_label.config(text=f"{completed}/{total} (æˆåŠŸ:{successful}, å¤±æ•—:{failed})")
        except Exception:
            pass
    
    def _safe_update_kb_progress_bar(self, progress_value):
        """å®‰å…¨æ›´æ–°çŸ¥è­˜åº«æ–‡ä»¶è¼‰å…¥é€²åº¦æ¢"""
        try:
            if self.gui_running and hasattr(self, 'kb_files_progress'):
                self.kb_files_progress.configure(value=progress_value)
        except Exception:
            pass
            
    def _safe_update_kb_progress_label(self, current, total):
        """å®‰å…¨æ›´æ–°çŸ¥è­˜åº«æ–‡ä»¶è¼‰å…¥é€²åº¦æ¨™ç±¤"""
        try:
            if self.gui_running and hasattr(self, 'kb_progress_label'):
                self.kb_progress_label.config(text=f"{current}/{total}")
        except Exception:
            pass
    
    def _safe_update_kb_progress_label_text(self, text):
        """å®‰å…¨æ›´æ–°çŸ¥è­˜åº«æ–‡ä»¶è¼‰å…¥é€²åº¦æ¨™ç±¤ï¼ˆä»»æ„æ–‡æœ¬ï¼‰"""
        try:
            if self.gui_running and hasattr(self, 'kb_progress_label'):
                self.kb_progress_label.config(text=text)
        except Exception:
            pass
    
    def run_kb_export(self, selected_files):
        """åŸ·è¡ŒçŸ¥è­˜åº«æ–‡ä»¶åŒ¯å‡ºï¼ˆåœ¨èƒŒæ™¯åŸ·è¡Œç·’ä¸­ï¼‰"""
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            result = loop.run_until_complete(self.export_kb_files(selected_files))
            loop.close()
            
            if isinstance(result, dict):  # æˆåŠŸï¼ŒåŒ…å«çµ±è¨ˆä¿¡æ¯
                export_stats = result
                if self.gui_running:
                    self.root.after(0, lambda: self.kb_export_completed(export_stats))
            elif result:  # èˆŠç‰ˆæœ¬çš„å¸ƒçˆ¾è¿”å›å€¼
                if self.gui_running:
                    self.root.after(0, lambda: self.kb_export_completed())
            else:
                if self.gui_running:
                    self.root.after(0, lambda: self.kb_export_failed("åŒ¯å‡ºéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤"))
                
        except Exception as e:
            error_msg = str(e)
            if self.gui_running:
                self.root.after(0, lambda: self.kb_export_failed(error_msg))
    
    async def export_kb_files(self, selected_files):
        """åŒ¯å‡ºçŸ¥è­˜åº«æ–‡ä»¶ï¼ˆçµ‚æ¥µä¸²è¡Œä¸‹è¼‰ - å®Œå…¨ç„¡æ—¥èªŒï¼‰"""
        try:
            # çµ‚æ¥µéœé»˜æ¨¡å¼ - å®Œå…¨ç¦ç”¨æ‰€æœ‰æ—¥èªŒå’ŒGUIæ›´æ–°
            self._download_in_progress = True
            self._emergency_throttle = True  # å¼·åˆ¶å•Ÿç”¨ç·Šæ€¥é™æµ
            print(f"[SILENT] é–‹å§‹ä¸²è¡Œä¸‹è¼‰ {len(selected_files)} å€‹æ–‡ä»¶")
            
            # ä½¿ç”¨å®Œå…¨ç„¡æ—¥èªŒçš„APIå®¢æˆ¶ç«¯
            async with MaiAgentApiClient(self.kb_base_url.get(), 
                                       self.kb_api_key.get(), 
                                       None) as client:
                
                total_files = len(selected_files)
                export_dir = Path(self.kb_export_dir.get())
                
                # å‰µå»ºåŒ¯å‡ºç›®éŒ„
                kb_name = "unknown_kb"
                for kb in self.knowledge_bases:
                    if kb['id'] == self.selected_kb_id:
                        kb_name = kb.get('name', 'unknown_kb')
                        break
                
                kb_export_path = export_dir / f"knowledge_base_{kb_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                kb_export_path.mkdir(parents=True, exist_ok=True)
                
                print(f"[DOWNLOAD] å‰µå»ºåŒ¯å‡ºç›®éŒ„: {kb_export_path}")
                print(f"[DOWNLOAD] é–‹å§‹ä¸²è¡Œä¸‹è¼‰ {total_files} å€‹æ–‡ä»¶")
                
                # ä¸²è¡Œä¸‹è¼‰çµ±è¨ˆ
                successful = 0
                failed = 0
                
                # ä¸²è¡Œä¸‹è¼‰æ¯å€‹æ–‡ä»¶ - ä¿®å¾©æ–‡ä»¶åå’Œé€²åº¦æ¢å•é¡Œ
                for i, file_info in enumerate(selected_files):
                    # å®‰å…¨çš„æ–‡ä»¶è™•ç†æµç¨‹
                    safe_filename = "unknown_file"
                    final_filename = "unknown_file"
                    
                    try:
                        # è™•ç†æ–‡ä»¶åï¼šé•·åº¦é™åˆ¶å’Œç‰¹æ®Šå­—ç¬¦æ¸…ç†
                        original_filename = file_info.get('filename', f'file_{file_info.get("id", "unknown")}')
                        safe_filename = self._sanitize_filename(original_filename)
                        print(f"[DOWNLOAD] ä¸‹è¼‰ {i+1}/{total_files}: {safe_filename}")
                        
                        # ç¢ºä¿æ–‡ä»¶åå”¯ä¸€ï¼ˆé¿å…é‡è¤‡ï¼‰
                        final_filename = self._ensure_unique_filename(kb_export_path, safe_filename)
                        
                        # ç°¡å–®ä¸‹è¼‰ - ç„¡é‡è©¦ï¼Œç„¡è¤‡é›œéŒ¯èª¤è™•ç†
                        file_content = await client.download_knowledge_base_file(
                            self.selected_kb_id, file_info['id'], max_retries=1
                        )
                        
                        # å®‰å…¨ä¿å­˜æ–‡ä»¶
                        file_path = kb_export_path / final_filename
                        with open(file_path, 'wb') as f:
                            f.write(file_content)
                        
                        successful += 1
                        print(f"[DOWNLOAD] âœ… æˆåŠŸ: {final_filename}")
                        
                    except Exception as e:
                        failed += 1
                        print(f"[DOWNLOAD] âŒ å¤±æ•—: {final_filename} - {str(e)[:100]}")
                    
                    # å®‰å…¨æ›´æ–°é€²åº¦æ¢ï¼ˆé‡æ–°å•Ÿç”¨ï¼Œä½†ä½¿ç”¨ç°¡åŒ–ç‰ˆæœ¬ï¼‰
                    progress = ((i + 1) / total_files) * 100
                    print(f"[DOWNLOAD] é€²åº¦: {progress:.1f}% ({successful} æˆåŠŸ, {failed} å¤±æ•—)")
                    
                    # å®‰å…¨çš„GUIé€²åº¦æ›´æ–°ï¼ˆä¿®å¾©Lambdaé–‰åŒ…å•é¡Œï¼‰
                    try:
                        if self.gui_running:
                            # å‰µå»ºå±€éƒ¨è®Šé‡å‰¯æœ¬ï¼Œé¿å…Lambdaé–‰åŒ…å•é¡Œ
                            current_progress = progress
                            current_index = i + 1
                            current_successful = successful
                            current_failed = failed
                            self.root.after(0, 
                                lambda: self._update_export_progress_safe(
                                    current_progress, current_index, total_files, 
                                    current_successful, current_failed
                                )
                            )
                    except Exception:
                        # å¿½ç•¥GUIæ›´æ–°éŒ¯èª¤ï¼Œç¹¼çºŒä¸‹è¼‰
                        pass
                
                # æœ€çµ‚çµ±è¨ˆï¼ˆå«å®‰å…¨GUIæ›´æ–°ï¼‰
                print(f"[DOWNLOAD] ğŸ“Š ä¸²è¡Œä¸‹è¼‰å®Œæˆçµ±è¨ˆ:")
                print(f"[DOWNLOAD]    æˆåŠŸ: {successful} å€‹æ–‡ä»¶")
                print(f"[DOWNLOAD]    å¤±æ•—: {failed} å€‹æ–‡ä»¶")
                print(f"[DOWNLOAD]    ç¸½è¨ˆ: {total_files} å€‹æ–‡ä»¶")
                print(f"[DOWNLOAD]    åŒ¯å‡ºç›®éŒ„: {kb_export_path}")
                
                # æœ€çµ‚é€²åº¦æ¢æ›´æ–°ï¼ˆä¿®å¾©Lambdaé–‰åŒ…ï¼‰
                try:
                    if self.gui_running:
                        # å‰µå»ºæœ€çµ‚å€¼çš„å±€éƒ¨å‰¯æœ¬
                        final_successful = successful
                        final_failed = failed
                        final_total = total_files
                        self.root.after(0, 
                            lambda: self._update_export_progress_safe(
                                100, final_total, final_total, final_successful, final_failed
                            )
                        )
                except Exception:
                    pass
                
                # æ ¹æ“šæˆåŠŸç‡åˆ¤å®šåŒ¯å‡ºçµæœ
                success_rate = successful / total_files if total_files > 0 else 0
                
                # æº–å‚™çµ±è¨ˆä¿¡æ¯
                export_stats = {
                    'successful': successful,
                    'failed': failed,
                    'total': total_files,
                    'success_rate': success_rate,
                    'concurrent': 1  # ä¸²è¡Œä¸‹è¼‰
                }
                
                if successful > 0:
                    if failed == 0:
                        print(f"[DOWNLOAD] ğŸ‰ ä¸²è¡Œä¸‹è¼‰å®Œå…¨æˆåŠŸï¼")
                    elif success_rate >= 0.8:  # 80% æˆåŠŸç‡è¦–ç‚ºæˆåŠŸ
                        print(f"[DOWNLOAD] âœ… ä¸²è¡Œä¸‹è¼‰åŸºæœ¬æˆåŠŸï¼ˆæˆåŠŸç‡: {success_rate:.1%}ï¼‰")
                    else:
                        print(f"[DOWNLOAD] âš ï¸ ä¸²è¡Œä¸‹è¼‰éƒ¨åˆ†æˆåŠŸï¼ˆæˆåŠŸç‡: {success_rate:.1%}ï¼‰")
                    return export_stats
                else:
                    # å®Œå…¨å¤±æ•—
                    raise Exception(f"ä¸²è¡Œä¸‹è¼‰å®Œå…¨å¤±æ•—ï¼š{failed} å€‹æ–‡ä»¶éƒ½ç„¡æ³•ä¸‹è¼‰")
                
        except Exception as e:
            print(f"[DOWNLOAD] âŒ åŒ¯å‡ºå¤±æ•—: {str(e)}")
            return False
        finally:
            # ç¦ç”¨ä¸‹è¼‰éœé»˜æ¨¡å¼
            self._download_in_progress = False
            self._emergency_throttle = False
            print("[DOWNLOAD] ä¸‹è¼‰å®Œæˆï¼Œéœé»˜æ¨¡å¼å·²ç¦ç”¨")
    
    def _sanitize_filename(self, filename: str) -> str:
        """æ¸…ç†æ–‡ä»¶åï¼šè™•ç†é•·åº¦é™åˆ¶å’Œç‰¹æ®Šå­—ç¬¦ï¼ˆå¢å¼·ç‰ˆæœ¬ï¼‰"""
        try:
            import re
            import os
            import time
            
            # å®‰å…¨æª¢æŸ¥è¼¸å…¥
            if not filename or not isinstance(filename, str):
                return f"safe_file_{int(time.time())}.txt"
            
            # ç§»é™¤æˆ–æ›¿æ›ä¸å®‰å…¨çš„å­—ç¬¦
            # ä¿ç•™ä¸­æ–‡å­—ç¬¦ï¼Œåªæ›¿æ›æ–‡ä»¶ç³»çµ±ä¸æ”¯æŒçš„å­—ç¬¦
            unsafe_chars = r'[<>:"/\\|?*\x00-\x1f\x7f-\x9f]'
            safe_filename = re.sub(unsafe_chars, '_', filename)
            
            # ç§»é™¤é€£çºŒçš„ä¸‹åŠƒç·šå’Œå‰å¾Œç©ºç™½
            safe_filename = re.sub(r'_+', '_', safe_filename).strip('_. ')
            
            # è™•ç†æ–‡ä»¶åé•·åº¦é™åˆ¶ï¼ˆä¿ç•™å‰¯æª”åï¼‰
            name_part, ext_part = os.path.splitext(safe_filename)
            max_name_length = 180  # æ›´ä¿å®ˆçš„é™åˆ¶
            
            if len(name_part) > max_name_length:
                # æˆªæ–·åç¨±éƒ¨åˆ†ï¼Œä¿æŒå‰¯æª”å
                name_part = name_part[:max_name_length].rstrip('._')
                safe_filename = name_part + ext_part
            
            # ç¢ºä¿æ–‡ä»¶åä¸ç‚ºç©ºå’Œæœ‰æ•ˆ
            if not safe_filename or safe_filename in ['.', '..', '_']:
                safe_filename = f"safe_file_{int(time.time())}.txt"
            
            # ç¢ºä¿æœ‰å‰¯æª”å
            if '.' not in safe_filename:
                safe_filename += '.txt'
            
            return safe_filename
            
        except Exception:
            # å¦‚æœä»»ä½•æ­¥é©Ÿå¤±æ•—ï¼Œè¿”å›å®‰å…¨çš„é è¨­å€¼
            import time
            return f"fallback_file_{int(time.time())}.txt"
    
    def _ensure_unique_filename(self, directory: Path, filename: str) -> str:
        """ç¢ºä¿æ–‡ä»¶ååœ¨ç›®éŒ„ä¸­å”¯ä¸€ï¼ˆå¢å¼·ç‰ˆæœ¬ï¼‰"""
        try:
            import os
            import time
            
            # å®‰å…¨æª¢æŸ¥è¼¸å…¥
            if not filename:
                filename = f"safe_file_{int(time.time())}.txt"
            
            base_path = directory / filename
            if not base_path.exists():
                return filename
            
            # æ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ åºè™Ÿ
            name_part, ext_part = os.path.splitext(filename)
            
            # é™åˆ¶å¾ªç’°æ¬¡æ•¸ï¼Œé˜²æ­¢ç„¡é™å¾ªç’°
            for counter in range(1, 100):
                new_filename = f"{name_part}_{counter}{ext_part}"
                new_path = directory / new_filename
                if not new_path.exists():
                    return new_filename
            
            # å¦‚æœ100æ¬¡éƒ½ä¸è¡Œï¼Œä½¿ç”¨æ™‚é–“æˆ³
            timestamp = int(time.time())
            return f"{name_part}_{timestamp}{ext_part}"
            
        except Exception:
            # å¦‚æœä»»ä½•æ­¥é©Ÿå¤±æ•—ï¼Œè¿”å›å¸¶æ™‚é–“æˆ³çš„å®‰å…¨åç¨±
            import time
            return f"emergency_file_{int(time.time())}.txt"
    
    def _update_export_progress_safe(self, progress: float, current: int, total: int, successful: int, failed: int):
        """å®‰å…¨çš„é€²åº¦æ¢æ›´æ–°æ–¹æ³•"""
        try:
            if not self.gui_running:
                return
                
            # æ›´æ–°é€²åº¦æ¢
            if hasattr(self, 'kb_export_progress'):
                self.kb_export_progress.configure(value=progress)
            
            # æ›´æ–°æ¨™ç±¤
            if hasattr(self, 'kb_export_progress_label'):
                status_text = f"{current}/{total} æª”æ¡ˆ (æˆåŠŸ: {successful}, å¤±æ•—: {failed})"
                self.kb_export_progress_label.config(text=status_text)
                
        except Exception:
            # å®Œå…¨å¿½ç•¥GUIæ›´æ–°éŒ¯èª¤
            pass
    
    def kb_export_completed(self, export_stats=None):
        """çŸ¥è­˜åº«åŒ¯å‡ºå®Œæˆ"""
        # ç¢ºä¿é—œé–‰éœé»˜æ¨¡å¼
        self._download_in_progress = False
        self._emergency_throttle = False
        print("[DOWNLOAD] ä¸‹è¼‰å®Œæˆï¼Œéœé»˜æ¨¡å¼å·²ç¦ç”¨")
        
        self.kb_export_button.config(state='normal')
        # é‡ç½®é€²åº¦æ¢
        self.kb_export_progress.configure(value=0)
        self.kb_export_progress_label.config(text="0/0")
        
        # é¡¯ç¤ºè©³ç´°çš„åŒ¯å‡ºçµæœ
        if export_stats:
            successful = export_stats.get('successful', 0)
            failed = export_stats.get('failed', 0)
            total = successful + failed
            concurrent = export_stats.get('concurrent', 1)
            
            if failed == 0:
                message = f"çŸ¥è­˜åº«æ–‡ä»¶ä¸¦è¡Œä¸‹è¼‰å®Œå…¨æˆåŠŸï¼\n\næˆåŠŸåŒ¯å‡º {successful} å€‹æ–‡ä»¶\nä¸¦ç™¼æ•¸: {concurrent}"
                title = "ä¸¦è¡Œä¸‹è¼‰å®Œæˆ"
            else:
                success_rate = (successful / total) * 100 if total > 0 else 0
                message = f"çŸ¥è­˜åº«æ–‡ä»¶ä¸¦è¡Œä¸‹è¼‰å·²å®Œæˆï¼\n\næˆåŠŸ: {successful} å€‹æ–‡ä»¶\nå¤±æ•—: {failed} å€‹æ–‡ä»¶\næˆåŠŸç‡: {success_rate:.1f}%\nä¸¦ç™¼æ•¸: {concurrent}"
                title = "ä¸¦è¡Œä¸‹è¼‰å®Œæˆ"
        else:
            message = "çŸ¥è­˜åº«æ–‡ä»¶ä¸¦è¡Œä¸‹è¼‰å·²æˆåŠŸå®Œæˆï¼"
            title = "ä¸¦è¡Œä¸‹è¼‰å®Œæˆ"
            
        messagebox.showinfo(title, message)
        self.log_info("çŸ¥è­˜åº«æ–‡ä»¶åŒ¯å‡ºå®Œæˆ", 'KnowledgeBase')
    
    def kb_export_failed(self, error_message):
        """çŸ¥è­˜åº«åŒ¯å‡ºå¤±æ•—"""
        # ç¢ºä¿é—œé–‰éœé»˜æ¨¡å¼
        self._download_in_progress = False
        self._emergency_throttle = False
        print("[DOWNLOAD] ä¸‹è¼‰å¤±æ•—ï¼Œéœé»˜æ¨¡å¼å·²ç¦ç”¨")
        
        self.kb_export_button.config(state='normal')
        # é‡ç½®é€²åº¦æ¢
        self.kb_export_progress.configure(value=0)
        self.kb_export_progress_label.config(text="åŒ¯å‡ºå¤±æ•—")
        messagebox.showerror("åŒ¯å‡ºå¤±æ•—", f"åŒ¯å‡ºéç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{error_message}")
        self.log_error(f"çŸ¥è­˜åº«æ–‡ä»¶åŒ¯å‡ºå¤±æ•—: {error_message}", 'KnowledgeBase')
    
    def log_kb(self, message):
        """è¨˜éŒ„çŸ¥è­˜åº«æ—¥èªŒ"""
        self.root.after(0, lambda: self._update_kb_log(message))
    
    def _update_kb_log(self, message):
        """æ›´æ–°çŸ¥è­˜åº«æ—¥èªŒé¡¯ç¤º"""
        if self.kb_log_text:
            self.kb_log_text.insert(tk.END, f"{message}\n")
            self.kb_log_text.see(tk.END)
            self.root.update()

    def browse_upload_file(self):
        """ç€è¦½é¸æ“‡è¦ä¸Šå‚³çš„æª”æ¡ˆ"""
        filetypes = [
            ("æ–‡å­—æª”æ¡ˆ", "*.txt"),
            ("Markdown æª”æ¡ˆ", "*.md"),
            ("PDF æª”æ¡ˆ", "*.pdf"),
            ("Word æª”æ¡ˆ", "*.docx"),
            ("PowerPoint æª”æ¡ˆ", "*.pptx"),
            ("Excel æª”æ¡ˆ", "*.xlsx"),
            ("æ‰€æœ‰æª”æ¡ˆ", "*.*")
        ]
        
        filename = filedialog.askopenfilename(
            title="é¸æ“‡è¦ä¸Šå‚³çš„æª”æ¡ˆ",
            filetypes=filetypes
        )
        
        if filename:
            self.upload_file_var.set(filename)
            # æª¢æŸ¥æ˜¯å¦é¸æ“‡äº†çŸ¥è­˜åº«
            if self.current_kb_id:
                self.upload_start_button.config(state=tk.NORMAL)
            self.log_kb(f"å·²é¸æ“‡æª”æ¡ˆ: {os.path.basename(filename)}")

    def start_file_upload(self):
        """é–‹å§‹æª”æ¡ˆä¸Šå‚³"""
        if not self.upload_file_var.get():
            messagebox.showwarning("è­¦å‘Š", "è«‹å…ˆé¸æ“‡è¦ä¸Šå‚³çš„æª”æ¡ˆ")
            return
        
        if not self.current_kb_id:
            messagebox.showwarning("è­¦å‘Š", "è«‹å…ˆé¸æ“‡çŸ¥è­˜åº«")
            return
        
        # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
        file_path = self.upload_file_var.get()
        if not os.path.exists(file_path):
            messagebox.showerror("éŒ¯èª¤", "é¸æ“‡çš„æª”æ¡ˆä¸å­˜åœ¨")
            return
        
        # æª¢æŸ¥æª”æ¡ˆå¤§å°ï¼ˆé™åˆ¶100MBï¼‰
        file_size = os.path.getsize(file_path)
        max_size = 100 * 1024 * 1024  # 100MB
        if file_size > max_size:
            messagebox.showerror("éŒ¯èª¤", f"æª”æ¡ˆéå¤§ï¼Œæœ€å¤§æ”¯æ´ {max_size // (1024*1024)} MB")
            return
        
        # é–‹å§‹ä¸Šå‚³
        self.upload_start_button.config(state=tk.DISABLED)
        self.upload_progress.start()
        
        filename = os.path.basename(file_path)
        self.log_kb(f"é–‹å§‹ä¸Šå‚³æª”æ¡ˆ: {filename}")
        
        # åœ¨èƒŒæ™¯åŸ·è¡Œä¸Šå‚³
        self.upload_thread = threading.Thread(target=self.run_file_upload, daemon=True)
        self.upload_thread.start()

    def run_file_upload(self):
        """åŸ·è¡Œæª”æ¡ˆä¸Šå‚³çš„èƒŒæ™¯è™•ç†"""
        try:
            # å–å¾—APIé…ç½®
            base_url = self.kb_base_url_var.get().strip()
            api_key = self.kb_api_key_var.get().strip()
            file_path = self.upload_file_var.get()
            
            if not base_url or not api_key:
                self.root.after(0, lambda: self.upload_failed("è«‹å…ˆé…ç½®APIåŸºç¤URLå’ŒAPIé‡‘é‘°"))
                return
            
            def upload_async():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    async def upload():
                        async with MaiAgentApiClient(base_url, api_key, None) as client:
                            result = await client.upload_file_to_knowledge_base(
                                kb_id=self.current_kb_id,
                                file_path=file_path
                            )
                            return result
                    
                    result = loop.run_until_complete(upload())
                    
                    # ä¸Šå‚³æˆåŠŸ
                    self.root.after(0, lambda: self.upload_completed(result))
                    
                except Exception as e:
                    error_msg = f"ä¸Šå‚³å¤±æ•—: {str(e)}"
                    self.root.after(0, lambda: self.upload_failed(error_msg))
                finally:
                    loop.close()
            
            upload_async()
            
        except Exception as e:
            error_msg = f"ä¸Šå‚³æº–å‚™å¤±æ•—: {str(e)}"
            self.root.after(0, lambda: self.upload_failed(error_msg))

    def upload_completed(self, result):
        """æª”æ¡ˆä¸Šå‚³å®Œæˆå›èª¿"""
        self.upload_progress.stop()
        self.upload_start_button.config(state=tk.NORMAL)
        
        if result and len(result) > 0:
            uploaded_file = result[0]
            filename = uploaded_file.get('filename', 'æœªçŸ¥æª”æ¡ˆ')
            self.log_kb(f"âœ… æª”æ¡ˆä¸Šå‚³æˆåŠŸ: {filename}")
            
            # æ¸…ç©ºæª”æ¡ˆé¸æ“‡
            self.upload_file_var.set("")
            self.upload_start_button.config(state=tk.DISABLED)
            
            # é‡æ–°è¼‰å…¥æª”æ¡ˆåˆ—è¡¨
            self.load_kb_files()
            
            messagebox.showinfo("æˆåŠŸ", f"æª”æ¡ˆ '{filename}' ä¸Šå‚³æˆåŠŸï¼")
        else:
            self.log_kb("âŒ ä¸Šå‚³å®Œæˆä½†æœªç²å¾—æª”æ¡ˆè³‡è¨Š")

    def upload_failed(self, error_message):
        """æª”æ¡ˆä¸Šå‚³å¤±æ•—å›èª¿"""
        self.upload_progress.stop()
        self.upload_start_button.config(state=tk.NORMAL)
        
        self.log_kb(f"âŒ {error_message}")
        messagebox.showerror("ä¸Šå‚³å¤±æ•—", error_message)
            
    def run(self):
        """åŸ·è¡Œ GUI æ‡‰ç”¨ç¨‹å¼"""
        try:
            # è¨­å®šé—œé–‰æ™‚çš„æ¸…ç†
            def on_closing():
                self.gui_running = False  # åœæ­¢æ‰€æœ‰ GUI æ›´æ–°
                try:
                    self.log_info("MaiAgent é©—è­‰å·¥å…·æ­£åœ¨é—œé–‰...")
                    self.log_info(f"æœ€çµ‚æ—¥èªŒçµ±è¨ˆ: {self.get_log_stats()}")
                except:
                    # å¦‚æœæ—¥èªŒè¨˜éŒ„å¤±æ•—ï¼Œç›´æ¥é—œé–‰
                    pass
                self.root.destroy()
            
            self.root.protocol("WM_DELETE_WINDOW", on_closing)
            self.root.mainloop()
        except Exception as e:
            # å®Œå…¨å®‰å…¨çš„ç•°å¸¸è™•ç† - é¿å…ä»»ä½•å¯èƒ½çš„éæ­¸
            error_type = type(e).__name__
            error_msg = str(e)[:200]  # é™åˆ¶éŒ¯èª¤è¨Šæ¯é•·åº¦
            
            print(f"[SAFE-ERROR] æ‡‰ç”¨ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {error_msg}")
            print(f"[SAFE-ERROR] éŒ¯èª¤é¡å‹: {error_type}")
            
            # å¦‚æœæ˜¯éæ­¸éŒ¯èª¤ï¼Œç«‹å³å•Ÿç”¨æ‰€æœ‰å®‰å…¨æ©Ÿåˆ¶
            if isinstance(e, RecursionError) or "recursion" in error_msg.lower() or "maximum" in error_msg.lower():
                self._emergency_throttle = True
                self._download_in_progress = False  # åœæ­¢ä¸‹è¼‰
                print("[SAFE-ERROR] åµæ¸¬åˆ°éæ­¸éŒ¯èª¤ï¼Œå•Ÿç”¨ç·Šæ€¥ä¿è­·æ¨¡å¼")
                
                # å˜—è©¦æ¸…ç†GUIç‹€æ…‹
                try:
                    if hasattr(self, 'root') and self.root:
                        self.root.after(100, lambda: setattr(self, 'gui_running', False))
                except:
                    pass
            
            # ä¸èª¿ç”¨ä»»ä½•å¯èƒ½éæ­¸çš„æ–¹æ³•ï¼Œç›´æ¥é€€å‡º
            return

    def on_kb_selection_changed(self, event):
        """çŸ¥è­˜åº«é¸æ“‡è®Šæ›´è™•ç†"""
        selection = self.kb_listbox.curselection()
        if selection:
            selected_kb = self.knowledge_bases[selection[0]]
            self.current_kb_id = selected_kb['id']
            self.selected_kb_id = selected_kb['id']  # ä¿æŒç›¸å®¹æ€§
            self.log_kb(f"é¸æ“‡äº†çŸ¥è­˜åº«: {selected_kb.get('name', 'Unknown')}")
            
            # å•Ÿç”¨ä¸Šå‚³åŠŸèƒ½ï¼ˆå¦‚æœå·²é¸æ“‡æª”æ¡ˆï¼‰
            if hasattr(self, 'upload_file_var') and self.upload_file_var.get():
                self.upload_start_button.config(state=tk.NORMAL)
            
            # è‡ªå‹•è¼‰å…¥æª”æ¡ˆåˆ—è¡¨
            self.load_kb_files()
        else:
            self.current_kb_id = None
            self.selected_kb_id = None
            if hasattr(self, 'upload_start_button'):
                self.upload_start_button.config(state=tk.DISABLED)
    
    def on_load_mode_changed(self):
        """è¼‰å…¥æ¨¡å¼è®Šæ›´è™•ç†"""
        if hasattr(self, 'load_all_at_once'):
            mode = "ä¸€æ¬¡æ€§è¼‰å…¥" if self.load_all_at_once.get() else "åˆ†é è¼‰å…¥"
            self.log_kb(f"ğŸ“‹ è¼‰å…¥æ¨¡å¼å·²è®Šæ›´ç‚º: {mode}")
            # å¦‚æœå·²ç¶“è¼‰å…¥äº†æ–‡ä»¶ï¼Œæç¤ºç”¨æˆ¶é‡æ–°è¼‰å…¥
            if hasattr(self, 'files_tree') and self.files_tree.get_children():
                self.log_kb("ğŸ’¡ æ¨¡å¼è®Šæ›´å¾Œï¼Œè«‹é‡æ–°è¼‰å…¥æ–‡ä»¶ä»¥å¥—ç”¨æ–°è¨­ç½®")
    
    def load_kb_files(self):
        """è¼‰å…¥çŸ¥è­˜åº«æª”æ¡ˆåˆ—è¡¨"""
        if not self.current_kb_id and not self.selected_kb_id:
            messagebox.showerror("éŒ¯èª¤", "è«‹å…ˆé¸æ“‡çŸ¥è­˜åº«")
            self.log_kb("âŒ è¼‰å…¥æª”æ¡ˆå¤±æ•— - æœªé¸æ“‡çŸ¥è­˜åº«")
            return
        
        # ç²å–APIé…ç½®
        base_url = self.kb_base_url.get().strip()
        api_key = self.kb_api_key.get().strip()
        
        if not base_url:
            messagebox.showerror("éŒ¯èª¤", "è«‹å…ˆè¼¸å…¥ API åŸºç¤ URL")
            self.log_kb("âŒ è¼‰å…¥å¤±æ•— - æœªè¼¸å…¥åŸºç¤URL")
            return
            
        if not api_key:
            messagebox.showerror("éŒ¯èª¤", "è«‹å…ˆè¼¸å…¥ API é‡‘é‘°")
            self.log_kb("âŒ è¼‰å…¥å¤±æ•— - æœªè¼¸å…¥APIé‡‘é‘°")
            return
        
        # ä½¿ç”¨current_kb_idæˆ–selected_kb_id
        kb_id = self.current_kb_id or self.selected_kb_id
        
        def update_progress(current, total):
            """æ›´æ–°é€²åº¦æ¢ï¼ˆç·šç¨‹å®‰å…¨ï¼‰"""
            if not self.gui_running:
                return
                
            if total > 0:
                progress = (current / total) * 100
                try:
                    self.root.after(0, lambda p=progress: self._safe_update_kb_progress_bar(p))
                    self.root.after(0, lambda c=current, t=total: self._safe_update_kb_progress_label(c, t))
                except Exception:
                    pass
            else:
                try:
                    self.root.after(0, lambda: self._safe_update_kb_progress_bar(0))
                    self.root.after(0, lambda: self._safe_update_kb_progress_label(0, 0))
                except Exception:
                    pass
        
        def load_async():
            try:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                # é‡ç½®é€²åº¦æ¢
                self.root.after(0, lambda: self._safe_update_kb_progress_bar(0))
                self.root.after(0, lambda: self._safe_update_kb_progress_label_text("è¼‰å…¥ä¸­..."))
                
                self.root.after(0, lambda: self.log_kb(f"ï¿½ï¿½ æ­£åœ¨è¼‰å…¥çŸ¥è­˜åº«æª”æ¡ˆ (ID: {kb_id})..."))
                
                async def fetch():
                    async with MaiAgentApiClient(base_url, api_key, None) as client:
                        load_all = getattr(self, 'load_all_at_once', tk.BooleanVar(value=True)).get()
                        files = await client.get_knowledge_base_files(kb_id, progress_callback=update_progress, load_all_at_once=load_all)
                        mode_text = "ä¸€æ¬¡æ€§è¼‰å…¥" if load_all else "åˆ†é è¼‰å…¥"
                        self.root.after(0, lambda: self.log_kb(f"ğŸ“‹ æˆåŠŸç²å– {len(files)} å€‹æª”æ¡ˆï¼ˆ{mode_text}ï¼‰"))
                        return files
                
                files = loop.run_until_complete(fetch())
                loop.close()
                
                # å®Œæˆé€²åº¦
                self.root.after(0, lambda: self._safe_update_kb_progress_bar(100))
                self.root.after(0, lambda: self.update_files_list(files))
                
            except Exception as e:
                error_msg = str(e)
                self.root.after(0, lambda: self.log_kb(f"âŒ è¼‰å…¥æª”æ¡ˆå¤±æ•—: {error_msg}"))
                self.root.after(0, lambda: messagebox.showerror("éŒ¯èª¤", f"è¼‰å…¥æª”æ¡ˆåˆ—è¡¨å¤±æ•—ï¼š{error_msg}"))
                # é‡ç½®é€²åº¦æ¢
                self.root.after(0, lambda: self._safe_update_kb_progress_bar(0))
                self.root.after(0, lambda: self._safe_update_kb_progress_label_text("è¼‰å…¥å¤±æ•—"))
        
        threading.Thread(target=load_async, daemon=True).start()


def main():
    """ä¸»å‡½æ•¸"""
    try:
        app = MaiAgentValidatorGUI()
        app.run()
    except Exception as e:
        messagebox.showerror("éŒ¯èª¤", f"æ‡‰ç”¨ç¨‹å¼å•Ÿå‹•å¤±æ•—: {str(e)}")


if __name__ == "__main__":
    main() 